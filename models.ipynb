{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc82a403-2dd5-4c13-a37e-3a116d02427e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-pandasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for sklearn-pandas from https://files.pythonhosted.org/packages/30/71/ccd5222f731993dfc1a6d9e766a507f1859bda4930b9548e54c11c876baf/sklearn_pandas-2.2.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached sklearn_pandas-2.2.0-py2.py3-none-any.whl.metadata (445 bytes)\n",
      "Collecting scikit-learn>=0.23.0 (from sklearn-pandas)\n",
      "  Obtaining dependency information for scikit-learn>=0.23.0 from https://files.pythonhosted.org/packages/52/2d/ad6928a578c78bb0e44e34a5a922818b14c56716b81d145924f1f291416f/scikit_learn-1.3.2-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.2-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.5.1 (from sklearn-pandas)\n",
      "  Obtaining dependency information for scipy>=1.5.1 from https://files.pythonhosted.org/packages/32/8e/7f403535ddf826348c9b8417791e28712019962f7e90ff845896d6325d09/scipy-1.10.1-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached scipy-1.10.1-cp38-cp38-win_amd64.whl.metadata (58 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from sklearn-pandas) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from sklearn-pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas) (2025.2)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.23.0->sklearn-pandas)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.23.0->sklearn-pandas)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->sklearn-pandas) (1.17.0)\n",
      "Using cached sklearn_pandas-2.2.0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached scikit_learn-1.3.2-cp38-cp38-win_amd64.whl (9.3 MB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "   ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/42.2 MB 388.9 kB/s eta 0:01:49\n",
      "   ---------------------------------------- 0.0/42.2 MB 388.9 kB/s eta 0:01:49\n",
      "   ---------------------------------------- 0.1/42.2 MB 363.1 kB/s eta 0:01:57\n",
      "   ---------------------------------------- 0.1/42.2 MB 301.2 kB/s eta 0:02:20\n",
      "   ---------------------------------------- 0.1/42.2 MB 301.2 kB/s eta 0:02:20\n",
      "   ---------------------------------------- 0.1/42.2 MB 301.2 kB/s eta 0:02:20\n",
      "   ---------------------------------------- 0.1/42.2 MB 301.2 kB/s eta 0:02:20\n",
      "   ---------------------------------------- 0.1/42.2 MB 201.3 kB/s eta 0:03:30\n",
      "   ---------------------------------------- 0.1/42.2 MB 242.7 kB/s eta 0:02:54\n",
      "   ---------------------------------------- 0.1/42.2 MB 242.7 kB/s eta 0:02:54\n",
      "   ---------------------------------------- 0.1/42.2 MB 242.7 kB/s eta 0:02:54\n",
      "   ---------------------------------------- 0.1/42.2 MB 242.7 kB/s eta 0:02:54\n",
      "   ---------------------------------------- 0.1/42.2 MB 175.7 kB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.1/42.2 MB 175.7 kB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.1/42.2 MB 175.7 kB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.1/42.2 MB 175.7 kB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.1/42.2 MB 175.7 kB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.1/42.2 MB 175.7 kB/s eta 0:04:00\n",
      "   ---------------------------------------- 0.1/42.2 MB 144.4 kB/s eta 0:04:52\n",
      "   ---------------------------------------- 0.1/42.2 MB 144.4 kB/s eta 0:04:52\n",
      "   ---------------------------------------- 0.1/42.2 MB 144.4 kB/s eta 0:04:52\n",
      "   ---------------------------------------- 0.2/42.2 MB 132.9 kB/s eta 0:05:17\n",
      "   ---------------------------------------- 0.2/42.2 MB 132.9 kB/s eta 0:05:17\n",
      "   ---------------------------------------- 0.2/42.2 MB 132.9 kB/s eta 0:05:17\n",
      "   ---------------------------------------- 0.2/42.2 MB 132.9 kB/s eta 0:05:17\n",
      "   ---------------------------------------- 0.2/42.2 MB 131.1 kB/s eta 0:05:21\n",
      "   ---------------------------------------- 0.2/42.2 MB 131.1 kB/s eta 0:05:21\n",
      "   ---------------------------------------- 0.2/42.2 MB 131.1 kB/s eta 0:05:21\n",
      "   ---------------------------------------- 0.2/42.2 MB 131.1 kB/s eta 0:05:21\n",
      "   ---------------------------------------- 0.2/42.2 MB 131.0 kB/s eta 0:05:21\n",
      "   ---------------------------------------- 0.2/42.2 MB 131.0 kB/s eta 0:05:21\n",
      "   ---------------------------------------- 0.2/42.2 MB 128.3 kB/s eta 0:05:28\n",
      "   ---------------------------------------- 0.2/42.2 MB 128.3 kB/s eta 0:05:28\n",
      "   ---------------------------------------- 0.2/42.2 MB 128.3 kB/s eta 0:05:28\n",
      "   ---------------------------------------- 0.2/42.2 MB 128.3 kB/s eta 0:05:28\n",
      "   ---------------------------------------- 0.2/42.2 MB 128.3 kB/s eta 0:05:28\n",
      "   ---------------------------------------- 0.2/42.2 MB 123.9 kB/s eta 0:05:39\n",
      "   ---------------------------------------- 0.2/42.2 MB 123.9 kB/s eta 0:05:39\n",
      "   ---------------------------------------- 0.2/42.2 MB 120.1 kB/s eta 0:05:50\n",
      "   ---------------------------------------- 0.2/42.2 MB 120.1 kB/s eta 0:05:50\n",
      "   ---------------------------------------- 0.2/42.2 MB 120.1 kB/s eta 0:05:50\n",
      "   ---------------------------------------- 0.3/42.2 MB 122.9 kB/s eta 0:05:42\n",
      "   ---------------------------------------- 0.3/42.2 MB 122.9 kB/s eta 0:05:42\n",
      "   ---------------------------------------- 0.3/42.2 MB 122.9 kB/s eta 0:05:42\n",
      "   ---------------------------------------- 0.3/42.2 MB 122.9 kB/s eta 0:05:42\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 119.1 kB/s eta 0:05:53\n",
      "   ---------------------------------------- 0.3/42.2 MB 106.6 kB/s eta 0:06:34\n",
      "   ---------------------------------------- 0.3/42.2 MB 106.6 kB/s eta 0:06:34\n",
      "   ---------------------------------------- 0.3/42.2 MB 106.6 kB/s eta 0:06:34\n",
      "   ---------------------------------------- 0.3/42.2 MB 106.6 kB/s eta 0:06:34\n",
      "   ---------------------------------------- 0.3/42.2 MB 106.6 kB/s eta 0:06:34\n",
      "   ---------------------------------------- 0.3/42.2 MB 106.6 kB/s eta 0:06:34\n",
      "   ---------------------------------------- 0.3/42.2 MB 103.3 kB/s eta 0:06:46\n",
      "   ---------------------------------------- 0.3/42.2 MB 103.3 kB/s eta 0:06:46\n",
      "   ---------------------------------------- 0.3/42.2 MB 103.3 kB/s eta 0:06:46\n",
      "   ---------------------------------------- 0.3/42.2 MB 103.3 kB/s eta 0:06:46\n",
      "   ---------------------------------------- 0.3/42.2 MB 103.3 kB/s eta 0:06:46\n",
      "   ---------------------------------------- 0.3/42.2 MB 103.3 kB/s eta 0:06:46\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.8 kB/s eta 0:07:09\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.8 kB/s eta 0:07:09\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.8 kB/s eta 0:07:09\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.8 kB/s eta 0:07:09\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.1 kB/s eta 0:07:12\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.1 kB/s eta 0:07:12\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.1 kB/s eta 0:07:12\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.1 kB/s eta 0:07:12\n",
      "   ---------------------------------------- 0.3/42.2 MB 97.1 kB/s eta 0:07:12\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 96.4 kB/s eta 0:07:15\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 91.4 kB/s eta 0:07:38\n",
      "   ---------------------------------------- 0.4/42.2 MB 89.1 kB/s eta 0:07:50\n",
      "   ---------------------------------------- 0.4/42.2 MB 89.1 kB/s eta 0:07:50\n",
      "   ---------------------------------------- 0.4/42.2 MB 89.1 kB/s eta 0:07:50\n",
      "   ---------------------------------------- 0.4/42.2 MB 89.1 kB/s eta 0:07:50\n",
      "   ---------------------------------------- 0.4/42.2 MB 89.1 kB/s eta 0:07:50\n",
      "   ---------------------------------------- 0.4/42.2 MB 89.1 kB/s eta 0:07:50\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.3 kB/s eta 0:08:11\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.3 kB/s eta 0:08:11\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.3 kB/s eta 0:08:11\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.3 kB/s eta 0:08:11\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.3 kB/s eta 0:08:11\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.3 kB/s eta 0:08:11\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.4 kB/s eta 0:08:10\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.4 kB/s eta 0:08:10\n",
      "   ---------------------------------------- 0.4/42.2 MB 85.4 kB/s eta 0:08:10\n",
      "   ---------------------------------------- 0.4/42.2 MB 86.8 kB/s eta 0:08:02\n",
      "   ---------------------------------------- 0.4/42.2 MB 86.8 kB/s eta 0:08:02\n",
      "   ---------------------------------------- 0.4/42.2 MB 86.8 kB/s eta 0:08:02\n",
      "   ---------------------------------------- 0.4/42.2 MB 86.8 kB/s eta 0:08:02\n",
      "   ---------------------------------------- 0.5/42.2 MB 85.9 kB/s eta 0:08:07\n",
      "   ---------------------------------------- 0.5/42.2 MB 85.9 kB/s eta 0:08:07\n",
      "   ---------------------------------------- 0.5/42.2 MB 85.9 kB/s eta 0:08:07\n",
      "   ---------------------------------------- 0.5/42.2 MB 85.9 kB/s eta 0:08:07\n",
      "   ---------------------------------------- 0.5/42.2 MB 86.2 kB/s eta 0:08:05\n",
      "   ---------------------------------------- 0.5/42.2 MB 86.2 kB/s eta 0:08:05\n",
      "   ---------------------------------------- 0.5/42.2 MB 86.2 kB/s eta 0:08:05\n",
      "   ---------------------------------------- 0.5/42.2 MB 86.2 kB/s eta 0:08:05\n",
      "   ---------------------------------------- 0.5/42.2 MB 86.2 kB/s eta 0:08:05\n",
      "   ---------------------------------------- 0.5/42.2 MB 86.2 kB/s eta 0:08:05\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 83.3 kB/s eta 0:08:22\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 82.1 kB/s eta 0:08:28\n",
      "   ---------------------------------------- 0.5/42.2 MB 81.1 kB/s eta 0:08:35\n",
      "   ---------------------------------------- 0.5/42.2 MB 81.1 kB/s eta 0:08:35\n",
      "   ---------------------------------------- 0.5/42.2 MB 81.1 kB/s eta 0:08:35\n",
      "   ---------------------------------------- 0.5/42.2 MB 81.1 kB/s eta 0:08:35\n",
      "   ---------------------------------------- 0.5/42.2 MB 81.1 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.5/42.2 MB 79.8 kB/s eta 0:08:43\n",
      "    --------------------------------------- 0.5/42.2 MB 79.8 kB/s eta 0:08:43\n",
      "    --------------------------------------- 0.5/42.2 MB 79.8 kB/s eta 0:08:43\n",
      "    --------------------------------------- 0.5/42.2 MB 79.8 kB/s eta 0:08:43\n",
      "    --------------------------------------- 0.6/42.2 MB 81.0 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 81.0 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 81.0 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 81.0 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 81.0 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 79.3 kB/s eta 0:08:45\n",
      "    --------------------------------------- 0.6/42.2 MB 79.3 kB/s eta 0:08:45\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.6/42.2 MB 82.1 kB/s eta 0:08:27\n",
      "    --------------------------------------- 0.6/42.2 MB 82.1 kB/s eta 0:08:27\n",
      "    --------------------------------------- 0.6/42.2 MB 82.1 kB/s eta 0:08:27\n",
      "    --------------------------------------- 0.6/42.2 MB 82.1 kB/s eta 0:08:27\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 81.6 kB/s eta 0:08:31\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 80.8 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.6/42.2 MB 79.0 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.6/42.2 MB 79.0 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.6/42.2 MB 79.0 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.7/42.2 MB 79.9 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.7/42.2 MB 79.9 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.7/42.2 MB 79.9 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.7/42.2 MB 79.9 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.7/42.2 MB 79.9 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.7/42.2 MB 80.2 kB/s eta 0:08:38\n",
      "    --------------------------------------- 0.7/42.2 MB 80.2 kB/s eta 0:08:38\n",
      "    --------------------------------------- 0.7/42.2 MB 80.2 kB/s eta 0:08:38\n",
      "    --------------------------------------- 0.7/42.2 MB 80.2 kB/s eta 0:08:38\n",
      "    --------------------------------------- 0.7/42.2 MB 80.2 kB/s eta 0:08:38\n",
      "    --------------------------------------- 0.7/42.2 MB 80.2 kB/s eta 0:08:38\n",
      "    --------------------------------------- 0.7/42.2 MB 78.4 kB/s eta 0:08:50\n",
      "    --------------------------------------- 0.7/42.2 MB 78.4 kB/s eta 0:08:50\n",
      "    --------------------------------------- 0.7/42.2 MB 78.4 kB/s eta 0:08:50\n",
      "    --------------------------------------- 0.7/42.2 MB 79.6 kB/s eta 0:08:42\n",
      "    --------------------------------------- 0.7/42.2 MB 79.6 kB/s eta 0:08:42\n",
      "    --------------------------------------- 0.7/42.2 MB 79.6 kB/s eta 0:08:42\n",
      "    --------------------------------------- 0.7/42.2 MB 79.5 kB/s eta 0:08:42\n",
      "    --------------------------------------- 0.7/42.2 MB 79.5 kB/s eta 0:08:42\n",
      "    --------------------------------------- 0.7/42.2 MB 79.5 kB/s eta 0:08:42\n",
      "    --------------------------------------- 0.7/42.2 MB 80.4 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.7/42.2 MB 80.4 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.7/42.2 MB 80.4 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.7/42.2 MB 80.4 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.7/42.2 MB 80.4 kB/s eta 0:08:36\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 80.7 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.8/42.2 MB 78.9 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.8/42.2 MB 78.9 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.8/42.2 MB 78.9 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.8/42.2 MB 78.9 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.8/42.2 MB 78.9 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.8/42.2 MB 78.9 kB/s eta 0:08:46\n",
      "    --------------------------------------- 0.8/42.2 MB 78.6 kB/s eta 0:08:47\n",
      "    --------------------------------------- 0.8/42.2 MB 78.6 kB/s eta 0:08:47\n",
      "    --------------------------------------- 0.8/42.2 MB 78.6 kB/s eta 0:08:47\n",
      "    --------------------------------------- 0.8/42.2 MB 78.4 kB/s eta 0:08:49\n",
      "    --------------------------------------- 0.8/42.2 MB 78.4 kB/s eta 0:08:49\n",
      "    --------------------------------------- 0.8/42.2 MB 78.4 kB/s eta 0:08:49\n",
      "    --------------------------------------- 0.8/42.2 MB 78.4 kB/s eta 0:08:49\n",
      "    --------------------------------------- 0.8/42.2 MB 78.8 kB/s eta 0:08:45\n",
      "    --------------------------------------- 0.8/42.2 MB 78.8 kB/s eta 0:08:45\n",
      "    --------------------------------------- 0.8/42.2 MB 78.8 kB/s eta 0:08:45\n",
      "    --------------------------------------- 0.8/42.2 MB 78.8 kB/s eta 0:08:45\n",
      "    --------------------------------------- 0.8/42.2 MB 79.6 kB/s eta 0:08:40\n",
      "    --------------------------------------- 0.8/42.2 MB 79.6 kB/s eta 0:08:40\n",
      "    --------------------------------------- 0.8/42.2 MB 79.6 kB/s eta 0:08:40\n",
      "    --------------------------------------- 0.9/42.2 MB 79.4 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.9/42.2 MB 79.4 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.9/42.2 MB 79.4 kB/s eta 0:08:41\n",
      "    --------------------------------------- 0.9/42.2 MB 80.4 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.9/42.2 MB 80.4 kB/s eta 0:08:35\n",
      "    --------------------------------------- 0.9/42.2 MB 80.5 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.9/42.2 MB 80.5 kB/s eta 0:08:34\n",
      "    --------------------------------------- 0.9/42.2 MB 81.7 kB/s eta 0:08:26\n",
      "    --------------------------------------- 0.9/42.2 MB 81.7 kB/s eta 0:08:26\n",
      "    --------------------------------------- 0.9/42.2 MB 82.8 kB/s eta 0:08:19\n",
      "    --------------------------------------- 0.9/42.2 MB 82.8 kB/s eta 0:08:19\n",
      "    --------------------------------------- 0.9/42.2 MB 82.8 kB/s eta 0:08:19\n",
      "    --------------------------------------- 0.9/42.2 MB 82.8 kB/s eta 0:08:19\n",
      "    --------------------------------------- 0.9/42.2 MB 82.4 kB/s eta 0:08:22\n",
      "    --------------------------------------- 0.9/42.2 MB 82.4 kB/s eta 0:08:22\n",
      "    --------------------------------------- 0.9/42.2 MB 82.4 kB/s eta 0:08:22\n",
      "    --------------------------------------- 1.0/42.2 MB 83.4 kB/s eta 0:08:15\n",
      "    --------------------------------------- 1.0/42.2 MB 83.7 kB/s eta 0:08:13\n",
      "    --------------------------------------- 1.0/42.2 MB 83.7 kB/s eta 0:08:13\n",
      "    --------------------------------------- 1.0/42.2 MB 83.7 kB/s eta 0:08:13\n",
      "    --------------------------------------- 1.0/42.2 MB 83.7 kB/s eta 0:08:13\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.8 kB/s eta 0:08:06\n",
      "    --------------------------------------- 1.0/42.2 MB 84.8 kB/s eta 0:08:06\n",
      "    --------------------------------------- 1.0/42.2 MB 84.8 kB/s eta 0:08:06\n",
      "    --------------------------------------- 1.0/42.2 MB 84.8 kB/s eta 0:08:06\n",
      "    --------------------------------------- 1.0/42.2 MB 84.8 kB/s eta 0:08:06\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.0 kB/s eta 0:08:11\n",
      "    --------------------------------------- 1.0/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.0/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.1/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.1/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.1/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.1/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.1/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "    --------------------------------------- 1.1/42.2 MB 84.5 kB/s eta 0:08:08\n",
      "   - -------------------------------------- 1.1/42.2 MB 84.0 kB/s eta 0:08:10\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 85.2 kB/s eta 0:08:03\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 83.9 kB/s eta 0:08:11\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.9 kB/s eta 0:08:16\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.9 kB/s eta 0:08:16\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.9 kB/s eta 0:08:16\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.1/42.2 MB 82.6 kB/s eta 0:08:18\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.7 kB/s eta 0:08:23\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.7 kB/s eta 0:08:23\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.7 kB/s eta 0:08:23\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.7 kB/s eta 0:08:23\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.7 kB/s eta 0:08:23\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.7 kB/s eta 0:08:23\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 81.6 kB/s eta 0:08:24\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.6 kB/s eta 0:08:36\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.6 kB/s eta 0:08:36\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.6 kB/s eta 0:08:36\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.6 kB/s eta 0:08:36\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.6 kB/s eta 0:08:36\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.7 kB/s eta 0:08:35\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.7 kB/s eta 0:08:35\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.7 kB/s eta 0:08:35\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 79.4 kB/s eta 0:08:37\n",
      "   - -------------------------------------- 1.2/42.2 MB 78.5 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.2/42.2 MB 78.5 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 79.0 kB/s eta 0:08:39\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.0 kB/s eta 0:08:45\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.0 kB/s eta 0:08:45\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.0 kB/s eta 0:08:45\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.0 kB/s eta 0:08:45\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.4 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.4 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.4 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.4 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.4 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 78.4 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.5 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.0 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.0 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.0 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.0 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.0 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.3/42.2 MB 77.0 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.3/42.2 MB 76.8 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.3/42.2 MB 76.8 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.3/42.2 MB 76.8 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.3/42.2 MB 76.8 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.4/42.2 MB 76.7 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.4/42.2 MB 76.7 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.4/42.2 MB 76.7 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.2 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.2 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.2 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.2 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 76.6 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.4/42.2 MB 76.6 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.4/42.2 MB 76.6 kB/s eta 0:08:53\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:51\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:51\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:51\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:51\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.1 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.1 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.1 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.1 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.4/42.2 MB 77.0 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.4 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.4 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.4 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.4 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.4 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.4 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.5/42.2 MB 76.7 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.5/42.2 MB 76.7 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.5/42.2 MB 76.7 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.2 kB/s eta 0:08:48\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.2 kB/s eta 0:08:48\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.2 kB/s eta 0:08:48\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.2 kB/s eta 0:08:48\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.5 kB/s eta 0:08:46\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.5 kB/s eta 0:08:46\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.6 kB/s eta 0:08:45\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.6 kB/s eta 0:08:45\n",
      "   - -------------------------------------- 1.5/42.2 MB 78.2 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.5/42.2 MB 78.2 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.5/42.2 MB 78.2 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.5/42.2 MB 78.2 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.5/42.2 MB 78.2 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.5/42.2 MB 78.2 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.8 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.8 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.8 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.8 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.8 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.5/42.2 MB 77.8 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.2 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.2 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.2 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.2 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.1 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.1 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.1 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.1 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.1 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 78.1 kB/s eta 0:08:40\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:42\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:42\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:42\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.9 kB/s eta 0:08:41\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.6/42.2 MB 77.6 kB/s eta 0:08:44\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.7 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.7 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.7 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.7 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.7 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.7 kB/s eta 0:08:43\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 77.0 kB/s eta 0:08:47\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 76.7 kB/s eta 0:08:49\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.9 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.9 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.9 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.9 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.9 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.9 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.7/42.2 MB 75.8 kB/s eta 0:08:54\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 75.3 kB/s eta 0:08:58\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.4 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 74.2 kB/s eta 0:09:05\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.3 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.3 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.3 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.3 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.5 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.2 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.2 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.2 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.2 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.2 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.8/42.2 MB 73.2 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.1 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.1 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.1 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.1 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.1 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.1 kB/s eta 0:09:12\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.8 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.8 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.8 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.8 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.8 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.8 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.7 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.7 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.7 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.7 kB/s eta 0:09:15\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.9 kB/s eta 0:09:13\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.9 kB/s eta 0:09:13\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.9 kB/s eta 0:09:13\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.9 kB/s eta 0:09:13\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.9 kB/s eta 0:09:13\n",
      "   - -------------------------------------- 1.9/42.2 MB 72.9 kB/s eta 0:09:13\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.3 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.3 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 1.9/42.2 MB 73.3 kB/s eta 0:09:10\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.4 kB/s eta 0:09:09\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.4 kB/s eta 0:09:09\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.4 kB/s eta 0:09:09\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.4 kB/s eta 0:09:09\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.4 kB/s eta 0:09:09\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.5 kB/s eta 0:09:08\n",
      "   - -------------------------------------- 2.0/42.2 MB 73.5 kB/s eta 0:09:08\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.0 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.0 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.0 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.0 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.0 kB/s eta 0:09:04\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.5 kB/s eta 0:09:00\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.5 kB/s eta 0:09:00\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.5 kB/s eta 0:09:00\n",
      "   - -------------------------------------- 2.0/42.2 MB 74.5 kB/s eta 0:09:00\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.1 kB/s eta 0:08:55\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.1 kB/s eta 0:08:55\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.6 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.6 kB/s eta 0:08:52\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.7 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.7 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.7 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.7 kB/s eta 0:08:50\n",
      "   - -------------------------------------- 2.1/42.2 MB 75.9 kB/s eta 0:08:49\n",
      "   -- ------------------------------------- 2.1/42.2 MB 76.1 kB/s eta 0:08:47\n",
      "   -- ------------------------------------- 2.1/42.2 MB 76.1 kB/s eta 0:08:47\n",
      "   -- ------------------------------------- 2.1/42.2 MB 76.6 kB/s eta 0:08:44\n",
      "   -- ------------------------------------- 2.1/42.2 MB 76.6 kB/s eta 0:08:44\n",
      "   -- ------------------------------------- 2.2/42.2 MB 77.1 kB/s eta 0:08:40\n",
      "   -- ------------------------------------- 2.2/42.2 MB 77.1 kB/s eta 0:08:40\n",
      "   -- ------------------------------------- 2.2/42.2 MB 77.3 kB/s eta 0:08:39\n",
      "   -- ------------------------------------- 2.2/42.2 MB 77.8 kB/s eta 0:08:35\n",
      "   -- ------------------------------------- 2.2/42.2 MB 77.8 kB/s eta 0:08:35\n",
      "   -- ------------------------------------- 2.2/42.2 MB 77.9 kB/s eta 0:08:34\n",
      "   -- ------------------------------------- 2.2/42.2 MB 78.5 kB/s eta 0:08:30\n",
      "   -- ------------------------------------- 2.2/42.2 MB 79.0 kB/s eta 0:08:26\n",
      "   -- ------------------------------------- 2.3/42.2 MB 79.2 kB/s eta 0:08:25\n",
      "   -- ------------------------------------- 2.3/42.2 MB 79.2 kB/s eta 0:08:25\n",
      "   -- ------------------------------------- 2.3/42.2 MB 79.8 kB/s eta 0:08:21\n",
      "   -- ------------------------------------- 2.3/42.2 MB 80.0 kB/s eta 0:08:20\n",
      "   -- ------------------------------------- 2.3/42.2 MB 80.5 kB/s eta 0:08:16\n",
      "   -- ------------------------------------- 2.3/42.2 MB 80.8 kB/s eta 0:08:15\n",
      "   -- ------------------------------------- 2.3/42.2 MB 81.3 kB/s eta 0:08:11\n",
      "   -- ------------------------------------- 2.4/42.2 MB 81.9 kB/s eta 0:08:07\n",
      "   -- ------------------------------------- 2.4/42.2 MB 82.1 kB/s eta 0:08:06\n",
      "   -- ------------------------------------- 2.4/42.2 MB 82.1 kB/s eta 0:08:06\n",
      "   -- ------------------------------------- 2.4/42.2 MB 82.1 kB/s eta 0:08:06\n",
      "   -- ------------------------------------- 2.4/42.2 MB 82.1 kB/s eta 0:08:06\n",
      "   -- ------------------------------------- 2.4/42.2 MB 82.1 kB/s eta 0:08:06\n",
      "   -- ------------------------------------- 2.4/42.2 MB 83.2 kB/s eta 0:07:59\n",
      "   -- ------------------------------------- 2.4/42.2 MB 83.2 kB/s eta 0:07:59\n",
      "   -- ------------------------------------- 2.4/42.2 MB 83.7 kB/s eta 0:07:56\n",
      "   -- ------------------------------------- 2.4/42.2 MB 83.9 kB/s eta 0:07:55\n",
      "   -- ------------------------------------- 2.4/42.2 MB 83.9 kB/s eta 0:07:55\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.4 kB/s eta 0:07:51\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.4 kB/s eta 0:07:51\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.4 kB/s eta 0:07:51\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.4 kB/s eta 0:07:51\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.4 kB/s eta 0:07:51\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.0 kB/s eta 0:07:54\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.6 kB/s eta 0:07:50\n",
      "   -- ------------------------------------- 2.5/42.2 MB 84.6 kB/s eta 0:07:50\n",
      "   -- ------------------------------------- 2.5/42.2 MB 85.0 kB/s eta 0:07:48\n",
      "   -- ------------------------------------- 2.5/42.2 MB 85.1 kB/s eta 0:07:47\n",
      "   -- ------------------------------------- 2.5/42.2 MB 85.1 kB/s eta 0:07:47\n",
      "   -- ------------------------------------- 2.5/42.2 MB 85.6 kB/s eta 0:07:44\n",
      "   -- ------------------------------------- 2.6/42.2 MB 85.7 kB/s eta 0:07:43\n",
      "   -- ------------------------------------- 2.6/42.2 MB 85.7 kB/s eta 0:07:43\n",
      "   -- ------------------------------------- 2.6/42.2 MB 86.3 kB/s eta 0:07:40\n",
      "   -- ------------------------------------- 2.6/42.2 MB 86.8 kB/s eta 0:07:37\n",
      "   -- ------------------------------------- 2.6/42.2 MB 86.8 kB/s eta 0:07:37\n",
      "   -- ------------------------------------- 2.6/42.2 MB 87.5 kB/s eta 0:07:33\n",
      "   -- ------------------------------------- 2.6/42.2 MB 87.5 kB/s eta 0:07:33\n",
      "   -- ------------------------------------- 2.6/42.2 MB 87.5 kB/s eta 0:07:33\n",
      "   -- ------------------------------------- 2.7/42.2 MB 87.4 kB/s eta 0:07:33\n",
      "   -- ------------------------------------- 2.7/42.2 MB 87.8 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.7/42.2 MB 87.5 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.7/42.2 MB 88.2 kB/s eta 0:07:28\n",
      "   -- ------------------------------------- 2.7/42.2 MB 88.4 kB/s eta 0:07:27\n",
      "   -- ------------------------------------- 2.7/42.2 MB 88.4 kB/s eta 0:07:27\n",
      "   -- ------------------------------------- 2.7/42.2 MB 88.4 kB/s eta 0:07:27\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.6 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 88.5 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.5 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.5 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.5 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.5 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.5 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.5 kB/s eta 0:07:31\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.2 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.2 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.2 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.1 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.1 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.1 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.1 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.1 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.8/42.2 MB 87.1 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 86.7 kB/s eta 0:07:35\n",
      "   -- ------------------------------------- 2.9/42.2 MB 86.7 kB/s eta 0:07:35\n",
      "   -- ------------------------------------- 2.9/42.2 MB 86.7 kB/s eta 0:07:35\n",
      "   -- ------------------------------------- 2.9/42.2 MB 86.7 kB/s eta 0:07:35\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.2 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.2 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.2 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.0 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.0 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.0 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.0 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.0 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.0 kB/s eta 0:07:32\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.4 kB/s eta 0:07:30\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.4 kB/s eta 0:07:30\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.4 kB/s eta 0:07:30\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.4 kB/s eta 0:07:30\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.6 kB/s eta 0:07:29\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.6 kB/s eta 0:07:29\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.6 kB/s eta 0:07:29\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.6 kB/s eta 0:07:29\n",
      "   -- ------------------------------------- 2.9/42.2 MB 87.6 kB/s eta 0:07:29\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.1 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.1 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:26\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.2 kB/s eta 0:07:25\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.4 kB/s eta 0:07:24\n",
      "   -- ------------------------------------- 3.0/42.2 MB 88.4 kB/s eta 0:07:24\n",
      "   -- ------------------------------------- 3.0/42.2 MB 89.0 kB/s eta 0:07:21\n",
      "   -- ------------------------------------- 3.0/42.2 MB 89.0 kB/s eta 0:07:21\n",
      "   -- ------------------------------------- 3.0/42.2 MB 89.0 kB/s eta 0:07:21\n",
      "   -- ------------------------------------- 3.0/42.2 MB 89.3 kB/s eta 0:07:19\n",
      "   -- ------------------------------------- 3.0/42.2 MB 89.3 kB/s eta 0:07:19\n",
      "   -- ------------------------------------- 3.1/42.2 MB 89.4 kB/s eta 0:07:19\n",
      "   -- ------------------------------------- 3.1/42.2 MB 89.4 kB/s eta 0:07:19\n",
      "   -- ------------------------------------- 3.1/42.2 MB 89.8 kB/s eta 0:07:17\n",
      "   -- ------------------------------------- 3.1/42.2 MB 90.5 kB/s eta 0:07:13\n",
      "   -- ------------------------------------- 3.1/42.2 MB 90.6 kB/s eta 0:07:12\n",
      "   -- ------------------------------------- 3.1/42.2 MB 90.6 kB/s eta 0:07:12\n",
      "   -- ------------------------------------- 3.1/42.2 MB 91.1 kB/s eta 0:07:10\n",
      "   -- ------------------------------------- 3.1/42.2 MB 91.2 kB/s eta 0:07:09\n",
      "   -- ------------------------------------- 3.2/42.2 MB 92.1 kB/s eta 0:07:05\n",
      "   -- ------------------------------------- 3.2/42.2 MB 92.1 kB/s eta 0:07:05\n",
      "   -- ------------------------------------- 3.2/42.2 MB 92.1 kB/s eta 0:07:05\n",
      "   -- ------------------------------------- 3.2/42.2 MB 92.1 kB/s eta 0:07:05\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.2 kB/s eta 0:07:04\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.2 kB/s eta 0:07:04\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.1 kB/s eta 0:07:04\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.5 kB/s eta 0:07:02\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.5 kB/s eta 0:07:02\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.5 kB/s eta 0:07:02\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.5 kB/s eta 0:07:02\n",
      "   --- ------------------------------------ 3.2/42.2 MB 92.9 kB/s eta 0:07:00\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.7 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.7 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.7 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.7 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 93.8 kB/s eta 0:06:56\n",
      "   --- ------------------------------------ 3.3/42.2 MB 94.4 kB/s eta 0:06:53\n",
      "   --- ------------------------------------ 3.3/42.2 MB 94.4 kB/s eta 0:06:53\n",
      "   --- ------------------------------------ 3.3/42.2 MB 94.7 kB/s eta 0:06:51\n",
      "   --- ------------------------------------ 3.3/42.2 MB 94.7 kB/s eta 0:06:51\n",
      "   --- ------------------------------------ 3.3/42.2 MB 94.7 kB/s eta 0:06:51\n",
      "   --- ------------------------------------ 3.3/42.2 MB 95.2 kB/s eta 0:06:49\n",
      "   --- ------------------------------------ 3.3/42.2 MB 95.2 kB/s eta 0:06:49\n",
      "   --- ------------------------------------ 3.3/42.2 MB 95.2 kB/s eta 0:06:49\n",
      "   --- ------------------------------------ 3.4/42.2 MB 95.5 kB/s eta 0:06:47\n",
      "   --- ------------------------------------ 3.4/42.2 MB 95.6 kB/s eta 0:06:47\n",
      "   --- ------------------------------------ 3.4/42.2 MB 95.6 kB/s eta 0:06:47\n",
      "   --- ------------------------------------ 3.4/42.2 MB 96.1 kB/s eta 0:06:44\n",
      "   --- ------------------------------------ 3.4/42.2 MB 96.1 kB/s eta 0:06:44\n",
      "   --- ------------------------------------ 3.4/42.2 MB 96.6 kB/s eta 0:06:42\n",
      "   --- ------------------------------------ 3.4/42.2 MB 96.7 kB/s eta 0:06:42\n",
      "   --- ------------------------------------ 3.4/42.2 MB 96.7 kB/s eta 0:06:42\n",
      "   --- ------------------------------------ 3.5/42.2 MB 97.3 kB/s eta 0:06:39\n",
      "   --- ------------------------------------ 3.5/42.2 MB 97.4 kB/s eta 0:06:38\n",
      "   --- ------------------------------------ 3.5/42.2 MB 97.4 kB/s eta 0:06:38\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.1 kB/s eta 0:06:35\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.6 kB/s eta 0:06:33\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.8 kB/s eta 0:06:32\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.8 kB/s eta 0:06:32\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.8 kB/s eta 0:06:32\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.8 kB/s eta 0:06:32\n",
      "   --- ------------------------------------ 3.5/42.2 MB 99.0 kB/s eta 0:06:31\n",
      "   --- ------------------------------------ 3.5/42.2 MB 99.0 kB/s eta 0:06:31\n",
      "   --- ------------------------------------ 3.5/42.2 MB 99.0 kB/s eta 0:06:31\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.5 kB/s eta 0:06:33\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.5 kB/s eta 0:06:33\n",
      "   --- ------------------------------------ 3.5/42.2 MB 98.5 kB/s eta 0:06:33\n",
      "   --- ------------------------------------ 3.6/42.2 MB 98.6 kB/s eta 0:06:32\n",
      "   --- ------------------------------------ 3.6/42.2 MB 98.6 kB/s eta 0:06:32\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.7 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.6/42.2 MB 99.6 kB/s eta 0:06:28\n",
      "   --- ------------------------------------ 3.7/42.2 MB 99.8 kB/s eta 0:06:27\n",
      "   --- ------------------------------------ 3.7/42.2 MB 99.8 kB/s eta 0:06:27\n",
      "   --- ------------------------------------ 3.7/42.2 MB 99.8 kB/s eta 0:06:27\n",
      "   --- ------------------------------------ 3.7/42.2 MB 99.8 kB/s eta 0:06:27\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.1 kB/s eta 0:06:26\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.1 kB/s eta 0:06:26\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.1 kB/s eta 0:06:26\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.3 kB/s eta 0:06:24\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.3 kB/s eta 0:06:24\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.3 kB/s eta 0:06:24\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.3 kB/s eta 0:06:24\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.1 kB/s eta 0:06:25\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.4 kB/s eta 0:06:24\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.4 kB/s eta 0:06:24\n",
      "   --- ------------------------------------ 3.7/42.2 MB 100.8 kB/s eta 0:06:22\n",
      "   --- ------------------------------------ 3.8/42.2 MB 101.1 kB/s eta 0:06:21\n",
      "   --- ------------------------------------ 3.8/42.2 MB 101.1 kB/s eta 0:06:21\n",
      "   --- ------------------------------------ 3.8/42.2 MB 101.5 kB/s eta 0:06:19\n",
      "   --- ------------------------------------ 3.8/42.2 MB 101.7 kB/s eta 0:06:18\n",
      "   --- ------------------------------------ 3.8/42.2 MB 101.7 kB/s eta 0:06:18\n",
      "   --- ------------------------------------ 3.8/42.2 MB 102.1 kB/s eta 0:06:17\n",
      "   --- ------------------------------------ 3.8/42.2 MB 102.6 kB/s eta 0:06:15\n",
      "   --- ------------------------------------ 3.8/42.2 MB 103.2 kB/s eta 0:06:12\n",
      "   --- ------------------------------------ 3.9/42.2 MB 103.7 kB/s eta 0:06:10\n",
      "   --- ------------------------------------ 3.9/42.2 MB 103.7 kB/s eta 0:06:10\n",
      "   --- ------------------------------------ 3.9/42.2 MB 103.7 kB/s eta 0:06:10\n",
      "   --- ------------------------------------ 3.9/42.2 MB 103.7 kB/s eta 0:06:10\n",
      "   --- ------------------------------------ 3.9/42.2 MB 103.9 kB/s eta 0:06:09\n",
      "   --- ------------------------------------ 3.9/42.2 MB 105.0 kB/s eta 0:06:05\n",
      "   --- ------------------------------------ 3.9/42.2 MB 105.1 kB/s eta 0:06:05\n",
      "   --- ------------------------------------ 3.9/42.2 MB 105.1 kB/s eta 0:06:05\n",
      "   --- ------------------------------------ 3.9/42.2 MB 105.6 kB/s eta 0:06:03\n",
      "   --- ------------------------------------ 4.0/42.2 MB 105.7 kB/s eta 0:06:03\n",
      "   --- ------------------------------------ 4.0/42.2 MB 105.7 kB/s eta 0:06:03\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.2 kB/s eta 0:06:01\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.4 kB/s eta 0:06:00\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.6 kB/s eta 0:05:59\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.6 kB/s eta 0:05:59\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.6 kB/s eta 0:05:59\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.6 kB/s eta 0:05:59\n",
      "   --- ------------------------------------ 4.0/42.2 MB 106.6 kB/s eta 0:05:59\n",
      "   --- ------------------------------------ 4.0/42.2 MB 107.2 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.0/42.2 MB 107.2 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.5 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.5 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.5 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.5 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.3 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.3 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.3 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.3 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.1/42.2 MB 106.7 kB/s eta 0:05:58\n",
      "   --- ------------------------------------ 4.1/42.2 MB 106.7 kB/s eta 0:05:58\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.0 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.0 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.0 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.1/42.2 MB 107.0 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.1/42.2 MB 106.5 kB/s eta 0:05:58\n",
      "   --- ------------------------------------ 4.1/42.2 MB 106.5 kB/s eta 0:05:58\n",
      "   --- ------------------------------------ 4.1/42.2 MB 106.8 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.1/42.2 MB 106.8 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.1 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.1 kB/s eta 0:05:56\n",
      "   --- ------------------------------------ 4.2/42.2 MB 106.7 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.2/42.2 MB 106.7 kB/s eta 0:05:57\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.5 kB/s eta 0:05:54\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.5 kB/s eta 0:05:54\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.5 kB/s eta 0:05:54\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.5 kB/s eta 0:05:54\n",
      "   --- ------------------------------------ 4.2/42.2 MB 107.9 kB/s eta 0:05:53\n",
      "   ---- ----------------------------------- 4.2/42.2 MB 108.1 kB/s eta 0:05:52\n",
      "   ---- ----------------------------------- 4.2/42.2 MB 108.3 kB/s eta 0:05:51\n",
      "   ---- ----------------------------------- 4.2/42.2 MB 108.3 kB/s eta 0:05:51\n",
      "   ---- ----------------------------------- 4.3/42.2 MB 108.8 kB/s eta 0:05:49\n",
      "   ---- ----------------------------------- 4.3/42.2 MB 109.0 kB/s eta 0:05:49\n",
      "   ---- ----------------------------------- 4.3/42.2 MB 109.5 kB/s eta 0:05:47\n",
      "   ---- ----------------------------------- 4.3/42.2 MB 109.9 kB/s eta 0:05:45\n",
      "   ---- ----------------------------------- 4.3/42.2 MB 109.9 kB/s eta 0:05:45\n",
      "   ---- ----------------------------------- 4.3/42.2 MB 110.4 kB/s eta 0:05:44\n",
      "   ---- ----------------------------------- 4.4/42.2 MB 111.0 kB/s eta 0:05:41\n",
      "   ---- ----------------------------------- 4.4/42.2 MB 111.3 kB/s eta 0:05:40\n",
      "   ---- ----------------------------------- 4.4/42.2 MB 111.8 kB/s eta 0:05:39\n",
      "   ---- ----------------------------------- 4.4/42.2 MB 112.0 kB/s eta 0:05:38\n",
      "   ---- ----------------------------------- 4.4/42.2 MB 113.3 kB/s eta 0:05:34\n",
      "   ---- ----------------------------------- 4.4/42.2 MB 113.5 kB/s eta 0:05:33\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.0 kB/s eta 0:05:32\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.5 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.5 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.5 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.5 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.5 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.5 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.6 kB/s eta 0:05:30\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.7 kB/s eta 0:05:29\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 114.7 kB/s eta 0:05:29\n",
      "   ---- ----------------------------------- 4.5/42.2 MB 115.0 kB/s eta 0:05:28\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 115.6 kB/s eta 0:05:26\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 115.7 kB/s eta 0:05:26\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.5 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 116.4 kB/s eta 0:05:24\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 116.8 kB/s eta 0:05:22\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.3 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.6/42.2 MB 117.3 kB/s eta 0:05:21\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.5 kB/s eta 0:05:17\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.5 kB/s eta 0:05:17\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.5 kB/s eta 0:05:17\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.5 kB/s eta 0:05:17\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.4 kB/s eta 0:05:18\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.4 kB/s eta 0:05:18\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.4 kB/s eta 0:05:17\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 118.4 kB/s eta 0:05:17\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.1 kB/s eta 0:05:15\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.7 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.8 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.8 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.8 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.8 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.7/42.2 MB 119.8 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.4 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.4 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.4 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.4 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.5 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.5 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.5 kB/s eta 0:05:14\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.7 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.7 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 119.7 kB/s eta 0:05:13\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 120.0 kB/s eta 0:05:12\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 120.0 kB/s eta 0:05:12\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.3 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.3 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.3 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.3 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.2 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.2 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.2 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.8/42.2 MB 121.2 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 120.9 kB/s eta 0:05:10\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 120.9 kB/s eta 0:05:10\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 121.1 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 121.1 kB/s eta 0:05:09\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 122.0 kB/s eta 0:05:06\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 122.0 kB/s eta 0:05:06\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 122.0 kB/s eta 0:05:06\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 121.8 kB/s eta 0:05:07\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 121.8 kB/s eta 0:05:07\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 122.0 kB/s eta 0:05:06\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 122.5 kB/s eta 0:05:05\n",
      "   ---- ----------------------------------- 4.9/42.2 MB 122.5 kB/s eta 0:05:05\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 122.8 kB/s eta 0:05:04\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 123.8 kB/s eta 0:05:01\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 123.9 kB/s eta 0:05:01\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 124.3 kB/s eta 0:05:00\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 124.4 kB/s eta 0:04:59\n",
      "   ---- ----------------------------------- 5.0/42.2 MB 124.9 kB/s eta 0:04:58\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 125.3 kB/s eta 0:04:57\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 125.3 kB/s eta 0:04:57\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.1 kB/s eta 0:04:52\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.3 kB/s eta 0:04:52\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.8 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.8 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.8 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.8 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.7 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.7 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.7 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.1/42.2 MB 127.7 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 128.3 kB/s eta 0:04:49\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.3 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.3 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.8 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.5 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.5 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.5 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.2/42.2 MB 127.5 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:51\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ---- ----------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.5 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.8 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.8 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.8 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.7 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.7 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.7 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.7 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.7 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.3 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.3 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.3 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.3 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.3 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.3 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.3/42.2 MB 127.4 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.4 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:52\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 125.9 kB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 125.9 kB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 125.9 kB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 125.9 kB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 125.9 kB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 125.9 kB/s eta 0:04:53\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.5 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.6 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.6 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.6 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.6 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.4/42.2 MB 126.6 kB/s eta 0:04:51\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 126.8 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 126.8 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 126.8 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 126.8 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 126.8 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 126.8 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.2 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.2 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.2 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.2 kB/s eta 0:04:49\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.0 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.0 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.0 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.0 kB/s eta 0:04:50\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.6 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.6 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.6 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.6 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.5 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.5 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.5 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.5/42.2 MB 127.5 kB/s eta 0:04:48\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.0 kB/s eta 0:04:47\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.0 kB/s eta 0:04:47\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.0 kB/s eta 0:04:47\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.0 kB/s eta 0:04:47\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.8 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.8 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.9 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.9 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.9 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.9 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.5 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.5 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 128.5 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 129.8 kB/s eta 0:04:43\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 129.8 kB/s eta 0:04:43\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 130.0 kB/s eta 0:04:42\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 130.0 kB/s eta 0:04:42\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 129.8 kB/s eta 0:04:42\n",
      "   ----- ---------------------------------- 5.6/42.2 MB 129.8 kB/s eta 0:04:42\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 130.3 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 130.3 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.3 kB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.3 kB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.3 kB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.3 kB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.2 kB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.2 kB/s eta 0:04:39\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 131.5 kB/s eta 0:04:38\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 132.3 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 132.3 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 132.3 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 5.7/42.2 MB 132.6 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 132.6 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 133.0 kB/s eta 0:04:35\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 133.0 kB/s eta 0:04:35\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 134.5 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 134.5 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 134.9 kB/s eta 0:04:30\n",
      "   ----- ---------------------------------- 5.8/42.2 MB 134.9 kB/s eta 0:04:30\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 135.4 kB/s eta 0:04:29\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 135.4 kB/s eta 0:04:29\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 135.4 kB/s eta 0:04:29\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 135.4 kB/s eta 0:04:29\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 135.5 kB/s eta 0:04:29\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 135.7 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 136.5 kB/s eta 0:04:26\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 136.5 kB/s eta 0:04:26\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 136.5 kB/s eta 0:04:26\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 136.5 kB/s eta 0:04:26\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 136.5 kB/s eta 0:04:26\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 136.5 kB/s eta 0:04:26\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 137.3 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 5.9/42.2 MB 137.3 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 137.6 kB/s eta 0:04:24\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 137.6 kB/s eta 0:04:24\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 137.6 kB/s eta 0:04:24\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 137.6 kB/s eta 0:04:24\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 138.3 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 138.3 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 138.3 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 138.6 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 139.0 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 139.0 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 139.0 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.0/42.2 MB 139.0 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.4 kB/s eta 0:04:20\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.4 kB/s eta 0:04:20\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.4 kB/s eta 0:04:20\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.4 kB/s eta 0:04:20\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.6 kB/s eta 0:04:19\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.6 kB/s eta 0:04:19\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.6 kB/s eta 0:04:19\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.6 kB/s eta 0:04:19\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 139.6 kB/s eta 0:04:19\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.8 kB/s eta 0:04:21\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.1 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.1 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.1 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 138.1 kB/s eta 0:04:22\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 137.4 kB/s eta 0:04:23\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.1/42.2 MB 136.2 kB/s eta 0:04:25\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 134.6 kB/s eta 0:04:28\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 133.1 kB/s eta 0:04:31\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 130.8 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 130.8 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 130.8 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 130.8 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 130.8 kB/s eta 0:04:36\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.7 kB/s eta 0:04:40\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.7 kB/s eta 0:04:40\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.7 kB/s eta 0:04:40\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.5 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.5 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.5 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.5 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 128.5 kB/s eta 0:04:41\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 126.6 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 126.6 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 126.6 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 126.6 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 126.6 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 126.6 kB/s eta 0:04:45\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.2/42.2 MB 125.9 kB/s eta 0:04:46\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 122.0 kB/s eta 0:04:55\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 122.0 kB/s eta 0:04:55\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 122.0 kB/s eta 0:04:55\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 122.0 kB/s eta 0:04:55\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 121.4 kB/s eta 0:04:57\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 121.4 kB/s eta 0:04:57\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 121.4 kB/s eta 0:04:57\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 121.4 kB/s eta 0:04:57\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.3 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.2 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.2 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.2 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 119.2 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ----- ---------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.3/42.2 MB 118.8 kB/s eta 0:05:02\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.1 kB/s eta 0:05:01\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.1 kB/s eta 0:05:01\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.4 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.4 kB/s eta 0:05:00\n",
      "   ------ --------------------------------- 6.4/42.2 MB 119.8 kB/s eta 0:04:59\n",
      "   ------ --------------------------------- 6.4/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.4/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.4/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.4/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.4/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.1 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.2 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.2 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.2 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.2 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 120.2 kB/s eta 0:04:58\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.2 kB/s eta 0:04:55\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.2 kB/s eta 0:04:55\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.4 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.4 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.5 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.5 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.5 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.5/42.2 MB 121.5 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.6/42.2 MB 121.3 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.6/42.2 MB 121.4 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.6/42.2 MB 121.4 kB/s eta 0:04:54\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.0 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.3 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.3 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.3 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.3 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.5 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.5 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.8 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.6/42.2 MB 122.8 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.7 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.7 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.7 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.7 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.7 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.1 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.1 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.5 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.5 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.5 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.7/42.2 MB 122.5 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.8 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.8 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.8 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.7 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.2 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.2 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.7/42.2 MB 121.2 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.1 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.3 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.3 kB/s eta 0:04:53\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.3 kB/s eta 0:04:52\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.8 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.9 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.8/42.2 MB 121.9 kB/s eta 0:04:51\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.3 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.0 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.0 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.0 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.0 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.0 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 121.9 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 121.9 kB/s eta 0:04:50\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.2 kB/s eta 0:04:49\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.2 kB/s eta 0:04:49\n",
      "   ------ --------------------------------- 6.9/42.2 MB 122.6 kB/s eta 0:04:48\n",
      "   ------ --------------------------------- 7.0/42.2 MB 123.2 kB/s eta 0:04:47\n",
      "   ------ --------------------------------- 7.0/42.2 MB 123.6 kB/s eta 0:04:46\n",
      "   ------ --------------------------------- 7.0/42.2 MB 123.6 kB/s eta 0:04:46\n",
      "   ------ --------------------------------- 7.0/42.2 MB 123.6 kB/s eta 0:04:45\n",
      "   ------ --------------------------------- 7.0/42.2 MB 123.9 kB/s eta 0:04:45\n",
      "   ------ --------------------------------- 7.0/42.2 MB 124.4 kB/s eta 0:04:43\n",
      "   ------ --------------------------------- 7.0/42.2 MB 124.4 kB/s eta 0:04:43\n",
      "   ------ --------------------------------- 7.0/42.2 MB 124.8 kB/s eta 0:04:42\n",
      "   ------ --------------------------------- 7.1/42.2 MB 125.2 kB/s eta 0:04:41\n",
      "   ------ --------------------------------- 7.1/42.2 MB 125.3 kB/s eta 0:04:41\n",
      "   ------ --------------------------------- 7.1/42.2 MB 125.7 kB/s eta 0:04:40\n",
      "   ------ --------------------------------- 7.1/42.2 MB 126.4 kB/s eta 0:04:38\n",
      "   ------ --------------------------------- 7.1/42.2 MB 126.7 kB/s eta 0:04:37\n",
      "   ------ --------------------------------- 7.1/42.2 MB 126.8 kB/s eta 0:04:37\n",
      "   ------ --------------------------------- 7.2/42.2 MB 127.4 kB/s eta 0:04:36\n",
      "   ------ --------------------------------- 7.2/42.2 MB 127.9 kB/s eta 0:04:34\n",
      "   ------ --------------------------------- 7.2/42.2 MB 128.1 kB/s eta 0:04:34\n",
      "   ------ --------------------------------- 7.2/42.2 MB 128.3 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.2/42.2 MB 128.3 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.2/42.2 MB 128.3 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.2/42.2 MB 128.3 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.2/42.2 MB 128.1 kB/s eta 0:04:34\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 128.1 kB/s eta 0:04:33\n",
      "   ------ --------------------------------- 7.3/42.2 MB 125.8 kB/s eta 0:04:38\n",
      "   ------ --------------------------------- 7.3/42.2 MB 125.8 kB/s eta 0:04:38\n",
      "   ------ --------------------------------- 7.3/42.2 MB 125.8 kB/s eta 0:04:38\n",
      "   ------ --------------------------------- 7.3/42.2 MB 126.1 kB/s eta 0:04:37\n",
      "   ------ --------------------------------- 7.3/42.2 MB 126.3 kB/s eta 0:04:37\n",
      "   ------ --------------------------------- 7.3/42.2 MB 126.3 kB/s eta 0:04:37\n",
      "   ------ --------------------------------- 7.3/42.2 MB 126.3 kB/s eta 0:04:37\n",
      "   ------ --------------------------------- 7.3/42.2 MB 126.4 kB/s eta 0:04:36\n",
      "   ------ --------------------------------- 7.3/42.2 MB 126.4 kB/s eta 0:04:36\n",
      "   ------ --------------------------------- 7.4/42.2 MB 126.9 kB/s eta 0:04:35\n",
      "   ------ --------------------------------- 7.4/42.2 MB 126.9 kB/s eta 0:04:35\n",
      "   ------ --------------------------------- 7.4/42.2 MB 126.6 kB/s eta 0:04:36\n",
      "   ------ --------------------------------- 7.4/42.2 MB 126.6 kB/s eta 0:04:36\n",
      "   ------ --------------------------------- 7.4/42.2 MB 126.6 kB/s eta 0:04:36\n",
      "   ------- -------------------------------- 7.4/42.2 MB 126.6 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.4/42.2 MB 126.6 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.0 kB/s eta 0:04:32\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.1 kB/s eta 0:04:32\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.1 kB/s eta 0:04:32\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.5 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.5 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.5 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.4/42.2 MB 128.5 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.1 kB/s eta 0:04:32\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.3 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.3 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.5 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.5 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.5 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.2 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.2 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.2 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.2 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 129.2 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.6 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.6 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.6 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.9 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.9 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.9 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.5/42.2 MB 128.9 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.3 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.3 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.6/42.2 MB 127.8 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 127.8 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.0 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.0 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.0 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.0 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 128.0 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.6/42.2 MB 127.0 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.6/42.2 MB 127.0 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.6/42.2 MB 127.0 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.6/42.2 MB 126.5 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.6/42.2 MB 126.5 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.7 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.7 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.3 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.3 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.3 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.3 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.1 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 125.8 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.7/42.2 MB 125.8 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.1 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.1 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.1 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.1 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.7/42.2 MB 126.1 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.7 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.7 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.7 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.2 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.2 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.2 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.2 kB/s eta 0:04:35\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.5 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.5 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.8/42.2 MB 125.6 kB/s eta 0:04:34\n",
      "   ------- -------------------------------- 7.9/42.2 MB 126.3 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.9/42.2 MB 126.3 kB/s eta 0:04:33\n",
      "   ------- -------------------------------- 7.9/42.2 MB 126.7 kB/s eta 0:04:32\n",
      "   ------- -------------------------------- 7.9/42.2 MB 126.8 kB/s eta 0:04:31\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 7.9/42.2 MB 127.2 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.4 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.4 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.4 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.4 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.6 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.6 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.5 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.0/42.2 MB 127.9 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.0/42.2 MB 128.0 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.1/42.2 MB 128.0 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.1/42.2 MB 127.7 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.1/42.2 MB 127.7 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.1/42.2 MB 128.1 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.1/42.2 MB 128.1 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.1/42.2 MB 128.2 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.1/42.2 MB 128.2 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.1/42.2 MB 128.2 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.2/42.2 MB 127.3 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.2/42.2 MB 127.3 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.4 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.4 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.4 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.2/42.2 MB 126.3 kB/s eta 0:04:30\n",
      "   ------- -------------------------------- 8.3/42.2 MB 126.3 kB/s eta 0:04:29\n",
      "   ------- -------------------------------- 8.3/42.2 MB 126.9 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.3/42.2 MB 126.9 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.3/42.2 MB 126.9 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.3/42.2 MB 127.3 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.3/42.2 MB 126.7 kB/s eta 0:04:28\n",
      "   ------- -------------------------------- 8.3/42.2 MB 127.2 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 126.9 kB/s eta 0:04:27\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.6 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.6 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.6 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.6 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.6 kB/s eta 0:04:26\n",
      "   ------- -------------------------------- 8.4/42.2 MB 127.6 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:25\n",
      "   -------- ------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:25\n",
      "   -------- ------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:25\n",
      "   -------- ------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:25\n",
      "   -------- ------------------------------- 8.4/42.2 MB 127.7 kB/s eta 0:04:25\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.9 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.9 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.9 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 127.0 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 8.5/42.2 MB 127.0 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 8.5/42.2 MB 127.0 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 8.5/42.2 MB 127.0 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 8.5/42.2 MB 127.0 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.7 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.7 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.7 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.7 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.7 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.7 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 126.3 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.5/42.2 MB 125.7 kB/s eta 0:04:28\n",
      "   -------- ------------------------------- 8.5/42.2 MB 125.7 kB/s eta 0:04:28\n",
      "   -------- ------------------------------- 8.5/42.2 MB 125.7 kB/s eta 0:04:28\n",
      "   -------- ------------------------------- 8.5/42.2 MB 125.7 kB/s eta 0:04:28\n",
      "   -------- ------------------------------- 8.5/42.2 MB 125.7 kB/s eta 0:04:28\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 125.5 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.6 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.6 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.6 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.6 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.6 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.3 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.3 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.3 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.3 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 124.3 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.7 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.7 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.7 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.6 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.6 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.4 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.4 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.6/42.2 MB 123.4 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.9 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.9 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.7 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.7 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.7 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.7 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.7 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.7/42.2 MB 122.7 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.7/42.2 MB 121.2 kB/s eta 0:04:37\n",
      "   -------- ------------------------------- 8.7/42.2 MB 121.2 kB/s eta 0:04:37\n",
      "   -------- ------------------------------- 8.7/42.2 MB 120.9 kB/s eta 0:04:38\n",
      "   -------- ------------------------------- 8.7/42.2 MB 120.9 kB/s eta 0:04:38\n",
      "   -------- ------------------------------- 8.7/42.2 MB 120.7 kB/s eta 0:04:38\n",
      "   -------- ------------------------------- 8.7/42.2 MB 120.7 kB/s eta 0:04:38\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.0 kB/s eta 0:04:37\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.4 kB/s eta 0:04:36\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.4 kB/s eta 0:04:36\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.4 kB/s eta 0:04:36\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.6 kB/s eta 0:04:35\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.6 kB/s eta 0:04:35\n",
      "   -------- ------------------------------- 8.8/42.2 MB 121.6 kB/s eta 0:04:35\n",
      "   -------- ------------------------------- 8.8/42.2 MB 122.1 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.8/42.2 MB 122.1 kB/s eta 0:04:34\n",
      "   -------- ------------------------------- 8.8/42.2 MB 122.4 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.8/42.2 MB 122.4 kB/s eta 0:04:33\n",
      "   -------- ------------------------------- 8.9/42.2 MB 122.7 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.9/42.2 MB 122.7 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.9/42.2 MB 122.9 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.9/42.2 MB 122.9 kB/s eta 0:04:32\n",
      "   -------- ------------------------------- 8.9/42.2 MB 123.3 kB/s eta 0:04:31\n",
      "   -------- ------------------------------- 8.9/42.2 MB 124.1 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.9/42.2 MB 124.1 kB/s eta 0:04:29\n",
      "   -------- ------------------------------- 8.9/42.2 MB 124.5 kB/s eta 0:04:28\n",
      "   -------- ------------------------------- 8.9/42.2 MB 124.9 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.9/42.2 MB 124.9 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 8.9/42.2 MB 125.0 kB/s eta 0:04:27\n",
      "   -------- ------------------------------- 9.0/42.2 MB 125.4 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 9.0/42.2 MB 125.4 kB/s eta 0:04:26\n",
      "   -------- ------------------------------- 9.0/42.2 MB 125.9 kB/s eta 0:04:24\n",
      "   -------- ------------------------------- 9.0/42.2 MB 125.9 kB/s eta 0:04:24\n",
      "   -------- ------------------------------- 9.0/42.2 MB 126.3 kB/s eta 0:04:23\n",
      "   -------- ------------------------------- 9.0/42.2 MB 126.8 kB/s eta 0:04:22\n",
      "   -------- ------------------------------- 9.1/42.2 MB 127.4 kB/s eta 0:04:21\n",
      "   -------- ------------------------------- 9.1/42.2 MB 127.5 kB/s eta 0:04:20\n",
      "   -------- ------------------------------- 9.1/42.2 MB 128.0 kB/s eta 0:04:19\n",
      "   -------- ------------------------------- 9.1/42.2 MB 128.9 kB/s eta 0:04:17\n",
      "   -------- ------------------------------- 9.1/42.2 MB 129.1 kB/s eta 0:04:17\n",
      "   -------- ------------------------------- 9.1/42.2 MB 129.6 kB/s eta 0:04:16\n",
      "   -------- ------------------------------- 9.1/42.2 MB 129.8 kB/s eta 0:04:15\n",
      "   -------- ------------------------------- 9.2/42.2 MB 130.2 kB/s eta 0:04:14\n",
      "   -------- ------------------------------- 9.2/42.2 MB 131.3 kB/s eta 0:04:12\n",
      "   -------- ------------------------------- 9.2/42.2 MB 131.8 kB/s eta 0:04:11\n",
      "   -------- ------------------------------- 9.2/42.2 MB 132.0 kB/s eta 0:04:10\n",
      "   -------- ------------------------------- 9.2/42.2 MB 132.5 kB/s eta 0:04:09\n",
      "   -------- ------------------------------- 9.3/42.2 MB 133.2 kB/s eta 0:04:08\n",
      "   -------- ------------------------------- 9.3/42.2 MB 133.9 kB/s eta 0:04:06\n",
      "   -------- ------------------------------- 9.3/42.2 MB 134.3 kB/s eta 0:04:05\n",
      "   -------- ------------------------------- 9.4/42.2 MB 135.0 kB/s eta 0:04:04\n",
      "   -------- ------------------------------- 9.4/42.2 MB 136.6 kB/s eta 0:04:01\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.1 kB/s eta 0:04:00\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.1 kB/s eta 0:04:00\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.1 kB/s eta 0:04:00\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.1 kB/s eta 0:04:00\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.3 kB/s eta 0:03:59\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.3 kB/s eta 0:03:59\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.3 kB/s eta 0:03:59\n",
      "   -------- ------------------------------- 9.4/42.2 MB 137.3 kB/s eta 0:03:59\n",
      "   -------- ------------------------------- 9.5/42.2 MB 138.3 kB/s eta 0:03:57\n",
      "   -------- ------------------------------- 9.5/42.2 MB 138.3 kB/s eta 0:03:57\n",
      "   -------- ------------------------------- 9.5/42.2 MB 138.6 kB/s eta 0:03:57\n",
      "   --------- ------------------------------ 9.5/42.2 MB 139.0 kB/s eta 0:03:56\n",
      "   --------- ------------------------------ 9.5/42.2 MB 139.0 kB/s eta 0:03:56\n",
      "   --------- ------------------------------ 9.5/42.2 MB 140.4 kB/s eta 0:03:53\n",
      "   --------- ------------------------------ 9.5/42.2 MB 140.8 kB/s eta 0:03:53\n",
      "   --------- ------------------------------ 9.5/42.2 MB 140.8 kB/s eta 0:03:53\n",
      "   --------- ------------------------------ 9.6/42.2 MB 140.8 kB/s eta 0:03:53\n",
      "   --------- ------------------------------ 9.6/42.2 MB 141.1 kB/s eta 0:03:52\n",
      "   --------- ------------------------------ 9.6/42.2 MB 141.6 kB/s eta 0:03:51\n",
      "   --------- ------------------------------ 9.6/42.2 MB 141.6 kB/s eta 0:03:51\n",
      "   --------- ------------------------------ 9.6/42.2 MB 141.7 kB/s eta 0:03:51\n",
      "   --------- ------------------------------ 9.6/42.2 MB 143.1 kB/s eta 0:03:48\n",
      "   --------- ------------------------------ 9.6/42.2 MB 143.2 kB/s eta 0:03:48\n",
      "   --------- ------------------------------ 9.7/42.2 MB 144.1 kB/s eta 0:03:46\n",
      "   --------- ------------------------------ 9.7/42.2 MB 144.2 kB/s eta 0:03:46\n",
      "   --------- ------------------------------ 9.7/42.2 MB 144.7 kB/s eta 0:03:45\n",
      "   --------- ------------------------------ 9.7/42.2 MB 144.8 kB/s eta 0:03:45\n",
      "   --------- ------------------------------ 9.8/42.2 MB 146.1 kB/s eta 0:03:43\n",
      "   --------- ------------------------------ 9.8/42.2 MB 146.1 kB/s eta 0:03:43\n",
      "   --------- ------------------------------ 9.8/42.2 MB 146.1 kB/s eta 0:03:43\n",
      "   --------- ------------------------------ 9.8/42.2 MB 146.1 kB/s eta 0:03:43\n",
      "   --------- ------------------------------ 9.8/42.2 MB 147.4 kB/s eta 0:03:40\n",
      "   --------- ------------------------------ 9.8/42.2 MB 147.8 kB/s eta 0:03:40\n",
      "   --------- ------------------------------ 9.8/42.2 MB 148.2 kB/s eta 0:03:39\n",
      "   --------- ------------------------------ 9.9/42.2 MB 148.2 kB/s eta 0:03:39\n",
      "   --------- ------------------------------ 9.9/42.2 MB 148.8 kB/s eta 0:03:38\n",
      "   --------- ------------------------------ 9.9/42.2 MB 148.8 kB/s eta 0:03:38\n",
      "   --------- ------------------------------ 9.9/42.2 MB 148.8 kB/s eta 0:03:38\n",
      "   --------- ------------------------------ 9.9/42.2 MB 148.8 kB/s eta 0:03:38\n",
      "   --------- ------------------------------ 9.9/42.2 MB 149.1 kB/s eta 0:03:37\n",
      "   --------- ------------------------------ 9.9/42.2 MB 149.1 kB/s eta 0:03:37\n",
      "   --------- ------------------------------ 9.9/42.2 MB 149.5 kB/s eta 0:03:36\n",
      "   --------- ------------------------------ 9.9/42.2 MB 150.0 kB/s eta 0:03:36\n",
      "   --------- ------------------------------ 9.9/42.2 MB 150.0 kB/s eta 0:03:36\n",
      "   --------- ------------------------------ 10.0/42.2 MB 150.4 kB/s eta 0:03:35\n",
      "   --------- ------------------------------ 10.0/42.2 MB 150.4 kB/s eta 0:03:35\n",
      "   --------- ------------------------------ 10.0/42.2 MB 150.4 kB/s eta 0:03:35\n",
      "   --------- ------------------------------ 10.0/42.2 MB 151.5 kB/s eta 0:03:33\n",
      "   --------- ------------------------------ 10.0/42.2 MB 151.9 kB/s eta 0:03:33\n",
      "   --------- ------------------------------ 10.0/42.2 MB 151.9 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 152.3 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 152.3 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 152.3 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 152.3 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 152.3 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 152.3 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.0/42.2 MB 151.9 kB/s eta 0:03:32\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.4 kB/s eta 0:03:31\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.4 kB/s eta 0:03:31\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.7 kB/s eta 0:03:31\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.7 kB/s eta 0:03:31\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.2 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.2 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.2 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.2 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.4 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.4 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.4 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.4 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.9 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.9 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 152.9 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.0 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.0 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.1/42.2 MB 153.0 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.3 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.3 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.3 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 152.9 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 152.9 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.2/42.2 MB 152.9 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.2/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.5 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.5 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.3/42.2 MB 153.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.4/42.2 MB 153.4 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 153.4 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 153.1 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.4/42.2 MB 153.0 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.9 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.9 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.9 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.9 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.4 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.9 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.4/42.2 MB 152.9 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.2 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.6 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.6 kB/s eta 0:03:28\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 152.3 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 151.8 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 151.8 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 151.8 kB/s eta 0:03:29\n",
      "   --------- ------------------------------ 10.5/42.2 MB 151.2 kB/s eta 0:03:30\n",
      "   --------- ------------------------------ 10.5/42.2 MB 151.2 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 150.9 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 150.9 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 150.9 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.5 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.5 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.5 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.5 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.3 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.3 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.3 kB/s eta 0:03:30\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.8 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.8 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.7 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.7 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 151.7 kB/s eta 0:03:29\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.6/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.0 kB/s eta 0:03:25\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.0 kB/s eta 0:03:25\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.8 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.5 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.5 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.4 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 153.4 kB/s eta 0:03:26\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.4 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.4 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.6 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.6 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.6 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.6 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.7/42.2 MB 154.6 kB/s eta 0:03:24\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.6 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.6 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.6 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.6 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.6 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.4 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.4 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.4 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 155.4 kB/s eta 0:03:23\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 156.5 kB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 156.5 kB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 10.8/42.2 MB 156.5 kB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 156.7 kB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 156.7 kB/s eta 0:03:21\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.1 kB/s eta 0:03:19\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.1 kB/s eta 0:03:19\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.4 kB/s eta 0:03:18\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.4 kB/s eta 0:03:18\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.4 kB/s eta 0:03:18\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.4 kB/s eta 0:03:18\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.0 kB/s eta 0:03:19\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.0 kB/s eta 0:03:19\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.0 kB/s eta 0:03:19\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.0 kB/s eta 0:03:19\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.9 kB/s eta 0:03:17\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.9 kB/s eta 0:03:17\n",
      "   ---------- ----------------------------- 10.9/42.2 MB 158.7 kB/s eta 0:03:18\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 159.1 kB/s eta 0:03:17\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 159.1 kB/s eta 0:03:17\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 159.4 kB/s eta 0:03:16\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 159.4 kB/s eta 0:03:16\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 160.2 kB/s eta 0:03:15\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 160.2 kB/s eta 0:03:15\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 160.2 kB/s eta 0:03:15\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 160.2 kB/s eta 0:03:15\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 160.7 kB/s eta 0:03:15\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 161.0 kB/s eta 0:03:14\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 161.0 kB/s eta 0:03:14\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 161.1 kB/s eta 0:03:14\n",
      "   ---------- ----------------------------- 11.0/42.2 MB 161.1 kB/s eta 0:03:14\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 161.2 kB/s eta 0:03:14\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 161.2 kB/s eta 0:03:14\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 163.7 kB/s eta 0:03:11\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 163.7 kB/s eta 0:03:11\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 164.1 kB/s eta 0:03:10\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 163.9 kB/s eta 0:03:10\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 164.2 kB/s eta 0:03:10\n",
      "   ---------- ----------------------------- 11.1/42.2 MB 164.2 kB/s eta 0:03:10\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 164.5 kB/s eta 0:03:09\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 164.4 kB/s eta 0:03:09\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 164.4 kB/s eta 0:03:09\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 164.8 kB/s eta 0:03:09\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 164.9 kB/s eta 0:03:09\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.2 kB/s eta 0:03:08\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.7 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.7 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.8 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.8 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.8 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.2/42.2 MB 165.8 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 166.2 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 166.2 kB/s eta 0:03:07\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 168.0 kB/s eta 0:03:05\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 168.2 kB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 168.2 kB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 168.2 kB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 11.3/42.2 MB 168.5 kB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 168.5 kB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 168.5 kB/s eta 0:03:04\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 169.1 kB/s eta 0:03:03\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 169.5 kB/s eta 0:03:02\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 169.5 kB/s eta 0:03:02\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 170.5 kB/s eta 0:03:01\n",
      "   ---------- ----------------------------- 11.4/42.2 MB 170.6 kB/s eta 0:03:01\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 170.9 kB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 171.3 kB/s eta 0:03:00\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 172.8 kB/s eta 0:02:58\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 173.1 kB/s eta 0:02:58\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 173.2 kB/s eta 0:02:58\n",
      "   ---------- ----------------------------- 11.5/42.2 MB 173.7 kB/s eta 0:02:57\n",
      "   ---------- ----------------------------- 11.6/42.2 MB 174.0 kB/s eta 0:02:57\n",
      "   ---------- ----------------------------- 11.6/42.2 MB 174.1 kB/s eta 0:02:57\n",
      "   ---------- ----------------------------- 11.6/42.2 MB 174.6 kB/s eta 0:02:56\n",
      "   ---------- ----------------------------- 11.6/42.2 MB 174.7 kB/s eta 0:02:56\n",
      "   ----------- ---------------------------- 11.6/42.2 MB 175.2 kB/s eta 0:02:55\n",
      "   ----------- ---------------------------- 11.7/42.2 MB 176.5 kB/s eta 0:02:54\n",
      "   ----------- ---------------------------- 11.7/42.2 MB 177.0 kB/s eta 0:02:53\n",
      "   ----------- ---------------------------- 11.7/42.2 MB 177.0 kB/s eta 0:02:53\n",
      "   ----------- ---------------------------- 11.7/42.2 MB 177.5 kB/s eta 0:02:52\n",
      "   ----------- ---------------------------- 11.7/42.2 MB 178.2 kB/s eta 0:02:52\n",
      "   ----------- ---------------------------- 11.8/42.2 MB 178.8 kB/s eta 0:02:51\n",
      "   ----------- ---------------------------- 11.8/42.2 MB 179.0 kB/s eta 0:02:51\n",
      "   ----------- ---------------------------- 11.8/42.2 MB 180.0 kB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 11.8/42.2 MB 180.4 kB/s eta 0:02:49\n",
      "   ----------- ---------------------------- 11.8/42.2 MB 181.1 kB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 11.9/42.2 MB 181.6 kB/s eta 0:02:48\n",
      "   ----------- ---------------------------- 11.9/42.2 MB 183.2 kB/s eta 0:02:46\n",
      "   ----------- ---------------------------- 11.9/42.2 MB 183.7 kB/s eta 0:02:45\n",
      "   ----------- ---------------------------- 12.0/42.2 MB 184.3 kB/s eta 0:02:45\n",
      "   ----------- ---------------------------- 12.0/42.2 MB 185.0 kB/s eta 0:02:44\n",
      "   ----------- ---------------------------- 12.0/42.2 MB 185.4 kB/s eta 0:02:43\n",
      "   ----------- ---------------------------- 12.0/42.2 MB 186.1 kB/s eta 0:02:43\n",
      "   ----------- ---------------------------- 12.1/42.2 MB 186.6 kB/s eta 0:02:42\n",
      "   ----------- ---------------------------- 12.1/42.2 MB 187.7 kB/s eta 0:02:41\n",
      "   ----------- ---------------------------- 12.1/42.2 MB 188.5 kB/s eta 0:02:40\n",
      "   ----------- ---------------------------- 12.1/42.2 MB 189.1 kB/s eta 0:02:40\n",
      "   ----------- ---------------------------- 12.2/42.2 MB 190.0 kB/s eta 0:02:39\n",
      "   ----------- ---------------------------- 12.2/42.2 MB 191.1 kB/s eta 0:02:38\n",
      "   ----------- ---------------------------- 12.2/42.2 MB 191.8 kB/s eta 0:02:37\n",
      "   ----------- ---------------------------- 12.2/42.2 MB 191.8 kB/s eta 0:02:37\n",
      "   ----------- ---------------------------- 12.2/42.2 MB 191.8 kB/s eta 0:02:37\n",
      "   ----------- ---------------------------- 12.2/42.2 MB 191.8 kB/s eta 0:02:37\n",
      "   ----------- ---------------------------- 12.3/42.2 MB 191.4 kB/s eta 0:02:37\n",
      "   ----------- ---------------------------- 12.3/42.2 MB 192.5 kB/s eta 0:02:36\n",
      "   ----------- ---------------------------- 12.3/42.2 MB 193.5 kB/s eta 0:02:35\n",
      "   ----------- ---------------------------- 12.3/42.2 MB 194.0 kB/s eta 0:02:34\n",
      "   ----------- ---------------------------- 12.4/42.2 MB 194.1 kB/s eta 0:02:34\n",
      "   ----------- ---------------------------- 12.4/42.2 MB 195.0 kB/s eta 0:02:33\n",
      "   ----------- ---------------------------- 12.4/42.2 MB 194.9 kB/s eta 0:02:33\n",
      "   ----------- ---------------------------- 12.4/42.2 MB 195.3 kB/s eta 0:02:33\n",
      "   ----------- ---------------------------- 12.5/42.2 MB 196.2 kB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 12.5/42.2 MB 196.7 kB/s eta 0:02:32\n",
      "   ----------- ---------------------------- 12.5/42.2 MB 197.3 kB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 12.5/42.2 MB 197.4 kB/s eta 0:02:31\n",
      "   ----------- ---------------------------- 12.6/42.2 MB 199.0 kB/s eta 0:02:29\n",
      "   ----------- ---------------------------- 12.6/42.2 MB 198.9 kB/s eta 0:02:29\n",
      "   ----------- ---------------------------- 12.6/42.2 MB 199.7 kB/s eta 0:02:29\n",
      "   ----------- ---------------------------- 12.6/42.2 MB 199.7 kB/s eta 0:02:29\n",
      "   ----------- ---------------------------- 12.6/42.2 MB 199.7 kB/s eta 0:02:29\n",
      "   ----------- ---------------------------- 12.6/42.2 MB 199.7 kB/s eta 0:02:29\n",
      "   ------------ --------------------------- 12.7/42.2 MB 201.0 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 12.7/42.2 MB 201.0 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.8 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.8 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.8 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.3 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.7/42.2 MB 202.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.8/42.2 MB 202.8 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.8/42.2 MB 202.8 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.8/42.2 MB 202.9 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.8/42.2 MB 202.9 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 12.8/42.2 MB 203.4 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 12.8/42.2 MB 203.3 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 12.8/42.2 MB 203.3 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 12.8/42.2 MB 203.5 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 12.9/42.2 MB 203.8 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 12.9/42.2 MB 203.8 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 12.9/42.2 MB 203.9 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 12.9/42.2 MB 204.2 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 12.9/42.2 MB 204.0 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 12.9/42.2 MB 204.0 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 12.9/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 12.9/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 12.9/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 203.5 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 203.5 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 203.4 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 203.4 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 204.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.0/42.2 MB 202.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.0/42.2 MB 202.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.0/42.2 MB 202.3 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.0/42.2 MB 202.3 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.0/42.2 MB 202.4 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.0/42.2 MB 202.4 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 202.4 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 202.4 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 201.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 201.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 201.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 201.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 201.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 201.7 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.1/42.2 MB 199.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.1/42.2 MB 199.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.1/42.2 MB 199.5 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.1/42.2 MB 199.5 kB/s eta 0:02:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ------------ --------------------------- 13.1/42.2 MB 198.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.1/42.2 MB 198.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.1/42.2 MB 198.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.1/42.2 MB 198.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.1/42.2 MB 197.8 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.1/42.2 MB 197.8 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.1/42.2 MB 197.8 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.1/42.2 MB 197.8 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.1/42.2 MB 196.4 kB/s eta 0:02:29\n",
      "   ------------ --------------------------- 13.1/42.2 MB 196.4 kB/s eta 0:02:29\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.4 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.4 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.4 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.4 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.4 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.4 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 196.8 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.3 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.3 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.2/42.2 MB 197.3 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.2/42.2 MB 196.6 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.7 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.7 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.5 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.5 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.5 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.5 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.5 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 196.5 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.6 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.6 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.6 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.9 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.9 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.3/42.2 MB 195.2 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.4/42.2 MB 195.7 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.4/42.2 MB 195.7 kB/s eta 0:02:28\n",
      "   ------------ --------------------------- 13.4/42.2 MB 197.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 197.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 197.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 197.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 197.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 197.1 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 196.2 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 196.4 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 196.4 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 196.4 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 196.4 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.4/42.2 MB 196.4 kB/s eta 0:02:27\n",
      "   ------------ --------------------------- 13.5/42.2 MB 196.9 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 196.9 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 196.9 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.1 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.1 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.2 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.2 kB/s eta 0:02:26\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.9 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.9 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.5/42.2 MB 197.9 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.6/42.2 MB 198.1 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.6/42.2 MB 198.6 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.6/42.2 MB 198.5 kB/s eta 0:02:25\n",
      "   ------------ --------------------------- 13.6/42.2 MB 199.0 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.6/42.2 MB 199.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.6/42.2 MB 199.3 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.6/42.2 MB 199.6 kB/s eta 0:02:24\n",
      "   ------------ --------------------------- 13.7/42.2 MB 200.0 kB/s eta 0:02:23\n",
      "   ------------ --------------------------- 13.7/42.2 MB 200.1 kB/s eta 0:02:23\n",
      "   ------------ --------------------------- 13.7/42.2 MB 200.5 kB/s eta 0:02:23\n",
      "   ------------- -------------------------- 13.7/42.2 MB 200.8 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.7/42.2 MB 200.9 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.7/42.2 MB 200.9 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.7/42.2 MB 200.9 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.8/42.2 MB 202.0 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 201.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 202.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 202.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 202.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 202.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 202.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 201.4 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.8/42.2 MB 201.4 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.1 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.7 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.7 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.5 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.5 kB/s eta 0:02:22\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 201.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.7 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 13.9/42.2 MB 200.7 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.5 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.7 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.7 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.0/42.2 MB 200.9 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 199.7 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 200.0 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 199.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 199.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 199.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 199.8 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.1/42.2 MB 200.1 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.4 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.2 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.2 kB/s eta 0:02:21\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.6 kB/s eta 0:02:20\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.2 kB/s eta 0:02:20\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.1 kB/s eta 0:02:20\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.5 kB/s eta 0:02:20\n",
      "   ------------- -------------------------- 14.2/42.2 MB 200.5 kB/s eta 0:02:20\n",
      "   ------------- -------------------------- 14.2/42.2 MB 201.2 kB/s eta 0:02:20\n",
      "   ------------- -------------------------- 14.3/42.2 MB 201.4 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.3/42.2 MB 201.4 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.3/42.2 MB 201.8 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.3/42.2 MB 201.1 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.3/42.2 MB 201.1 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.3/42.2 MB 201.6 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.4/42.2 MB 201.7 kB/s eta 0:02:19\n",
      "   ------------- -------------------------- 14.4/42.2 MB 201.8 kB/s eta 0:02:18\n",
      "   ------------- -------------------------- 14.4/42.2 MB 201.8 kB/s eta 0:02:18\n",
      "   ------------- -------------------------- 14.4/42.2 MB 202.9 kB/s eta 0:02:17\n",
      "   ------------- -------------------------- 14.4/42.2 MB 202.9 kB/s eta 0:02:17\n",
      "   ------------- -------------------------- 14.5/42.2 MB 203.3 kB/s eta 0:02:17\n",
      "   ------------- -------------------------- 14.5/42.2 MB 203.9 kB/s eta 0:02:16\n",
      "   ------------- -------------------------- 14.5/42.2 MB 204.0 kB/s eta 0:02:16\n",
      "   ------------- -------------------------- 14.5/42.2 MB 204.5 kB/s eta 0:02:16\n",
      "   ------------- -------------------------- 14.6/42.2 MB 206.1 kB/s eta 0:02:15\n",
      "   ------------- -------------------------- 14.6/42.2 MB 206.1 kB/s eta 0:02:15\n",
      "   ------------- -------------------------- 14.6/42.2 MB 206.1 kB/s eta 0:02:15\n",
      "   ------------- -------------------------- 14.6/42.2 MB 206.1 kB/s eta 0:02:15\n",
      "   ------------- -------------------------- 14.6/42.2 MB 205.5 kB/s eta 0:02:15\n",
      "   ------------- -------------------------- 14.6/42.2 MB 206.7 kB/s eta 0:02:14\n",
      "   ------------- -------------------------- 14.6/42.2 MB 207.0 kB/s eta 0:02:14\n",
      "   ------------- -------------------------- 14.7/42.2 MB 207.0 kB/s eta 0:02:14\n",
      "   ------------- -------------------------- 14.7/42.2 MB 207.4 kB/s eta 0:02:13\n",
      "   ------------- -------------------------- 14.7/42.2 MB 207.8 kB/s eta 0:02:13\n",
      "   ------------- -------------------------- 14.7/42.2 MB 208.3 kB/s eta 0:02:13\n",
      "   ------------- -------------------------- 14.7/42.2 MB 208.7 kB/s eta 0:02:12\n",
      "   ------------- -------------------------- 14.7/42.2 MB 209.8 kB/s eta 0:02:11\n",
      "   ------------- -------------------------- 14.8/42.2 MB 210.2 kB/s eta 0:02:11\n",
      "   -------------- ------------------------- 14.8/42.2 MB 210.7 kB/s eta 0:02:11\n",
      "   -------------- ------------------------- 14.8/42.2 MB 211.2 kB/s eta 0:02:10\n",
      "   -------------- ------------------------- 14.8/42.2 MB 211.2 kB/s eta 0:02:10\n",
      "   -------------- ------------------------- 14.8/42.2 MB 211.6 kB/s eta 0:02:10\n",
      "   -------------- ------------------------- 14.9/42.2 MB 213.6 kB/s eta 0:02:09\n",
      "   -------------- ------------------------- 14.9/42.2 MB 214.1 kB/s eta 0:02:08\n",
      "   -------------- ------------------------- 14.9/42.2 MB 214.2 kB/s eta 0:02:08\n",
      "   -------------- ------------------------- 14.9/42.2 MB 214.6 kB/s eta 0:02:08\n",
      "   -------------- ------------------------- 15.0/42.2 MB 215.0 kB/s eta 0:02:07\n",
      "   -------------- ------------------------- 15.0/42.2 MB 216.5 kB/s eta 0:02:06\n",
      "   -------------- ------------------------- 15.0/42.2 MB 216.6 kB/s eta 0:02:06\n",
      "   -------------- ------------------------- 15.0/42.2 MB 217.2 kB/s eta 0:02:06\n",
      "   -------------- ------------------------- 15.0/42.2 MB 217.5 kB/s eta 0:02:05\n",
      "   -------------- ------------------------- 15.1/42.2 MB 218.1 kB/s eta 0:02:05\n",
      "   -------------- ------------------------- 15.1/42.2 MB 219.9 kB/s eta 0:02:04\n",
      "   -------------- ------------------------- 15.1/42.2 MB 220.6 kB/s eta 0:02:03\n",
      "   -------------- ------------------------- 15.1/42.2 MB 221.1 kB/s eta 0:02:03\n",
      "   -------------- ------------------------- 15.2/42.2 MB 221.5 kB/s eta 0:02:03\n",
      "   -------------- ------------------------- 15.2/42.2 MB 222.0 kB/s eta 0:02:02\n",
      "   -------------- ------------------------- 15.2/42.2 MB 222.5 kB/s eta 0:02:02\n",
      "   -------------- ------------------------- 15.2/42.2 MB 224.2 kB/s eta 0:02:01\n",
      "   -------------- ------------------------- 15.3/42.2 MB 224.9 kB/s eta 0:02:00\n",
      "   -------------- ------------------------- 15.3/42.2 MB 225.3 kB/s eta 0:02:00\n",
      "   -------------- ------------------------- 15.3/42.2 MB 226.0 kB/s eta 0:02:00\n",
      "   -------------- ------------------------- 15.3/42.2 MB 228.7 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.3/42.2 MB 228.7 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.3/42.2 MB 228.7 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.3/42.2 MB 228.7 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.0 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.0 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.0 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.0 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.0 kB/s eta 0:01:58\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.4/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.8 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.8 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.8 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.8 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.3 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.3 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.3 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.3 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.1 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.5 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.4 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.4 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.4 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.5/42.2 MB 229.4 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.0 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.0 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 229.1 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.6/42.2 MB 229.4 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 229.4 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 229.4 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.6/42.2 MB 229.2 kB/s eta 0:01:57\n",
      "   -------------- ------------------------- 15.6/42.2 MB 229.3 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 229.4 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 229.4 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.0 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.0 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.1 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.1 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 229.7 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.2 kB/s eta 0:01:56\n",
      "   -------------- ------------------------- 15.7/42.2 MB 230.3 kB/s eta 0:01:55\n",
      "   -------------- ------------------------- 15.8/42.2 MB 230.3 kB/s eta 0:01:55\n",
      "   -------------- ------------------------- 15.8/42.2 MB 230.5 kB/s eta 0:01:55\n",
      "   -------------- ------------------------- 15.8/42.2 MB 230.6 kB/s eta 0:01:55\n",
      "   -------------- ------------------------- 15.8/42.2 MB 230.6 kB/s eta 0:01:55\n",
      "   -------------- ------------------------- 15.8/42.2 MB 230.6 kB/s eta 0:01:55\n",
      "   -------------- ------------------------- 15.8/42.2 MB 230.6 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.8/42.2 MB 230.4 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.8/42.2 MB 230.4 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.8/42.2 MB 229.8 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.9/42.2 MB 229.8 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.9/42.2 MB 230.2 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.9/42.2 MB 230.2 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.9/42.2 MB 230.2 kB/s eta 0:01:55\n",
      "   --------------- ------------------------ 15.9/42.2 MB 228.7 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 228.7 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 227.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 227.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 228.0 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 228.0 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 227.0 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 226.8 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 15.9/42.2 MB 226.8 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.0/42.2 MB 226.1 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 226.1 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 225.7 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 225.4 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 225.4 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 224.3 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 224.6 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.0/42.2 MB 223.9 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.6 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.6 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.6 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.6 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.1 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.1 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.1 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.1 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.1/42.2 MB 223.2 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.9 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.9 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.9 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 223.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.8 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.8 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.8 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.8 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.8 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.0 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.2/42.2 MB 222.1 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.8 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.8 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.4 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.4 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 221.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 219.8 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 219.8 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 219.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.3/42.2 MB 219.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.4/42.2 MB 219.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.4/42.2 MB 219.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.6 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.5 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.4/42.2 MB 218.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.4/42.2 MB 217.4 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 217.4 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.4/42.2 MB 217.4 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 217.4 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 217.4 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 217.1 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 217.1 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 216.9 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 216.9 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 216.7 kB/s eta 0:01:59\n",
      "   --------------- ------------------------ 16.5/42.2 MB 218.4 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.6/42.2 MB 218.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.6/42.2 MB 218.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.6/42.2 MB 218.4 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.6/42.2 MB 218.7 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.6/42.2 MB 218.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.6/42.2 MB 218.8 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.1 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.6 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.9 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 220.1 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 220.1 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 220.1 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 220.1 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 220.1 kB/s eta 0:01:56\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.7/42.2 MB 219.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.2 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.2 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.2 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.2 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 218.0 kB/s eta 0:01:57\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.7 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.7 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.7 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.7 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.6 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.3 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.3 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.8/42.2 MB 216.3 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.9/42.2 MB 216.1 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.9/42.2 MB 216.2 kB/s eta 0:01:58\n",
      "   --------------- ------------------------ 16.9/42.2 MB 216.2 kB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 16.9/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 16.9/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 16.9/42.2 MB 216.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 16.9/42.2 MB 217.1 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 16.9/42.2 MB 216.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 16.9/42.2 MB 216.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.4 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 217.0 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 215.8 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 215.8 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 215.8 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 215.8 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.0/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.5 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.5 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 215.7 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.2 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.1 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.1 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.1/42.2 MB 216.1 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 215.4 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 215.4 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.1 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.1 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 215.6 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 215.6 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.3 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.3 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.2/42.2 MB 215.7 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.1 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.1 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.3 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.3 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.1 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.1 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.3/42.2 MB 216.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 216.5 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 216.5 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 216.5 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 216.5 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 216.5 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.0 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.0 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 214.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 214.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 214.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.7 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.4/42.2 MB 215.7 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.8 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.8 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.1 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.5/42.2 MB 215.4 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 215.6 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 215.6 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 215.8 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 215.9 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 215.9 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 216.1 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 216.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 216.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 216.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.6/42.2 MB 216.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.6 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.6 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 214.7 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 214.7 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 214.7 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 214.7 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 215.2 kB/s eta 0:01:54\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 213.1 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 213.1 kB/s eta 0:01:55\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 212.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 212.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 212.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 212.4 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 211.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.7/42.2 MB 211.5 kB/s eta 0:01:56\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 210.6 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 210.6 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 210.4 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 210.4 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 210.4 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 210.1 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 209.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 209.3 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 208.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 208.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 208.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 208.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 208.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.8/42.2 MB 208.9 kB/s eta 0:01:57\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 206.6 kB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 206.5 kB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 206.5 kB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 206.5 kB/s eta 0:01:58\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 205.2 kB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 205.2 kB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 204.2 kB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 204.2 kB/s eta 0:01:59\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 202.9 kB/s eta 0:02:00\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 202.9 kB/s eta 0:02:00\n",
      "   ---------------- ----------------------- 17.9/42.2 MB 202.9 kB/s eta 0:02:00\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 200.7 kB/s eta 0:02:01\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 200.7 kB/s eta 0:02:01\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 199.2 kB/s eta 0:02:02\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 199.2 kB/s eta 0:02:02\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 198.0 kB/s eta 0:02:03\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 198.0 kB/s eta 0:02:03\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 196.9 kB/s eta 0:02:03\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 196.9 kB/s eta 0:02:03\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 195.7 kB/s eta 0:02:04\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 195.7 kB/s eta 0:02:04\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 195.7 kB/s eta 0:02:04\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 195.7 kB/s eta 0:02:04\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 193.4 kB/s eta 0:02:06\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 193.6 kB/s eta 0:02:05\n",
      "   ----------------- ---------------------- 18.0/42.2 MB 193.6 kB/s eta 0:02:05\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 193.2 kB/s eta 0:02:06\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 193.5 kB/s eta 0:02:05\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 193.5 kB/s eta 0:02:05\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 193.5 kB/s eta 0:02:05\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 193.5 kB/s eta 0:02:05\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 189.9 kB/s eta 0:02:08\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 189.9 kB/s eta 0:02:08\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 189.9 kB/s eta 0:02:08\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 187.5 kB/s eta 0:02:09\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 187.5 kB/s eta 0:02:09\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 187.5 kB/s eta 0:02:09\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 187.5 kB/s eta 0:02:09\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.7 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.7 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.7 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.7 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.0 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.0 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.0 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.0 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 184.0 kB/s eta 0:02:11\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 181.3 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 181.3 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 181.3 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.1/42.2 MB 181.3 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 181.0 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 181.0 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 181.0 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 181.0 kB/s eta 0:02:13\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.9 kB/s eta 0:02:14\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.9 kB/s eta 0:02:14\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.9 kB/s eta 0:02:14\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.9 kB/s eta 0:02:14\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 179.1 kB/s eta 0:02:15\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 176.5 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 176.5 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 176.5 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 176.5 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 176.5 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 174.9 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 174.9 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 174.9 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 174.9 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 175.4 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 175.4 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.2/42.2 MB 175.4 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 174.9 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 174.9 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 174.9 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 174.9 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 174.9 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 174.9 kB/s eta 0:02:17\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.5 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.4 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.1 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.1 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.3/42.2 MB 173.1 kB/s eta 0:02:18\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.4 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.4 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.4 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.2 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.2 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.2 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.2 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 172.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.7 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.7 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.3 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.4/42.2 MB 171.3 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 170.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 170.9 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 170.9 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 170.3 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 170.3 kB/s eta 0:02:20\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.6 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.5/42.2 MB 171.4 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 171.0 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 171.0 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 171.0 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.1 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.0 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 170.0 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 169.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 169.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 169.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.6/42.2 MB 169.8 kB/s eta 0:02:19\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 168.2 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 168.2 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 168.2 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 167.9 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 167.9 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 167.9 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 167.0 kB/s eta 0:02:21\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 166.3 kB/s eta 0:02:22\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.2 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.2 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.2 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 164.7 kB/s eta 0:02:23\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 163.4 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 163.4 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.7/42.2 MB 163.4 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.9 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.9 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.9 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.9 kB/s eta 0:02:24\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.1 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.1 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.0 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.0 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.0 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.3 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 162.3 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 161.3 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.8/42.2 MB 161.3 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.6 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.6 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.6 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.6 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.6 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.9 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.9 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.0 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 161.0 kB/s eta 0:02:25\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 160.7 kB/s eta 0:02:26\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 158.2 kB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 158.2 kB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 158.2 kB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 158.2 kB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 158.2 kB/s eta 0:02:28\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 155.5 kB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 155.5 kB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 155.5 kB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 155.5 kB/s eta 0:02:30\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 153.6 kB/s eta 0:02:32\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 153.6 kB/s eta 0:02:32\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 153.6 kB/s eta 0:02:32\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 153.6 kB/s eta 0:02:32\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 153.6 kB/s eta 0:02:32\n",
      "   ----------------- ---------------------- 18.9/42.2 MB 153.6 kB/s eta 0:02:32\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 150.5 kB/s eta 0:02:35\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 150.5 kB/s eta 0:02:35\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 150.5 kB/s eta 0:02:35\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 150.5 kB/s eta 0:02:35\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 150.5 kB/s eta 0:02:35\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 150.5 kB/s eta 0:02:35\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 147.8 kB/s eta 0:02:38\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 147.8 kB/s eta 0:02:38\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 147.8 kB/s eta 0:02:38\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 147.8 kB/s eta 0:02:38\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ----------------- ---------------------- 19.0/42.2 MB 146.2 kB/s eta 0:02:39\n",
      "   ------------------ --------------------- 19.0/42.2 MB 142.8 kB/s eta 0:02:43\n",
      "   ------------------ --------------------- 19.0/42.2 MB 142.8 kB/s eta 0:02:43\n",
      "   ------------------ --------------------- 19.0/42.2 MB 142.8 kB/s eta 0:02:43\n",
      "   ------------------ --------------------- 19.0/42.2 MB 142.8 kB/s eta 0:02:43\n",
      "   ------------------ --------------------- 19.0/42.2 MB 142.8 kB/s eta 0:02:43\n",
      "   ------------------ --------------------- 19.0/42.2 MB 142.8 kB/s eta 0:02:43\n",
      "   ------------------ --------------------- 19.0/42.2 MB 139.0 kB/s eta 0:02:47\n",
      "   ------------------ --------------------- 19.0/42.2 MB 139.0 kB/s eta 0:02:47\n",
      "   ------------------ --------------------- 19.0/42.2 MB 139.0 kB/s eta 0:02:47\n",
      "   ------------------ --------------------- 19.0/42.2 MB 139.0 kB/s eta 0:02:47\n",
      "   ------------------ --------------------- 19.0/42.2 MB 139.0 kB/s eta 0:02:47\n",
      "   ------------------ --------------------- 19.0/42.2 MB 135.3 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.0/42.2 MB 135.3 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.0/42.2 MB 135.3 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.0/42.2 MB 135.3 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.0/42.2 MB 135.3 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.1/42.2 MB 132.1 kB/s eta 0:02:56\n",
      "   ------------------ --------------------- 19.1/42.2 MB 132.1 kB/s eta 0:02:56\n",
      "   ------------------ --------------------- 19.1/42.2 MB 132.1 kB/s eta 0:02:56\n",
      "   ------------------ --------------------- 19.1/42.2 MB 129.4 kB/s eta 0:02:59\n",
      "   ------------------ --------------------- 19.1/42.2 MB 129.4 kB/s eta 0:02:59\n",
      "   ------------------ --------------------- 19.1/42.2 MB 127.7 kB/s eta 0:03:01\n",
      "   ------------------ --------------------- 19.1/42.2 MB 127.7 kB/s eta 0:03:01\n",
      "   ------------------ --------------------- 19.1/42.2 MB 127.7 kB/s eta 0:03:01\n",
      "   ------------------ --------------------- 19.1/42.2 MB 126.0 kB/s eta 0:03:04\n",
      "   ------------------ --------------------- 19.1/42.2 MB 126.0 kB/s eta 0:03:04\n",
      "   ------------------ --------------------- 19.1/42.2 MB 126.2 kB/s eta 0:03:03\n",
      "   ------------------ --------------------- 19.1/42.2 MB 126.2 kB/s eta 0:03:03\n",
      "   ------------------ --------------------- 19.1/42.2 MB 126.6 kB/s eta 0:03:03\n",
      "   ------------------ --------------------- 19.2/42.2 MB 125.9 kB/s eta 0:03:04\n",
      "   ------------------ --------------------- 19.2/42.2 MB 125.9 kB/s eta 0:03:04\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.3 kB/s eta 0:03:03\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.4 kB/s eta 0:03:03\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.4 kB/s eta 0:03:03\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.8 kB/s eta 0:03:02\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.4 kB/s eta 0:03:02\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.4 kB/s eta 0:03:02\n",
      "   ------------------ --------------------- 19.2/42.2 MB 126.8 kB/s eta 0:03:02\n",
      "   ------------------ --------------------- 19.3/42.2 MB 127.2 kB/s eta 0:03:01\n",
      "   ------------------ --------------------- 19.3/42.2 MB 127.3 kB/s eta 0:03:01\n",
      "   ------------------ --------------------- 19.3/42.2 MB 127.8 kB/s eta 0:03:00\n",
      "   ------------------ --------------------- 19.3/42.2 MB 127.8 kB/s eta 0:03:00\n",
      "   ------------------ --------------------- 19.3/42.2 MB 128.6 kB/s eta 0:02:59\n",
      "   ------------------ --------------------- 19.3/42.2 MB 128.7 kB/s eta 0:02:58\n",
      "   ------------------ --------------------- 19.3/42.2 MB 129.2 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.3/42.2 MB 129.2 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.3/42.2 MB 129.2 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.3/42.2 MB 129.2 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.3/42.2 MB 129.2 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.4/42.2 MB 128.7 kB/s eta 0:02:58\n",
      "   ------------------ --------------------- 19.4/42.2 MB 129.2 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.4/42.2 MB 128.9 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.4/42.2 MB 128.9 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.4/42.2 MB 129.4 kB/s eta 0:02:57\n",
      "   ------------------ --------------------- 19.5/42.2 MB 129.6 kB/s eta 0:02:56\n",
      "   ------------------ --------------------- 19.5/42.2 MB 129.6 kB/s eta 0:02:56\n",
      "   ------------------ --------------------- 19.5/42.2 MB 130.4 kB/s eta 0:02:55\n",
      "   ------------------ --------------------- 19.5/42.2 MB 130.5 kB/s eta 0:02:55\n",
      "   ------------------ --------------------- 19.5/42.2 MB 130.9 kB/s eta 0:02:54\n",
      "   ------------------ --------------------- 19.5/42.2 MB 131.0 kB/s eta 0:02:54\n",
      "   ------------------ --------------------- 19.5/42.2 MB 131.0 kB/s eta 0:02:54\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.2 kB/s eta 0:02:53\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.4 kB/s eta 0:02:53\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.5 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.5 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.6/42.2 MB 131.9 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.7 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.7 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.7 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.7 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.4 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.4 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.2 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.2 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.2 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.2 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.2 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.0 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.7/42.2 MB 131.1 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.8/42.2 MB 130.5 kB/s eta 0:02:53\n",
      "   ------------------ --------------------- 19.8/42.2 MB 130.5 kB/s eta 0:02:53\n",
      "   ------------------ --------------------- 19.8/42.2 MB 130.4 kB/s eta 0:02:53\n",
      "   ------------------ --------------------- 19.8/42.2 MB 130.4 kB/s eta 0:02:53\n",
      "   ------------------ --------------------- 19.8/42.2 MB 130.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.8/42.2 MB 130.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 19.8/42.2 MB 131.1 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.8/42.2 MB 131.3 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.8/42.2 MB 131.3 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.8/42.2 MB 131.3 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.8/42.2 MB 131.1 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.6 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.6 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.6 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.6 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.6 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.3 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.3 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.2 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 131.2 kB/s eta 0:02:50\n",
      "   ------------------ --------------------- 19.9/42.2 MB 130.9 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 130.9 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 130.9 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 130.9 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 19.9/42.2 MB 130.9 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.1 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.1 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 129.8 kB/s eta 0:02:52\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:51\n",
      "   ------------------ --------------------- 20.0/42.2 MB 130.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.1/42.2 MB 129.7 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.1/42.2 MB 129.7 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.1/42.2 MB 129.6 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.1/42.2 MB 130.2 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.1/42.2 MB 130.6 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.1/42.2 MB 130.6 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.1/42.2 MB 131.0 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.1/42.2 MB 131.1 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.2/42.2 MB 130.6 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.2/42.2 MB 130.7 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.2/42.2 MB 131.2 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 20.2/42.2 MB 131.8 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.2/42.2 MB 131.5 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 20.2/42.2 MB 132.7 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 20.3/42.2 MB 132.8 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 20.3/42.2 MB 132.8 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 20.3/42.2 MB 133.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.3/42.2 MB 133.9 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.3/42.2 MB 133.6 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.3/42.2 MB 133.7 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.8 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 135.0 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 135.0 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 135.0 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 135.0 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 135.0 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 135.0 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.0 kB/s eta 0:02:43\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.1 kB/s eta 0:02:43\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.4/42.2 MB 134.7 kB/s eta 0:02:42\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 132.8 kB/s eta 0:02:44\n",
      "   ------------------- -------------------- 20.5/42.2 MB 130.6 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.5/42.2 MB 130.6 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.5/42.2 MB 130.6 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.5/42.2 MB 130.6 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.5/42.2 MB 130.6 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.5/42.2 MB 130.6 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.5 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.5 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.5 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.5 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.5 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.3 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.3 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.3 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 128.3 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.4 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.5/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 127.0 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 126.5 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 125.7 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.6/42.2 MB 123.6 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.6/42.2 MB 123.6 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.6/42.2 MB 123.6 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.6/42.2 MB 123.6 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.6/42.2 MB 123.6 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.6/42.2 MB 122.6 kB/s eta 0:02:57\n",
      "   ------------------- -------------------- 20.6/42.2 MB 122.6 kB/s eta 0:02:57\n",
      "   ------------------- -------------------- 20.6/42.2 MB 122.6 kB/s eta 0:02:57\n",
      "   ------------------- -------------------- 20.6/42.2 MB 122.6 kB/s eta 0:02:57\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.6 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.6 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.6 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.6 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 122.7 kB/s eta 0:02:56\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.2 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.2 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.1 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.1 kB/s eta 0:02:55\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.5 kB/s eta 0:02:54\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.5 kB/s eta 0:02:54\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.4 kB/s eta 0:02:54\n",
      "   ------------------- -------------------- 20.7/42.2 MB 123.4 kB/s eta 0:02:54\n",
      "   ------------------- -------------------- 20.8/42.2 MB 123.8 kB/s eta 0:02:54\n",
      "   ------------------- -------------------- 20.8/42.2 MB 123.8 kB/s eta 0:02:54\n",
      "   ------------------- -------------------- 20.8/42.2 MB 124.2 kB/s eta 0:02:53\n",
      "   ------------------- -------------------- 20.8/42.2 MB 124.2 kB/s eta 0:02:53\n",
      "   ------------------- -------------------- 20.8/42.2 MB 124.4 kB/s eta 0:02:53\n",
      "   ------------------- -------------------- 20.8/42.2 MB 124.8 kB/s eta 0:02:52\n",
      "   ------------------- -------------------- 20.8/42.2 MB 125.2 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.8/42.2 MB 125.6 kB/s eta 0:02:51\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.1 kB/s eta 0:02:50\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.3 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.3 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.6 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.6 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.6 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.6 kB/s eta 0:02:49\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.7 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 20.9/42.2 MB 126.7 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 21.0/42.2 MB 126.8 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 21.0/42.2 MB 126.8 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 21.0/42.2 MB 126.9 kB/s eta 0:02:48\n",
      "   ------------------- -------------------- 21.0/42.2 MB 127.3 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 21.0/42.2 MB 127.2 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 21.0/42.2 MB 127.2 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 21.0/42.2 MB 127.7 kB/s eta 0:02:47\n",
      "   ------------------- -------------------- 21.0/42.2 MB 128.2 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 21.0/42.2 MB 128.3 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.4 kB/s eta 0:02:45\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.0 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.0 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.0 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.0 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.0 kB/s eta 0:02:46\n",
      "   ------------------- -------------------- 21.1/42.2 MB 128.0 kB/s eta 0:02:46\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.8 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.2 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.2 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.2 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.2 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.0 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.0 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.0 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.0 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.0 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.1/42.2 MB 126.0 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 21.2/42.2 MB 125.1 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 21.2/42.2 MB 125.1 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 21.2/42.2 MB 125.1 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 21.2/42.2 MB 125.0 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 21.2/42.2 MB 125.0 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 21.2/42.2 MB 125.0 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 21.2/42.2 MB 124.3 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 124.3 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 124.3 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 123.9 kB/s eta 0:02:50\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 121.0 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.2/42.2 MB 119.1 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.2/42.2 MB 119.1 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.2/42.2 MB 119.1 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.2/42.2 MB 119.1 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.2/42.2 MB 119.1 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.2/42.2 MB 119.1 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 119.4 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.3/42.2 MB 119.4 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.3/42.2 MB 119.4 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.3/42.2 MB 119.4 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.3/42.2 MB 119.4 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.3/42.2 MB 119.4 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.3/42.2 MB 118.4 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 118.4 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 118.4 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 118.4 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 118.4 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 118.4 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.9 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.9 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.9 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.9 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.5 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.5 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 117.5 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.9 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.9 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.9 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.9 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.9 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.8 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.8 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.8 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.8 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.8 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.3/42.2 MB 116.8 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 115.8 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 114.5 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.6 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.6 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.6 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.6 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.6 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.6 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.8 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.8 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.8 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 112.0 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.4/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.6 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.3 kB/s eta 0:03:07\n",
      "   -------------------- ------------------- 21.5/42.2 MB 112.2 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.5/42.2 MB 112.2 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.5/42.2 MB 112.2 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.5/42.2 MB 112.2 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.5/42.2 MB 111.7 kB/s eta 0:03:06\n",
      "   -------------------- ------------------- 21.6/42.2 MB 111.8 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.6/42.2 MB 111.8 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.6/42.2 MB 111.8 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.6/42.2 MB 111.8 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:05\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.3 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.3 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.3 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.3 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.3 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.5 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.5 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.5 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.1 kB/s eta 0:03:04\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.7 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.7 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.7 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.7 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.7 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.6/42.2 MB 112.7 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.7/42.2 MB 112.8 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.7/42.2 MB 112.8 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.7/42.2 MB 112.8 kB/s eta 0:03:03\n",
      "   -------------------- ------------------- 21.7/42.2 MB 113.2 kB/s eta 0:03:02\n",
      "   -------------------- ------------------- 21.7/42.2 MB 113.2 kB/s eta 0:03:02\n",
      "   -------------------- ------------------- 21.7/42.2 MB 113.2 kB/s eta 0:03:02\n",
      "   -------------------- ------------------- 21.7/42.2 MB 113.2 kB/s eta 0:03:02\n",
      "   -------------------- ------------------- 21.7/42.2 MB 113.5 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.7/42.2 MB 113.5 kB/s eta 0:03:01\n",
      "   -------------------- ------------------- 21.7/42.2 MB 114.2 kB/s eta 0:03:00\n",
      "   -------------------- ------------------- 21.7/42.2 MB 114.2 kB/s eta 0:03:00\n",
      "   -------------------- ------------------- 21.7/42.2 MB 114.6 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.7/42.2 MB 114.6 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.7/42.2 MB 114.6 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.7/42.2 MB 114.6 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.8/42.2 MB 114.5 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.8/42.2 MB 114.5 kB/s eta 0:02:59\n",
      "   -------------------- ------------------- 21.8/42.2 MB 114.9 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.8/42.2 MB 114.9 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.8/42.2 MB 115.3 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.8/42.2 MB 115.3 kB/s eta 0:02:58\n",
      "   -------------------- ------------------- 21.8/42.2 MB 115.9 kB/s eta 0:02:57\n",
      "   -------------------- ------------------- 21.8/42.2 MB 116.3 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.8/42.2 MB 116.3 kB/s eta 0:02:56\n",
      "   -------------------- ------------------- 21.9/42.2 MB 116.6 kB/s eta 0:02:55\n",
      "   -------------------- ------------------- 21.9/42.2 MB 116.7 kB/s eta 0:02:55\n",
      "   -------------------- ------------------- 21.9/42.2 MB 116.7 kB/s eta 0:02:55\n",
      "   -------------------- ------------------- 21.9/42.2 MB 117.1 kB/s eta 0:02:54\n",
      "   -------------------- ------------------- 21.9/42.2 MB 117.5 kB/s eta 0:02:53\n",
      "   -------------------- ------------------- 21.9/42.2 MB 117.9 kB/s eta 0:02:53\n",
      "   -------------------- ------------------- 21.9/42.2 MB 117.9 kB/s eta 0:02:53\n",
      "   -------------------- ------------------- 21.9/42.2 MB 118.4 kB/s eta 0:02:52\n",
      "   -------------------- ------------------- 21.9/42.2 MB 118.5 kB/s eta 0:02:52\n",
      "   -------------------- ------------------- 22.0/42.2 MB 119.0 kB/s eta 0:02:51\n",
      "   -------------------- ------------------- 22.0/42.2 MB 118.9 kB/s eta 0:02:51\n",
      "   -------------------- ------------------- 22.0/42.2 MB 118.9 kB/s eta 0:02:51\n",
      "   -------------------- ------------------- 22.0/42.2 MB 119.9 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 22.0/42.2 MB 119.9 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 22.0/42.2 MB 120.1 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 22.0/42.2 MB 120.1 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 22.0/42.2 MB 120.1 kB/s eta 0:02:49\n",
      "   -------------------- ------------------- 22.0/42.2 MB 120.3 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 22.1/42.2 MB 120.6 kB/s eta 0:02:48\n",
      "   -------------------- ------------------- 22.1/42.2 MB 121.0 kB/s eta 0:02:47\n",
      "   -------------------- ------------------- 22.1/42.2 MB 121.4 kB/s eta 0:02:46\n",
      "   -------------------- ------------------- 22.1/42.2 MB 121.5 kB/s eta 0:02:46\n",
      "   -------------------- ------------------- 22.1/42.2 MB 121.6 kB/s eta 0:02:46\n",
      "   -------------------- ------------------- 22.1/42.2 MB 121.4 kB/s eta 0:02:46\n",
      "   -------------------- ------------------- 22.1/42.2 MB 121.4 kB/s eta 0:02:46\n",
      "   -------------------- ------------------- 22.2/42.2 MB 121.9 kB/s eta 0:02:45\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.5 kB/s eta 0:02:44\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.6 kB/s eta 0:02:44\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.8 kB/s eta 0:02:43\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.8 kB/s eta 0:02:43\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.8 kB/s eta 0:02:43\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.8 kB/s eta 0:02:43\n",
      "   --------------------- ------------------ 22.2/42.2 MB 122.8 kB/s eta 0:02:43\n",
      "   --------------------- ------------------ 22.2/42.2 MB 123.4 kB/s eta 0:02:42\n",
      "   --------------------- ------------------ 22.3/42.2 MB 123.4 kB/s eta 0:02:42\n",
      "   --------------------- ------------------ 22.3/42.2 MB 123.4 kB/s eta 0:02:42\n",
      "   --------------------- ------------------ 22.3/42.2 MB 123.8 kB/s eta 0:02:42\n",
      "   --------------------- ------------------ 22.3/42.2 MB 124.1 kB/s eta 0:02:41\n",
      "   --------------------- ------------------ 22.3/42.2 MB 124.1 kB/s eta 0:02:41\n",
      "   --------------------- ------------------ 22.3/42.2 MB 124.2 kB/s eta 0:02:41\n",
      "   --------------------- ------------------ 22.3/42.2 MB 124.6 kB/s eta 0:02:40\n",
      "   --------------------- ------------------ 22.3/42.2 MB 124.8 kB/s eta 0:02:40\n",
      "   --------------------- ------------------ 22.4/42.2 MB 125.0 kB/s eta 0:02:39\n",
      "   --------------------- ------------------ 22.4/42.2 MB 125.6 kB/s eta 0:02:38\n",
      "   --------------------- ------------------ 22.4/42.2 MB 126.1 kB/s eta 0:02:38\n",
      "   --------------------- ------------------ 22.4/42.2 MB 126.3 kB/s eta 0:02:37\n",
      "   --------------------- ------------------ 22.4/42.2 MB 126.8 kB/s eta 0:02:36\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.3 kB/s eta 0:02:36\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.4 kB/s eta 0:02:36\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.4 kB/s eta 0:02:36\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.4 kB/s eta 0:02:36\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.4 kB/s eta 0:02:36\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.6 kB/s eta 0:02:35\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.6 kB/s eta 0:02:35\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.6 kB/s eta 0:02:35\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.6 kB/s eta 0:02:35\n",
      "   --------------------- ------------------ 22.5/42.2 MB 127.6 kB/s eta 0:02:35\n",
      "   --------------------- ------------------ 22.5/42.2 MB 128.9 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.5/42.2 MB 128.9 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.5/42.2 MB 128.7 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.5/42.2 MB 128.7 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.1 kB/s eta 0:02:33\n",
      "   --------------------- ------------------ 22.6/42.2 MB 130.0 kB/s eta 0:02:31\n",
      "   --------------------- ------------------ 22.6/42.2 MB 130.0 kB/s eta 0:02:31\n",
      "   --------------------- ------------------ 22.6/42.2 MB 130.0 kB/s eta 0:02:31\n",
      "   --------------------- ------------------ 22.6/42.2 MB 129.9 kB/s eta 0:02:31\n",
      "   --------------------- ------------------ 22.7/42.2 MB 130.2 kB/s eta 0:02:31\n",
      "   --------------------- ------------------ 22.7/42.2 MB 130.2 kB/s eta 0:02:31\n",
      "   --------------------- ------------------ 22.7/42.2 MB 130.5 kB/s eta 0:02:30\n",
      "   --------------------- ------------------ 22.7/42.2 MB 130.5 kB/s eta 0:02:30\n",
      "   --------------------- ------------------ 22.7/42.2 MB 130.7 kB/s eta 0:02:30\n",
      "   --------------------- ------------------ 22.7/42.2 MB 130.7 kB/s eta 0:02:30\n",
      "   --------------------- ------------------ 22.7/42.2 MB 131.1 kB/s eta 0:02:29\n",
      "   --------------------- ------------------ 22.7/42.2 MB 131.1 kB/s eta 0:02:29\n",
      "   --------------------- ------------------ 22.7/42.2 MB 131.2 kB/s eta 0:02:29\n",
      "   --------------------- ------------------ 22.7/42.2 MB 131.6 kB/s eta 0:02:29\n",
      "   --------------------- ------------------ 22.7/42.2 MB 131.6 kB/s eta 0:02:29\n",
      "   --------------------- ------------------ 22.7/42.2 MB 131.5 kB/s eta 0:02:29\n",
      "   --------------------- ------------------ 22.8/42.2 MB 131.9 kB/s eta 0:02:28\n",
      "   --------------------- ------------------ 22.8/42.2 MB 132.2 kB/s eta 0:02:28\n",
      "   --------------------- ------------------ 22.8/42.2 MB 132.3 kB/s eta 0:02:27\n",
      "   --------------------- ------------------ 22.8/42.2 MB 132.8 kB/s eta 0:02:27\n",
      "   --------------------- ------------------ 22.8/42.2 MB 132.8 kB/s eta 0:02:27\n",
      "   --------------------- ------------------ 22.8/42.2 MB 132.9 kB/s eta 0:02:26\n",
      "   --------------------- ------------------ 22.8/42.2 MB 133.5 kB/s eta 0:02:26\n",
      "   --------------------- ------------------ 22.9/42.2 MB 134.0 kB/s eta 0:02:25\n",
      "   --------------------- ------------------ 22.9/42.2 MB 134.2 kB/s eta 0:02:25\n",
      "   --------------------- ------------------ 22.9/42.2 MB 134.6 kB/s eta 0:02:24\n",
      "   --------------------- ------------------ 22.9/42.2 MB 134.9 kB/s eta 0:02:24\n",
      "   --------------------- ------------------ 22.9/42.2 MB 135.4 kB/s eta 0:02:23\n",
      "   --------------------- ------------------ 22.9/42.2 MB 135.8 kB/s eta 0:02:22\n",
      "   --------------------- ------------------ 22.9/42.2 MB 135.8 kB/s eta 0:02:22\n",
      "   --------------------- ------------------ 22.9/42.2 MB 135.8 kB/s eta 0:02:22\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.2 kB/s eta 0:02:22\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.8 kB/s eta 0:02:21\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.8 kB/s eta 0:02:21\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.8 kB/s eta 0:02:21\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.8 kB/s eta 0:02:21\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.8 kB/s eta 0:02:21\n",
      "   --------------------- ------------------ 23.0/42.2 MB 136.7 kB/s eta 0:02:21\n",
      "   --------------------- ------------------ 23.0/42.2 MB 138.5 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.0/42.2 MB 138.5 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.0/42.2 MB 138.4 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.0/42.2 MB 138.4 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.1/42.2 MB 138.7 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.1/42.2 MB 138.7 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.1/42.2 MB 138.7 kB/s eta 0:02:19\n",
      "   --------------------- ------------------ 23.1/42.2 MB 139.0 kB/s eta 0:02:18\n",
      "   --------------------- ------------------ 23.1/42.2 MB 139.0 kB/s eta 0:02:18\n",
      "   --------------------- ------------------ 23.1/42.2 MB 139.0 kB/s eta 0:02:18\n",
      "   --------------------- ------------------ 23.1/42.2 MB 139.0 kB/s eta 0:02:18\n",
      "   --------------------- ------------------ 23.1/42.2 MB 139.8 kB/s eta 0:02:17\n",
      "   --------------------- ------------------ 23.1/42.2 MB 140.1 kB/s eta 0:02:17\n",
      "   --------------------- ------------------ 23.1/42.2 MB 140.3 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.1/42.2 MB 140.3 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.2 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.2 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.2 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.2 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.2 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.5 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.9 kB/s eta 0:02:15\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.9 kB/s eta 0:02:15\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.9 kB/s eta 0:02:15\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.8 kB/s eta 0:02:16\n",
      "   --------------------- ------------------ 23.2/42.2 MB 140.8 kB/s eta 0:02:16\n",
      "   ---------------------- ----------------- 23.2/42.2 MB 141.0 kB/s eta 0:02:15\n",
      "   ---------------------- ----------------- 23.2/42.2 MB 141.0 kB/s eta 0:02:15\n",
      "   ---------------------- ----------------- 23.2/42.2 MB 141.0 kB/s eta 0:02:15\n",
      "   ---------------------- ----------------- 23.2/42.2 MB 142.0 kB/s eta 0:02:14\n",
      "   ---------------------- ----------------- 23.2/42.2 MB 142.0 kB/s eta 0:02:14\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.2 kB/s eta 0:02:14\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.2 kB/s eta 0:02:14\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 142.6 kB/s eta 0:02:13\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.3 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.3 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.3 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.3 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.3 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.7 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.7 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.3/42.2 MB 143.7 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.6 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.6 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.5 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.5 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.7 kB/s eta 0:02:12\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.8 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.8 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.9 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 144.3 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 144.3 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.9 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.4/42.2 MB 143.9 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.5/42.2 MB 144.1 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.5/42.2 MB 144.0 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.5/42.2 MB 144.0 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.5/42.2 MB 143.9 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.5/42.2 MB 144.4 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.5/42.2 MB 144.5 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.5 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.5 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.1 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.7 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 145.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 145.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 145.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 145.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 143.7 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 143.7 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.6/42.2 MB 144.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 143.8 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 143.8 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.9 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.9 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.8 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.8 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.5 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.5 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.0 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 142.0 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 141.8 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.7/42.2 MB 141.8 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 141.7 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 141.7 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 141.7 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 141.6 kB/s eta 0:02:11\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 141.7 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 142.1 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 142.1 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.8/42.2 MB 142.3 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.1 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.4 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.1 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.7 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.7 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.7 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.7 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 142.7 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 23.9/42.2 MB 141.6 kB/s eta 0:02:10\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.2 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.2 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.2 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 141.9 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.3 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.3 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.0 kB/s eta 0:02:09\n",
      "   ---------------------- ----------------- 24.0/42.2 MB 142.3 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 142.1 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 142.1 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 142.1 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 142.5 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 142.2 kB/s eta 0:02:08\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 142.6 kB/s eta 0:02:07\n",
      "   ---------------------- ----------------- 24.1/42.2 MB 143.0 kB/s eta 0:02:07\n",
      "   ---------------------- ----------------- 24.2/42.2 MB 143.4 kB/s eta 0:02:06\n",
      "   ---------------------- ----------------- 24.2/42.2 MB 143.8 kB/s eta 0:02:06\n",
      "   ---------------------- ----------------- 24.2/42.2 MB 143.9 kB/s eta 0:02:06\n",
      "   ---------------------- ----------------- 24.2/42.2 MB 144.4 kB/s eta 0:02:05\n",
      "   ---------------------- ----------------- 24.2/42.2 MB 143.8 kB/s eta 0:02:06\n",
      "   ---------------------- ----------------- 24.2/42.2 MB 144.0 kB/s eta 0:02:05\n",
      "   ---------------------- ----------------- 24.3/42.2 MB 144.5 kB/s eta 0:02:05\n",
      "   ---------------------- ----------------- 24.3/42.2 MB 145.4 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.3/42.2 MB 146.0 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.3/42.2 MB 146.0 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.3/42.2 MB 146.0 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.3/42.2 MB 146.0 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.3/42.2 MB 146.0 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 145.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 145.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 146.2 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 146.1 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 147.1 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 147.1 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.4/42.2 MB 147.2 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 147.3 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 147.3 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 147.3 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 147.3 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.9 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.9 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.9 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.9 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.5 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.5 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 145.5 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 144.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 144.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 144.5 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 143.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.5/42.2 MB 143.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 143.7 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 143.7 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 143.4 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.7 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.7 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.7 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.0 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.0 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.0 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.0 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.5 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.6/42.2 MB 142.5 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 142.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 142.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 142.8 kB/s eta 0:02:03\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 142.3 kB/s eta 0:02:04\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 143.6 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 143.6 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.7/42.2 MB 143.9 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 144.3 kB/s eta 0:02:02\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 144.3 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 144.5 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 144.9 kB/s eta 0:02:01\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 145.8 kB/s eta 0:02:00\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 146.2 kB/s eta 0:01:59\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 146.2 kB/s eta 0:01:59\n",
      "   ----------------------- ---------------- 24.8/42.2 MB 146.3 kB/s eta 0:01:59\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 146.7 kB/s eta 0:01:59\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 147.2 kB/s eta 0:01:58\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 147.2 kB/s eta 0:01:58\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 147.2 kB/s eta 0:01:58\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 147.2 kB/s eta 0:01:58\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 148.2 kB/s eta 0:01:57\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 148.2 kB/s eta 0:01:57\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 148.3 kB/s eta 0:01:57\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 148.6 kB/s eta 0:01:57\n",
      "   ----------------------- ---------------- 24.9/42.2 MB 148.6 kB/s eta 0:01:57\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 149.4 kB/s eta 0:01:56\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 149.4 kB/s eta 0:01:56\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 149.8 kB/s eta 0:01:56\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 149.8 kB/s eta 0:01:56\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 149.8 kB/s eta 0:01:56\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 150.1 kB/s eta 0:01:55\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 150.1 kB/s eta 0:01:55\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 150.3 kB/s eta 0:01:55\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 151.9 kB/s eta 0:01:54\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 151.9 kB/s eta 0:01:54\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 151.8 kB/s eta 0:01:54\n",
      "   ----------------------- ---------------- 25.0/42.2 MB 151.8 kB/s eta 0:01:54\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.2 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.2 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.2 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.2 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.2 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.2 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.5 kB/s eta 0:01:53\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 153.0 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 153.0 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 153.0 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 153.0 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 153.0 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.4 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.4 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.1/42.2 MB 152.4 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.2 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.2 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.2 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.2 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.1 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.1 kB/s eta 0:01:52\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.6 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.6 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.6 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 154.5 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.9 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.9 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.2/42.2 MB 153.9 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.4 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.4 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.4 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.4 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.4 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.4 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.0 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.0 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 154.0 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.9 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.9 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.9 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.9 kB/s eta 0:01:50\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.6 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.6 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.6 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ----------------------- ---------------- 25.3/42.2 MB 153.3 kB/s eta 0:01:51\n",
      "   ------------------------ --------------- 25.3/42.2 MB 151.4 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.3/42.2 MB 151.4 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.3/42.2 MB 151.4 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.3/42.2 MB 151.4 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.4/42.2 MB 150.9 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.4/42.2 MB 150.9 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.4/42.2 MB 150.9 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.4/42.2 MB 150.9 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.4/42.2 MB 149.5 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.4/42.2 MB 149.5 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.4/42.2 MB 149.5 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.4/42.2 MB 149.5 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.4/42.2 MB 149.5 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.4/42.2 MB 149.5 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.4/42.2 MB 148.1 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.4/42.2 MB 148.1 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.4/42.2 MB 148.1 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.4/42.2 MB 148.1 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.4/42.2 MB 147.3 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 147.3 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 147.3 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 146.2 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 146.2 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 146.2 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 146.2 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 146.9 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.4/42.2 MB 146.9 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.5/42.2 MB 146.7 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.5/42.2 MB 146.7 kB/s eta 0:01:55\n",
      "   ------------------------ --------------- 25.5/42.2 MB 146.8 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.5/42.2 MB 146.8 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.5/42.2 MB 147.1 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.5/42.2 MB 147.4 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.5/42.2 MB 147.4 kB/s eta 0:01:54\n",
      "   ------------------------ --------------- 25.5/42.2 MB 147.7 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.5/42.2 MB 147.7 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.5/42.2 MB 148.6 kB/s eta 0:01:53\n",
      "   ------------------------ --------------- 25.6/42.2 MB 149.0 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.6/42.2 MB 149.0 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.6/42.2 MB 148.9 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.6/42.2 MB 149.3 kB/s eta 0:01:52\n",
      "   ------------------------ --------------- 25.6/42.2 MB 149.7 kB/s eta 0:01:51\n",
      "   ------------------------ --------------- 25.6/42.2 MB 149.7 kB/s eta 0:01:51\n",
      "   ------------------------ --------------- 25.6/42.2 MB 150.5 kB/s eta 0:01:51\n",
      "   ------------------------ --------------- 25.6/42.2 MB 150.9 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.6/42.2 MB 150.9 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.6/42.2 MB 150.9 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.6/42.2 MB 150.9 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.6/42.2 MB 150.9 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 150.8 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.2 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.2 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.2 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.2 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.2 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.3 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.3 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.3 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.3 kB/s eta 0:01:50\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 151.4 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 152.0 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 152.1 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 152.1 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.7/42.2 MB 152.1 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.8/42.2 MB 151.9 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.8/42.2 MB 151.9 kB/s eta 0:01:49\n",
      "   ------------------------ --------------- 25.8/42.2 MB 152.5 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 152.5 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 152.6 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 152.6 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 152.6 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 152.6 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.1 kB/s eta 0:01:48\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.4 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.4 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.3 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.3 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.3 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.3 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.3 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.8/42.2 MB 153.3 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.5 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.5 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.5 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.0 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.0 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.0 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.0 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.8 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.8 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.8 kB/s eta 0:01:47\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.2 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.2 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.2 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.3 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 154.3 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.9 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.9 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 25.9/42.2 MB 153.9 kB/s eta 0:01:46\n",
      "   ------------------------ --------------- 26.0/42.2 MB 154.9 kB/s eta 0:01:45\n",
      "   ------------------------ --------------- 26.0/42.2 MB 154.9 kB/s eta 0:01:45\n",
      "   ------------------------ --------------- 26.0/42.2 MB 155.1 kB/s eta 0:01:45\n",
      "   ------------------------ --------------- 26.0/42.2 MB 155.8 kB/s eta 0:01:45\n",
      "   ------------------------ --------------- 26.0/42.2 MB 155.8 kB/s eta 0:01:45\n",
      "   ------------------------ --------------- 26.0/42.2 MB 156.1 kB/s eta 0:01:44\n",
      "   ------------------------ --------------- 26.0/42.2 MB 156.1 kB/s eta 0:01:44\n",
      "   ------------------------ --------------- 26.0/42.2 MB 156.1 kB/s eta 0:01:44\n",
      "   ------------------------ --------------- 26.1/42.2 MB 157.9 kB/s eta 0:01:43\n",
      "   ------------------------ --------------- 26.1/42.2 MB 158.0 kB/s eta 0:01:43\n",
      "   ------------------------ --------------- 26.1/42.2 MB 158.0 kB/s eta 0:01:43\n",
      "   ------------------------ --------------- 26.1/42.2 MB 158.4 kB/s eta 0:01:42\n",
      "   ------------------------ --------------- 26.1/42.2 MB 158.4 kB/s eta 0:01:42\n",
      "   ------------------------ --------------- 26.1/42.2 MB 158.7 kB/s eta 0:01:42\n",
      "   ------------------------ --------------- 26.1/42.2 MB 158.7 kB/s eta 0:01:42\n",
      "   ------------------------ --------------- 26.1/42.2 MB 160.3 kB/s eta 0:01:41\n",
      "   ------------------------ --------------- 26.2/42.2 MB 160.6 kB/s eta 0:01:41\n",
      "   ------------------------ --------------- 26.2/42.2 MB 160.8 kB/s eta 0:01:40\n",
      "   ------------------------ --------------- 26.2/42.2 MB 160.8 kB/s eta 0:01:40\n",
      "   ------------------------ --------------- 26.2/42.2 MB 160.9 kB/s eta 0:01:40\n",
      "   ------------------------ --------------- 26.2/42.2 MB 161.2 kB/s eta 0:01:40\n",
      "   ------------------------ --------------- 26.2/42.2 MB 161.5 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.2/42.2 MB 161.5 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.2/42.2 MB 162.5 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.2/42.2 MB 162.5 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.2/42.2 MB 162.5 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.2/42.2 MB 162.5 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.3/42.2 MB 162.2 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.3/42.2 MB 162.2 kB/s eta 0:01:39\n",
      "   ------------------------ --------------- 26.3/42.2 MB 163.1 kB/s eta 0:01:38\n",
      "   ------------------------ --------------- 26.3/42.2 MB 163.1 kB/s eta 0:01:38\n",
      "   ------------------------ --------------- 26.3/42.2 MB 163.4 kB/s eta 0:01:38\n",
      "   ------------------------ --------------- 26.3/42.2 MB 164.7 kB/s eta 0:01:37\n",
      "   ------------------------ --------------- 26.3/42.2 MB 164.7 kB/s eta 0:01:37\n",
      "   ------------------------ --------------- 26.3/42.2 MB 164.7 kB/s eta 0:01:37\n",
      "   ------------------------ --------------- 26.3/42.2 MB 164.4 kB/s eta 0:01:37\n",
      "   ------------------------ --------------- 26.3/42.2 MB 164.4 kB/s eta 0:01:37\n",
      "   ------------------------ --------------- 26.3/42.2 MB 164.2 kB/s eta 0:01:37\n",
      "   ------------------------ --------------- 26.4/42.2 MB 165.4 kB/s eta 0:01:36\n",
      "   ------------------------ --------------- 26.4/42.2 MB 165.4 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.6 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.6 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.5 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.7 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.4/42.2 MB 165.7 kB/s eta 0:01:36\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.0 kB/s eta 0:01:35\n",
      "   ------------------------- -------------- 26.5/42.2 MB 166.9 kB/s eta 0:01:35\n",
      "   ------------------------- -------------- 26.5/42.2 MB 166.9 kB/s eta 0:01:35\n",
      "   ------------------------- -------------- 26.5/42.2 MB 166.9 kB/s eta 0:01:35\n",
      "   ------------------------- -------------- 26.5/42.2 MB 166.9 kB/s eta 0:01:35\n",
      "   ------------------------- -------------- 26.5/42.2 MB 166.9 kB/s eta 0:01:35\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.4 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.4 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.1 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.1 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.3 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.3 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.5/42.2 MB 167.3 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.6/42.2 MB 167.8 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.6/42.2 MB 167.8 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.0 kB/s eta 0:01:34\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.4 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.4 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.5 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.5 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.5 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.4 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.7 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 168.7 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 169.0 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.6/42.2 MB 169.0 kB/s eta 0:01:33\n",
      "   ------------------------- -------------- 26.7/42.2 MB 169.1 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 26.7/42.2 MB 169.1 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 26.7/42.2 MB 169.3 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 26.7/42.2 MB 169.3 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 26.7/42.2 MB 169.6 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.7/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.2 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.2 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.4 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.4 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.1 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.1 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.8/42.2 MB 170.3 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.9 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.9 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.9 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.9 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 169.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.5 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.5 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.5 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.5 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 170.5 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 26.9/42.2 MB 169.7 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.9/42.2 MB 169.7 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.9/42.2 MB 169.7 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.9/42.2 MB 169.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 26.9/42.2 MB 169.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 168.6 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 168.6 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 168.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 168.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 168.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.8 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.8 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.6 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.6 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 166.9 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.0/42.2 MB 167.4 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.8 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.5 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 167.0 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.1/42.2 MB 165.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 165.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.2 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.4 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.4 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.4 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.1 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.1 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.2/42.2 MB 166.5 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.2 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.2 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.6 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.2 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.2 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.2 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 166.2 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 165.6 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 165.6 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 165.6 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 165.6 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 165.6 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.3/42.2 MB 163.2 kB/s eta 0:01:32\n",
      "   ------------------------- -------------- 27.4/42.2 MB 163.8 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.4/42.2 MB 163.8 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.4/42.2 MB 163.9 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.4/42.2 MB 164.2 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.4/42.2 MB 164.2 kB/s eta 0:01:31\n",
      "   ------------------------- -------------- 27.4/42.2 MB 164.7 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.4/42.2 MB 164.7 kB/s eta 0:01:30\n",
      "   ------------------------- -------------- 27.4/42.2 MB 164.6 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.4/42.2 MB 164.9 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.4/42.2 MB 164.9 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 164.0 kB/s eta 0:01:31\n",
      "   -------------------------- ------------- 27.5/42.2 MB 164.4 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 164.4 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 164.7 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 164.5 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 165.0 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 165.0 kB/s eta 0:01:30\n",
      "   -------------------------- ------------- 27.5/42.2 MB 165.8 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.6/42.2 MB 166.2 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.6/42.2 MB 166.6 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 27.6/42.2 MB 166.6 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 27.6/42.2 MB 166.6 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 27.6/42.2 MB 166.5 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 27.6/42.2 MB 166.9 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 27.7/42.2 MB 167.7 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.7/42.2 MB 168.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.7/42.2 MB 168.3 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.7/42.2 MB 168.9 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.4 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.2 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 169.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 166.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 27.8/42.2 MB 163.2 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.8/42.2 MB 163.2 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.8/42.2 MB 163.2 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.8/42.2 MB 163.2 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 162.6 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 162.6 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 162.6 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 162.6 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 162.6 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.2 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.5 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.5 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 27.9/42.2 MB 161.7 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 28.0/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 28.0/42.2 MB 161.1 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 28.0/42.2 MB 161.5 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 28.0/42.2 MB 161.5 kB/s eta 0:01:29\n",
      "   -------------------------- ------------- 28.0/42.2 MB 161.6 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 28.0/42.2 MB 162.4 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 28.0/42.2 MB 162.8 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 28.0/42.2 MB 162.8 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 28.0/42.2 MB 162.7 kB/s eta 0:01:28\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 162.9 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.2 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.1/42.2 MB 163.6 kB/s eta 0:01:27\n",
      "   -------------------------- ------------- 28.2/42.2 MB 163.9 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 163.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 164.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 164.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 164.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 164.6 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 163.9 kB/s eta 0:01:26\n",
      "   -------------------------- ------------- 28.2/42.2 MB 165.0 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.2/42.2 MB 165.0 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.2/42.2 MB 165.3 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.2/42.2 MB 165.3 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 164.8 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 164.8 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 165.6 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 165.7 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 165.7 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 165.6 kB/s eta 0:01:25\n",
      "   -------------------------- ------------- 28.3/42.2 MB 166.1 kB/s eta 0:01:24\n",
      "   -------------------------- ------------- 28.3/42.2 MB 166.4 kB/s eta 0:01:24\n",
      "   -------------------------- ------------- 28.3/42.2 MB 166.4 kB/s eta 0:01:24\n",
      "   -------------------------- ------------- 28.3/42.2 MB 166.5 kB/s eta 0:01:24\n",
      "   -------------------------- ------------- 28.4/42.2 MB 166.8 kB/s eta 0:01:24\n",
      "   -------------------------- ------------- 28.4/42.2 MB 167.0 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 167.4 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 167.4 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 167.4 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 167.4 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.4/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.5/42.2 MB 166.7 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.5/42.2 MB 166.7 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.5/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.5/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.5/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   -------------------------- ------------- 28.5/42.2 MB 166.8 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 165.6 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 165.8 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 165.8 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 165.5 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 165.5 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 164.9 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.5/42.2 MB 164.9 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.6 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.6 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.7 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.7 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.7 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.7 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.2 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.2 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.4 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.4 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.1 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.1 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.6/42.2 MB 165.1 kB/s eta 0:01:23\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.6 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.6 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.6 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.6 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.6 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.7 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.8 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.8 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.7/42.2 MB 165.8 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.0 kB/s eta 0:01:22\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.4 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.1 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.4 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.8/42.2 MB 166.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.4 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.4 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.7 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.7 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.7 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.7 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.7 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.4 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.4 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.3 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.3 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 166.3 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 28.9/42.2 MB 165.1 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 28.9/42.2 MB 165.1 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 165.3 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 165.3 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 165.4 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.0/42.2 MB 165.4 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.0/42.2 MB 164.8 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 164.8 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 164.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 164.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 164.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 163.9 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.0/42.2 MB 163.9 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 163.7 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 163.7 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 163.5 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 163.0 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 163.0 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 162.8 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 162.2 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 162.2 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.1/42.2 MB 162.2 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.2/42.2 MB 162.0 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.2/42.2 MB 162.0 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.2/42.2 MB 162.6 kB/s eta 0:01:21\n",
      "   --------------------------- ------------ 29.2/42.2 MB 163.0 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.2/42.2 MB 163.2 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.2/42.2 MB 163.5 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.2/42.2 MB 162.7 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.2/42.2 MB 162.3 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.2/42.2 MB 162.3 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.3/42.2 MB 162.9 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.3/42.2 MB 162.9 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.3/42.2 MB 162.9 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.3/42.2 MB 162.9 kB/s eta 0:01:20\n",
      "   --------------------------- ------------ 29.3/42.2 MB 163.8 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.3/42.2 MB 163.8 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.3/42.2 MB 163.8 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.3/42.2 MB 163.8 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.3/42.2 MB 163.8 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.3/42.2 MB 163.8 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.4/42.2 MB 163.9 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.4/42.2 MB 163.9 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.4/42.2 MB 164.3 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.4/42.2 MB 163.6 kB/s eta 0:01:19\n",
      "   --------------------------- ------------ 29.4/42.2 MB 164.0 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.4/42.2 MB 164.2 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.9 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.9 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.9 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.9 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 163.8 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.5 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.4 kB/s eta 0:01:18\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.6 kB/s eta 0:01:17\n",
      "   --------------------------- ------------ 29.5/42.2 MB 164.6 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 164.7 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.2 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.2 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.5 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.5 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.7 kB/s eta 0:01:16\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.5 kB/s eta 0:01:17\n",
      "   ---------------------------- ----------- 29.6/42.2 MB 165.8 kB/s eta 0:01:16\n",
      "   ---------------------------- ----------- 29.7/42.2 MB 166.0 kB/s eta 0:01:16\n",
      "   ---------------------------- ----------- 29.7/42.2 MB 166.4 kB/s eta 0:01:16\n",
      "   ---------------------------- ----------- 29.7/42.2 MB 166.2 kB/s eta 0:01:16\n",
      "   ---------------------------- ----------- 29.7/42.2 MB 166.7 kB/s eta 0:01:16\n",
      "   ---------------------------- ----------- 29.7/42.2 MB 167.3 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.7/42.2 MB 167.3 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.4 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.2 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.6 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.1 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.8/42.2 MB 167.1 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 167.1 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 168.0 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 165.8 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 29.9/42.2 MB 165.8 kB/s eta 0:01:15\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.6 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.6 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.6 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 165.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 165.9 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.1 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.0/42.2 MB 166.1 kB/s eta 0:01:14\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.8 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.7 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.7 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.9 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.9 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.9 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 166.9 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 167.6 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 167.6 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 168.0 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 168.0 kB/s eta 0:01:13\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 167.9 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 167.9 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 167.9 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.1/42.2 MB 167.7 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 167.7 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 167.7 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 167.7 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 167.7 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.4 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.4 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.1 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.1 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 168.3 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 167.6 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.2/42.2 MB 167.6 kB/s eta 0:01:12\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 168.7 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 168.7 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 168.5 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 168.5 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 168.9 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 169.1 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 169.8 kB/s eta 0:01:11\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 170.1 kB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 30.3/42.2 MB 170.1 kB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 170.0 kB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.1 kB/s eta 0:01:10\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.5 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.5 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.5 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.8 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.8 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.8 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.8 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.4/42.2 MB 171.8 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 172.6 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 172.6 kB/s eta 0:01:09\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 172.8 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 172.8 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 172.8 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 173.1 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 173.1 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 173.1 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 173.1 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 174.2 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 174.2 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 174.3 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.5/42.2 MB 174.3 kB/s eta 0:01:08\n",
      "   ---------------------------- ----------- 30.6/42.2 MB 174.4 kB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 30.6/42.2 MB 174.7 kB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 30.6/42.2 MB 174.7 kB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 30.6/42.2 MB 174.9 kB/s eta 0:01:07\n",
      "   ---------------------------- ----------- 30.6/42.2 MB 174.8 kB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 175.4 kB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 175.4 kB/s eta 0:01:07\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 175.7 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 177.1 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 177.1 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 177.1 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.6/42.2 MB 177.1 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 176.6 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 176.7 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 176.7 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 177.1 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 177.1 kB/s eta 0:01:06\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 177.3 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 177.3 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.7/42.2 MB 177.9 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.1 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.1 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.2 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.6 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.6 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.6 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.6 kB/s eta 0:01:05\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.8/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 178.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 177.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 177.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 177.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 177.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 30.9/42.2 MB 177.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.2 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.2 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 176.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 176.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 176.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 176.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 176.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.3 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.3 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.3 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.3 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.1 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.1 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.0/42.2 MB 177.1 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 177.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 176.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.5 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.2 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.1/42.2 MB 175.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.1 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 174.1 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 173.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 173.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 173.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.2/42.2 MB 173.7 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 173.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 173.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 173.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 173.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 173.6 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 171.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 172.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 172.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 172.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 172.0 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 171.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 171.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.3/42.2 MB 171.9 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.8 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.4 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.9 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.6 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.6 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.2 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.2 kB/s eta 0:01:04\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.1 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.4/42.2 MB 171.1 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 171.7 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 171.7 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 171.9 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.0 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.0 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.0 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.5/42.2 MB 171.9 kB/s eta 0:01:03\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.6 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.7 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.7 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.7 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.7 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.7 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.7 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 171.4 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ----------------------------- ---------- 31.6/42.2 MB 172.5 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.1 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.1 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 171.9 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 171.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.0 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.0 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.7/42.2 MB 172.0 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.3 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.3 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.3 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.3 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 171.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.5 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.5 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.5 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.5 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.8 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.8 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.8 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.8 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.8 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.8/42.2 MB 169.0 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.6 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 167.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.3 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.3 kB/s eta 0:01:02\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.7 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.5 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 31.9/42.2 MB 168.5 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.5 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.5 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.6 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.9 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.9 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.9 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.9 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.4 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.6 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.0/42.2 MB 168.6 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.4 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.4 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.5 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.5 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.1 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.1 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.3 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.0 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.0 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 167.8 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 167.8 kB/s eta 0:01:01\n",
      "   ------------------------------ --------- 32.1/42.2 MB 168.0 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 168.0 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 168.0 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 168.0 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 168.0 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 168.0 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.9 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.9 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.6 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.6 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.5 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.9 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.2/42.2 MB 167.9 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.9 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.5 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.5 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.5 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.5 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.5 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.4 kB/s eta 0:01:00\n",
      "   ------------------------------ --------- 32.3/42.2 MB 168.0 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.3/42.2 MB 168.0 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.3/42.2 MB 167.7 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 168.0 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 167.9 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 167.9 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 167.9 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 168.1 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 168.1 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 168.2 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.4/42.2 MB 168.4 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.5/42.2 MB 168.4 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 168.4 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 168.5 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 169.0 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 169.0 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 169.0 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 169.0 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 167.9 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 168.2 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 167.8 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 167.8 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 167.8 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 167.8 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.5/42.2 MB 167.8 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.6/42.2 MB 166.9 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.6/42.2 MB 166.5 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.6/42.2 MB 166.5 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.6/42.2 MB 165.8 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.6/42.2 MB 165.8 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.6/42.2 MB 165.9 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.6/42.2 MB 165.9 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.6/42.2 MB 164.6 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.6/42.2 MB 164.6 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.6/42.2 MB 164.2 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.7/42.2 MB 163.9 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.7/42.2 MB 163.9 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.7/42.2 MB 163.2 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.7/42.2 MB 163.2 kB/s eta 0:00:59\n",
      "   ------------------------------ --------- 32.7/42.2 MB 165.4 kB/s eta 0:00:58\n",
      "   ------------------------------ --------- 32.7/42.2 MB 165.4 kB/s eta 0:00:58\n",
      "   ------------------------------- -------- 32.7/42.2 MB 165.7 kB/s eta 0:00:58\n",
      "   ------------------------------- -------- 32.7/42.2 MB 165.7 kB/s eta 0:00:58\n",
      "   ------------------------------- -------- 32.7/42.2 MB 166.1 kB/s eta 0:00:58\n",
      "   ------------------------------- -------- 32.7/42.2 MB 166.1 kB/s eta 0:00:58\n",
      "   ------------------------------- -------- 32.8/42.2 MB 166.5 kB/s eta 0:00:57\n",
      "   ------------------------------- -------- 32.8/42.2 MB 166.5 kB/s eta 0:00:57\n",
      "   ------------------------------- -------- 32.8/42.2 MB 166.9 kB/s eta 0:00:57\n",
      "   ------------------------------- -------- 32.8/42.2 MB 166.9 kB/s eta 0:00:57\n",
      "   ------------------------------- -------- 32.8/42.2 MB 166.9 kB/s eta 0:00:57\n",
      "   ------------------------------- -------- 32.8/42.2 MB 168.0 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.8/42.2 MB 168.2 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.8/42.2 MB 168.5 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.8/42.2 MB 168.5 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.9/42.2 MB 168.5 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.9/42.2 MB 168.8 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.9/42.2 MB 168.8 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.9/42.2 MB 168.6 kB/s eta 0:00:56\n",
      "   ------------------------------- -------- 32.9/42.2 MB 169.7 kB/s eta 0:00:55\n",
      "   ------------------------------- -------- 32.9/42.2 MB 170.0 kB/s eta 0:00:55\n",
      "   ------------------------------- -------- 32.9/42.2 MB 170.0 kB/s eta 0:00:55\n",
      "   ------------------------------- -------- 32.9/42.2 MB 170.0 kB/s eta 0:00:55\n",
      "   ------------------------------- -------- 33.0/42.2 MB 170.4 kB/s eta 0:00:55\n",
      "   ------------------------------- -------- 33.0/42.2 MB 171.5 kB/s eta 0:00:54\n",
      "   ------------------------------- -------- 33.0/42.2 MB 171.6 kB/s eta 0:00:54\n",
      "   ------------------------------- -------- 33.0/42.2 MB 171.9 kB/s eta 0:00:54\n",
      "   ------------------------------- -------- 33.0/42.2 MB 172.0 kB/s eta 0:00:54\n",
      "   ------------------------------- -------- 33.0/42.2 MB 172.4 kB/s eta 0:00:54\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.0 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.1 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.2 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.7 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.7 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.1/42.2 MB 173.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 171.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 171.9 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 171.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 171.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 171.8 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 172.5 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 172.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 172.3 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 172.0 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.2/42.2 MB 172.0 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.3/42.2 MB 172.0 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.3/42.2 MB 172.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 171.6 kB/s eta 0:00:53\n",
      "   ------------------------------- -------- 33.3/42.2 MB 172.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 172.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 172.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 172.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 171.4 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 171.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 171.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.3/42.2 MB 171.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 171.4 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 171.4 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 171.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 171.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 171.0 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.9 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.9 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.3 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.3 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.4 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.5 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 170.5 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 169.9 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.4/42.2 MB 169.9 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.8 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.7 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 170.3 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 170.3 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.3 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.3 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.6 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.5/42.2 MB 169.6 kB/s eta 0:00:52\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.0 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.2 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.2 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.5 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.0 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.0 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.6 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.6/42.2 MB 170.3 kB/s eta 0:00:51\n",
      "   ------------------------------- -------- 33.7/42.2 MB 171.2 kB/s eta 0:00:50\n",
      "   ------------------------------- -------- 33.7/42.2 MB 171.0 kB/s eta 0:00:50\n",
      "   ------------------------------- -------- 33.7/42.2 MB 171.4 kB/s eta 0:00:50\n",
      "   ------------------------------- -------- 33.7/42.2 MB 171.4 kB/s eta 0:00:50\n",
      "   ------------------------------- -------- 33.7/42.2 MB 172.3 kB/s eta 0:00:50\n",
      "   ------------------------------- -------- 33.8/42.2 MB 172.7 kB/s eta 0:00:49\n",
      "   ------------------------------- -------- 33.8/42.2 MB 172.7 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.8/42.2 MB 173.4 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.8/42.2 MB 173.4 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.8/42.2 MB 173.7 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.8/42.2 MB 173.7 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.8/42.2 MB 173.7 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.8/42.2 MB 173.7 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.9/42.2 MB 173.5 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.9/42.2 MB 173.5 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.9/42.2 MB 173.5 kB/s eta 0:00:49\n",
      "   -------------------------------- ------- 33.9/42.2 MB 173.6 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 173.7 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 173.7 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 174.1 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 174.1 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 174.1 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 174.1 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 33.9/42.2 MB 174.1 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 172.8 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 172.8 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 172.6 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 172.6 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 172.4 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 172.4 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 173.1 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 173.3 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.0/42.2 MB 173.3 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.9 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.6 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.6 kB/s eta 0:00:48\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.1/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.4 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.4 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.5 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.7 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 172.8 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.2/42.2 MB 173.0 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.3/42.2 MB 172.6 kB/s eta 0:00:47\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.4 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.4 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.4 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.3/42.2 MB 173.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 173.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 173.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 173.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 173.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 173.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 172.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 172.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 172.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 172.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 172.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 170.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 170.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 170.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.4/42.2 MB 170.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 171.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 171.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 171.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 171.1 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 170.0 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 170.0 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 169.5 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 169.5 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 169.5 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.9 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.9 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.5/42.2 MB 168.7 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 168.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 168.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 167.9 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 167.9 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 168.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 168.3 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 167.9 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.6/42.2 MB 167.9 kB/s eta 0:00:46\n",
      "   -------------------------------- ------- 34.7/42.2 MB 168.1 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.7/42.2 MB 167.9 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.7/42.2 MB 167.8 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.7/42.2 MB 168.1 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.7/42.2 MB 167.8 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.7/42.2 MB 168.0 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.7/42.2 MB 167.8 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.8/42.2 MB 167.8 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.8/42.2 MB 168.0 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.8/42.2 MB 168.0 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.8/42.2 MB 168.1 kB/s eta 0:00:45\n",
      "   -------------------------------- ------- 34.8/42.2 MB 167.7 kB/s eta 0:00:45\n",
      "   --------------------------------- ------ 34.8/42.2 MB 168.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 167.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 167.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 167.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 167.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 167.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 34.9/42.2 MB 168.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 168.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 168.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 168.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 168.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.0/42.2 MB 166.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.6 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.6 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.6 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.6 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 165.6 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.4 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.1/42.2 MB 164.0 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 162.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 162.9 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 162.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 162.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 162.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 162.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 161.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 161.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 161.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.2 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.2 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 160.8 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.2/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.3 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.2 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.2 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 158.7 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.3/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.4/42.2 MB 159.1 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.5 kB/s eta 0:00:44\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.5 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.7 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.7 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.4 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.4/42.2 MB 158.4 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.4 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.4 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.0 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.0 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.4 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.4 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 157.7 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.1 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.1 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.1 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.1 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 158.3 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 157.8 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.5/42.2 MB 157.8 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.6/42.2 MB 158.0 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.6/42.2 MB 158.0 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.7 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.7 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.6 kB/s eta 0:00:43\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.6 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.6 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.7 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.6/42.2 MB 157.7 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.5 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.5 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.5 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.1 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.7 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.7 kB/s eta 0:00:42\n",
      "   --------------------------------- ------ 35.7/42.2 MB 159.0 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.7/42.2 MB 159.0 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.7/42.2 MB 158.9 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.7/42.2 MB 159.3 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.7/42.2 MB 159.3 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.7/42.2 MB 159.2 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.7/42.2 MB 159.2 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 159.7 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 159.7 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 159.7 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 159.7 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 159.7 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 160.2 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 160.2 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 160.2 kB/s eta 0:00:41\n",
      "   --------------------------------- ------ 35.8/42.2 MB 161.2 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.8/42.2 MB 161.2 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.8/42.2 MB 161.2 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.8/42.2 MB 160.4 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.8/42.2 MB 160.4 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.7 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.7 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.7 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.9 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.9 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.8 kB/s eta 0:00:40\n",
      "   --------------------------------- ------ 35.9/42.2 MB 160.8 kB/s eta 0:00:40\n",
      "   ---------------------------------- ----- 35.9/42.2 MB 162.9 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 35.9/42.2 MB 162.9 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 35.9/42.2 MB 162.7 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 35.9/42.2 MB 162.7 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 35.9/42.2 MB 162.9 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 163.2 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 163.2 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 163.2 kB/s eta 0:00:39\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.6 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.6 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.7 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 164.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 165.6 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 165.6 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.0/42.2 MB 165.6 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 165.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 165.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 165.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 165.9 kB/s eta 0:00:38\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 166.2 kB/s eta 0:00:37\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 167.5 kB/s eta 0:00:37\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 167.5 kB/s eta 0:00:37\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 167.4 kB/s eta 0:00:37\n",
      "   ---------------------------------- ----- 36.1/42.2 MB 167.9 kB/s eta 0:00:37\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 167.9 kB/s eta 0:00:37\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.2 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.2 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.2 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.2 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.2 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.2 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 167.8 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 167.8 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 167.8 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.4 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.0 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.2/42.2 MB 168.0 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 168.4 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 168.8 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 168.8 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 168.5 kB/s eta 0:00:36\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 169.0 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 169.6 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 169.6 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.3/42.2 MB 170.0 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.4/42.2 MB 170.3 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.4/42.2 MB 170.3 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.4/42.2 MB 170.4 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.4/42.2 MB 170.5 kB/s eta 0:00:35\n",
      "   ---------------------------------- ----- 36.4/42.2 MB 171.0 kB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 36.4/42.2 MB 171.4 kB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 171.5 kB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 171.5 kB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 171.7 kB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 172.3 kB/s eta 0:00:34\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 172.7 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 172.6 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 172.6 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 172.6 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.5/42.2 MB 172.6 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.3 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.3 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.3 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.5 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.5 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.5 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.5 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 172.6 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.6/42.2 MB 173.1 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 173.2 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 173.2 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 173.2 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 173.2 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 173.2 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 173.2 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.4 kB/s eta 0:00:33\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.6 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.6 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.6 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.6 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.6 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 172.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 171.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 171.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.7/42.2 MB 171.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.5 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.5 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.5 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.7 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 170.5 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 170.5 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 170.5 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.1 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.8/42.2 MB 171.1 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.8 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.3 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.9 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.9 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.9 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 171.0 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 171.0 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 171.0 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 171.0 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 171.0 kB/s eta 0:00:32\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.9 kB/s eta 0:00:31\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.9 kB/s eta 0:00:31\n",
      "   ---------------------------------- ----- 36.9/42.2 MB 170.9 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 36.9/42.2 MB 171.0 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 36.9/42.2 MB 171.0 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 36.9/42.2 MB 171.0 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 171.1 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 171.1 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 171.1 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 171.2 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 171.2 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 170.9 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 172.4 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 172.4 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 172.6 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 172.6 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 172.4 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.0/42.2 MB 172.4 kB/s eta 0:00:31\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 172.7 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 172.2 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 172.6 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.2 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.1 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.1 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.1/42.2 MB 173.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.5 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.6 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.6 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.6 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 173.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 173.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 173.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.4 kB/s eta 0:00:30\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.2/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.4 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.4 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 172.3 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 170.6 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 170.6 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 171.0 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 171.0 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 171.0 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.3/42.2 MB 171.0 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.7 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.7 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.9 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.9 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.9 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.6 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 169.6 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.7 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.7 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.5 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.4/42.2 MB 168.1 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 167.9 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 167.9 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 167.7 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 167.7 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 167.6 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 168.0 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 168.0 kB/s eta 0:00:29\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 168.0 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 168.0 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 168.0 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 168.0 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.5/42.2 MB 167.0 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.0 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.2 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.2 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.2 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.1 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.1 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.1 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.1 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.6/42.2 MB 167.3 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.9 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.9 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.9 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.9 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.5 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.8 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.8 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.8 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 166.8 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 165.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 165.6 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 165.3 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.7/42.2 MB 165.3 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 165.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 165.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 165.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 165.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 165.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 164.3 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 164.3 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 164.2 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 164.2 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 164.0 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 164.0 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 163.4 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 163.4 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 163.3 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 163.3 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 162.6 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.8/42.2 MB 162.6 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 162.4 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 162.4 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 162.4 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 161.2 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 161.2 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 161.2 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 161.2 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 159.8 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 159.8 kB/s eta 0:00:28\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 159.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 159.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 159.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 160.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 160.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 160.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 37.9/42.2 MB 160.7 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 38.0/42.2 MB 160.8 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 38.0/42.2 MB 160.8 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 38.0/42.2 MB 160.8 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 38.0/42.2 MB 160.8 kB/s eta 0:00:27\n",
      "   ----------------------------------- ---- 38.0/42.2 MB 159.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 160.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 160.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 160.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 160.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.4 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.4 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.1 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.1 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.1 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.1 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.0/42.2 MB 159.1 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 158.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 157.3 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 154.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 153.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 153.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 153.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 153.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 152.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.1/42.2 MB 152.9 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 152.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 150.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 150.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 150.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 148.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 148.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 148.8 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 147.5 kB/s eta 0:00:28\n",
      "   ------------------------------------ --- 38.2/42.2 MB 147.5 kB/s eta 0:00:28\n",
      "   ------------------------------------ --- 38.2/42.2 MB 147.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 147.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.2/42.2 MB 147.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 147.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 147.5 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 145.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 145.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.3/42.2 MB 146.6 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.4 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.4 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.4 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 146.2 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 145.7 kB/s eta 0:00:27\n",
      "   ------------------------------------ --- 38.4/42.2 MB 145.7 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.4/42.2 MB 145.7 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 146.9 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.2 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:26\n",
      "   ------------------------------------ --- 38.5/42.2 MB 147.3 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.6 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.6 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.5 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.5 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.9 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.8 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.8 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 148.1 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 148.1 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 148.1 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 148.1 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.8 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.8 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.3 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.6/42.2 MB 147.3 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.7/42.2 MB 147.2 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.7/42.2 MB 147.2 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.7/42.2 MB 147.1 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.6 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.6 kB/s eta 0:00:25\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.8 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.8 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.4 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.4 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.7/42.2 MB 146.2 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.8/42.2 MB 146.4 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.8/42.2 MB 146.8 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.8/42.2 MB 147.3 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.8/42.2 MB 147.5 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.8/42.2 MB 147.5 kB/s eta 0:00:24\n",
      "   ------------------------------------ --- 38.8/42.2 MB 147.9 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.8/42.2 MB 148.0 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.9/42.2 MB 148.4 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.9/42.2 MB 148.9 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.9/42.2 MB 148.8 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.9/42.2 MB 149.2 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.9/42.2 MB 149.2 kB/s eta 0:00:23\n",
      "   ------------------------------------ --- 38.9/42.2 MB 150.1 kB/s eta 0:00:22\n",
      "   ------------------------------------ --- 39.0/42.2 MB 150.6 kB/s eta 0:00:22\n",
      "   ------------------------------------ --- 39.0/42.2 MB 150.7 kB/s eta 0:00:22\n",
      "   ------------------------------------ --- 39.0/42.2 MB 151.2 kB/s eta 0:00:22\n",
      "   ------------------------------------ --- 39.0/42.2 MB 151.3 kB/s eta 0:00:22\n",
      "   ------------------------------------ --- 39.0/42.2 MB 151.9 kB/s eta 0:00:21\n",
      "   ------------------------------------ --- 39.0/42.2 MB 152.4 kB/s eta 0:00:21\n",
      "   ------------------------------------ --- 39.0/42.2 MB 152.4 kB/s eta 0:00:21\n",
      "   ------------------------------------ --- 39.0/42.2 MB 152.4 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 151.9 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.5 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.5 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.5 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.1 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.1 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.5 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.5 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.0 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.0 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.1/42.2 MB 152.0 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 151.6 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 151.6 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 151.2 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 151.2 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 150.9 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 150.9 kB/s eta 0:00:21\n",
      "   ------------------------------------- -- 39.2/42.2 MB 150.7 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 150.7 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 150.1 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 150.1 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 149.8 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 149.4 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 149.4 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 149.4 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.2/42.2 MB 149.4 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 147.3 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 147.9 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 148.1 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 148.1 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 148.3 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 148.3 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.3/42.2 MB 148.8 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.1 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.1 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.8 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.8 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.8 kB/s eta 0:00:20\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.6 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.6 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.6 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 148.6 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.5 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.5 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.5 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.5 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.4/42.2 MB 149.5 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.0 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.0 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 148.7 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 148.7 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 148.7 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.3 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.3 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.3 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.2 kB/s eta 0:00:19\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.5 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.5 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.5/42.2 MB 149.5 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 149.6 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 149.6 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.8 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.8 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.6 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.6 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.7 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.7 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.6/42.2 MB 150.9 kB/s eta 0:00:18\n",
      "   ------------------------------------- -- 39.7/42.2 MB 150.9 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.4 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 152.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 150.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 150.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 150.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.7/42.2 MB 150.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 149.2 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 149.2 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 149.2 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 149.2 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.9 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.9 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.9 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.5 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.5 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.5 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.5 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.5 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 148.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 146.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 146.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 146.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 146.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 146.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.8/42.2 MB 146.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.6 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.6 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.6 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.6 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.6 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 145.0 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 144.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 144.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 144.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 144.7 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 144.3 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 144.3 kB/s eta 0:00:17\n",
      "   ------------------------------------- -- 39.9/42.2 MB 143.8 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 39.9/42.2 MB 143.8 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 39.9/42.2 MB 143.8 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 39.9/42.2 MB 143.5 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 39.9/42.2 MB 143.5 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 39.9/42.2 MB 143.4 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.7 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.7 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.4 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.4 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.4 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.4 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.5 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.0/42.2 MB 143.6 kB/s eta 0:00:16\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.5 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.5 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.5 kB/s eta 0:00:15\n",
      "   ------------------------------------- -- 40.1/42.2 MB 144.5 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.1/42.2 MB 143.5 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.1/42.2 MB 143.5 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.1/42.2 MB 143.5 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.1/42.2 MB 143.9 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.1/42.2 MB 143.9 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.0 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.2 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.2 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.2 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 144.2 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:15\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 143.4 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 142.3 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 142.3 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 142.3 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 142.3 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 141.5 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 141.5 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.2/42.2 MB 141.5 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 141.6 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 141.6 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 141.6 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 141.6 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.8 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.8 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.7 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.7 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.7 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.4 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.4 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 140.0 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.3/42.2 MB 139.8 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.4/42.2 MB 139.9 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.4/42.2 MB 140.0 kB/s eta 0:00:14\n",
      "   -------------------------------------- - 40.4/42.2 MB 141.0 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.4/42.2 MB 141.0 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.4/42.2 MB 140.9 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.4/42.2 MB 141.3 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.4/42.2 MB 141.3 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.4/42.2 MB 141.7 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.4/42.2 MB 141.4 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.5/42.2 MB 141.7 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.5/42.2 MB 141.7 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.5/42.2 MB 142.1 kB/s eta 0:00:13\n",
      "   -------------------------------------- - 40.5/42.2 MB 142.5 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.5/42.2 MB 142.7 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.5/42.2 MB 142.7 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.7 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.7 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.7 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 141.4 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.0 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.0 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.0 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 142.0 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 140.6 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 140.4 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 140.4 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 140.0 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 139.6 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.6/42.2 MB 139.6 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.1 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.1 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.3 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 138.2 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.7/42.2 MB 138.2 kB/s eta 0:00:12\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 139.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 137.9 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 138.1 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.7/42.2 MB 138.1 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 138.4 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 138.4 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 138.4 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 138.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 138.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 139.2 kB/s eta 0:00:11\n",
      "   -------------------------------------- - 40.8/42.2 MB 139.6 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.8/42.2 MB 140.0 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.9/42.2 MB 140.0 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.9/42.2 MB 140.4 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.9/42.2 MB 140.0 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.9/42.2 MB 140.2 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.9/42.2 MB 140.2 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 40.9/42.2 MB 141.4 kB/s eta 0:00:10\n",
      "   -------------------------------------- - 41.0/42.2 MB 141.8 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.0/42.2 MB 141.9 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.0/42.2 MB 142.4 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.0/42.2 MB 142.9 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.0/42.2 MB 143.0 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.0/42.2 MB 143.5 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.1/42.2 MB 144.0 kB/s eta 0:00:09\n",
      "   -------------------------------------- - 41.1/42.2 MB 144.4 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 144.9 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 145.1 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 145.3 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 145.4 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 145.4 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 145.4 kB/s eta 0:00:08\n",
      "   -------------------------------------- - 41.1/42.2 MB 145.4 kB/s eta 0:00:08\n",
      "   ---------------------------------------  41.2/42.2 MB 147.0 kB/s eta 0:00:08\n",
      "   ---------------------------------------  41.2/42.2 MB 147.2 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.2/42.2 MB 147.5 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.2/42.2 MB 147.6 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.2/42.2 MB 148.0 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.3/42.2 MB 148.5 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.3/42.2 MB 148.6 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.3/42.2 MB 148.8 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.3/42.2 MB 149.5 kB/s eta 0:00:07\n",
      "   ---------------------------------------  41.3/42.2 MB 149.7 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 149.9 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 149.9 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.3/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 149.7 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 149.7 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.5 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.5 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.5 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.5 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.5 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.5 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.4 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.4 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.4 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.4 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.2 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.2 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.2 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.3 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.3 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.3 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.4/42.2 MB 150.0 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.5/42.2 MB 150.3 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.5/42.2 MB 150.3 kB/s eta 0:00:06\n",
      "   ---------------------------------------  41.5/42.2 MB 150.2 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 150.2 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 150.3 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 150.3 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 150.3 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 150.3 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 149.6 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 149.5 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 149.5 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 149.5 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.5/42.2 MB 149.5 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.4 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.4 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.2 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.0 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.0 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.2 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.2 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 149.8 kB/s eta 0:00:05\n",
      "   ---------------------------------------  41.6/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.6/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.6/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.6/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.6/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.3 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.3 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.7 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.6 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.6 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.8 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.7/42.2 MB 150.8 kB/s eta 0:00:04\n",
      "   ---------------------------------------  41.8/42.2 MB 151.2 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.8/42.2 MB 151.2 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.8/42.2 MB 151.2 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.8/42.2 MB 151.4 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.8/42.2 MB 151.2 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.8/42.2 MB 151.6 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.9/42.2 MB 152.5 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.9/42.2 MB 152.7 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.9/42.2 MB 153.1 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.9/42.2 MB 153.8 kB/s eta 0:00:03\n",
      "   ---------------------------------------  41.9/42.2 MB 154.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  41.9/42.2 MB 154.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  41.9/42.2 MB 154.8 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.0/42.2 MB 155.2 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.0/42.2 MB 155.3 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.0/42.2 MB 155.8 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.0/42.2 MB 156.9 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.0/42.2 MB 157.1 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.1/42.2 MB 157.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  42.1/42.2 MB 158.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.1/42.2 MB 158.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.1/42.2 MB 158.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.1/42.2 MB 159.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 160.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  42.2/42.2 MB 161.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.2/42.2 MB 156.8 kB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn-pandas\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 scipy-1.10.1 sklearn-pandas-2.2.0 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "%pip install sklearn-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2f611f-3f5e-4edc-8b74-f6e2fd0e139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b3e4df-7c06-43d3-bc55-a0e3b53e5e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe8a0b2-3a37-4e28-8b62-e97496210dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting taNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached ta-0.11.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from ta) (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from ta) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.11.0\n"
     ]
    }
   ],
   "source": [
    "%pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21bf916-d0d3-43eb-a132-44d122a56f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ta in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from ta) (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from ta) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas->ta) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d81af5c-b351-489e-9128-b8bb6fe4faaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seabornNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Obtaining dependency information for seaborn from https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl.metadata\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from seaborn) (1.24.4)\n",
      "Collecting pandas>=1.2 (from seaborn)\n",
      "  Obtaining dependency information for pandas>=1.2 from https://files.pythonhosted.org/packages/c3/6c/ea362eef61f05553aaf1a24b3e96b2d0603f5dc71a3bd35688a24ed88843/pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl.metadata (18 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n",
      "  Obtaining dependency information for matplotlib!=3.6.1,>=3.4 from https://files.pythonhosted.org/packages/16/51/58b0b9de42fe1e665736d9286f88b5f1556a0e22bed8a71f468231761083/matplotlib-3.7.5-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached matplotlib-3.7.5-cp38-cp38-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/96/1b/b05cd42c8d21767a0488b883b38658fb9a45f86c293b7b42521a8113dc5d/contourpy-1.1.1-cp38-cp38-win_amd64.whl.metadata\n",
      "  Using cached contourpy-1.1.1-cp38-cp38-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached matplotlib-3.7.5-cp38-cp38-win_amd64.whl (7.5 MB)\n",
      "Using cached pandas-2.0.3-cp38-cp38-win_amd64.whl (10.8 MB)\n",
      "Using cached contourpy-1.1.1-cp38-cp38-win_amd64.whl (477 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Installing collected packages: cycler, contourpy, pandas, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.1 matplotlib-3.7.5 pandas-2.0.3 seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353a283c-0506-41f8-8a0f-c8abc4165e3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pmdarimaNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pmdarima-2.0.4-cp38-cp38-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (1.4.2)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima)\n",
      "  Downloading cython-3.1.2-cp38-cp38-win_amd64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (1.10.1)\n",
      "Collecting statsmodels>=0.13.2 (from pmdarima)\n",
      "  Downloading statsmodels-0.14.1-cp38-cp38-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (2.2.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (68.2.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pmdarima) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=0.19->pmdarima) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pandas>=0.19->pmdarima) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (3.5.0)\n",
      "Collecting patsy>=0.5.4 (from statsmodels>=0.13.2->pmdarima)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima) (1.17.0)\n",
      "Downloading pmdarima-2.0.4-cp38-cp38-win_amd64.whl (615 kB)\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/615.5 kB ? eta -:--:--\n",
      "   -------------------------------- ----- 524.3/615.5 kB 140.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 524.3/615.5 kB 140.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 524.3/615.5 kB 140.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 524.3/615.5 kB 140.9 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 524.3/615.5 kB 140.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 615.5/615.5 kB 120.3 kB/s eta 0:00:00\n",
      "Downloading cython-3.1.2-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ------- -------------------------------- 0.5/2.7 MB 99.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 90.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 90.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 90.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 90.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 90.0 kB/s eta 0:00:22\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   --------------- ------------------------ 1.0/2.7 MB 113.4 kB/s eta 0:00:15\n",
      "   ------------------- -------------------- 1.3/2.7 MB 113.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 1.3/2.7 MB 113.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 1.3/2.7 MB 113.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 1.3/2.7 MB 113.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 1.3/2.7 MB 113.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 1.3/2.7 MB 113.2 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 126.0 kB/s eta 0:00:09\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 1.8/2.7 MB 127.1 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 2.1/2.7 MB 119.5 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 2.1/2.7 MB 119.5 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 2.1/2.7 MB 119.5 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 2.1/2.7 MB 119.5 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 2.1/2.7 MB 119.5 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 2.4/2.7 MB 127.1 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 2.6/2.7 MB 129.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 132.4 kB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.1-cp38-cp38-win_amd64.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   -- ------------------------------------- 0.5/10.0 MB 131.1 kB/s eta 0:01:13\n",
      "   --- ------------------------------------ 0.8/10.0 MB 140.4 kB/s eta 0:01:06\n",
      "   --- ------------------------------------ 0.8/10.0 MB 140.4 kB/s eta 0:01:06\n",
      "   --- ------------------------------------ 0.8/10.0 MB 140.4 kB/s eta 0:01:06\n",
      "   --- ------------------------------------ 0.8/10.0 MB 140.4 kB/s eta 0:01:06\n",
      "   --- ------------------------------------ 0.8/10.0 MB 140.4 kB/s eta 0:01:06\n",
      "   --- ------------------------------------ 0.8/10.0 MB 140.4 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ---- ----------------------------------- 1.0/10.0 MB 153.0 kB/s eta 0:00:59\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 122.7 kB/s eta 0:01:12\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------ --------------------------------- 1.6/10.0 MB 124.5 kB/s eta 0:01:08\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   ------- -------------------------------- 1.8/10.0 MB 116.8 kB/s eta 0:01:11\n",
      "   -------- ------------------------------- 2.1/10.0 MB 121.7 kB/s eta 0:01:06\n",
      "   -------- ------------------------------- 2.1/10.0 MB 121.7 kB/s eta 0:01:06\n",
      "   -------- ------------------------------- 2.1/10.0 MB 121.7 kB/s eta 0:01:06\n",
      "   -------- ------------------------------- 2.1/10.0 MB 121.7 kB/s eta 0:01:06\n",
      "   -------- ------------------------------- 2.1/10.0 MB 121.7 kB/s eta 0:01:06\n",
      "   -------- ------------------------------- 2.1/10.0 MB 121.7 kB/s eta 0:01:06\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   --------- ------------------------------ 2.4/10.0 MB 129.4 kB/s eta 0:01:00\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 2.6/10.0 MB 133.7 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 129.5 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------ --------------------------- 3.1/10.0 MB 124.9 kB/s eta 0:00:56\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   ------------- -------------------------- 3.4/10.0 MB 125.4 kB/s eta 0:00:53\n",
      "   -------------- ------------------------- 3.7/10.0 MB 128.6 kB/s eta 0:00:50\n",
      "   -------------- ------------------------- 3.7/10.0 MB 128.6 kB/s eta 0:00:50\n",
      "   -------------- ------------------------- 3.7/10.0 MB 128.6 kB/s eta 0:00:50\n",
      "   -------------- ------------------------- 3.7/10.0 MB 128.6 kB/s eta 0:00:50\n",
      "   -------------- ------------------------- 3.7/10.0 MB 128.6 kB/s eta 0:00:50\n",
      "   --------------- ------------------------ 3.9/10.0 MB 133.1 kB/s eta 0:00:46\n",
      "   --------------- ------------------------ 3.9/10.0 MB 133.1 kB/s eta 0:00:46\n",
      "   --------------- ------------------------ 3.9/10.0 MB 133.1 kB/s eta 0:00:46\n",
      "   --------------- ------------------------ 3.9/10.0 MB 133.1 kB/s eta 0:00:46\n",
      "   --------------- ------------------------ 3.9/10.0 MB 133.1 kB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ---------------- ----------------------- 4.2/10.0 MB 137.4 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 138.2 kB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 138.2 kB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 138.2 kB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 138.2 kB/s eta 0:00:41\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 138.2 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 4.7/10.0 MB 142.6 kB/s eta 0:00:38\n",
      "   ------------------ --------------------- 4.7/10.0 MB 142.6 kB/s eta 0:00:38\n",
      "   ------------------ --------------------- 4.7/10.0 MB 142.6 kB/s eta 0:00:38\n",
      "   ------------------ --------------------- 4.7/10.0 MB 142.6 kB/s eta 0:00:38\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   ------------------- -------------------- 5.0/10.0 MB 146.5 kB/s eta 0:00:35\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   -------------------- ------------------- 5.2/10.0 MB 144.8 kB/s eta 0:00:34\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   --------------------- ------------------ 5.5/10.0 MB 151.3 kB/s eta 0:00:30\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ----------------------- ---------------- 5.8/10.0 MB 148.5 kB/s eta 0:00:29\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------ --------------- 6.0/10.0 MB 150.7 kB/s eta 0:00:27\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   ------------------------- -------------- 6.3/10.0 MB 155.4 kB/s eta 0:00:25\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   -------------------------- ------------- 6.6/10.0 MB 154.4 kB/s eta 0:00:23\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   --------------------------- ------------ 6.8/10.0 MB 150.6 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ---------------------------- ----------- 7.1/10.0 MB 150.5 kB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 148.9 kB/s eta 0:00:19\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------ --------- 7.6/10.0 MB 155.6 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   ------------------------------- -------- 7.9/10.0 MB 145.5 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 8.1/10.0 MB 128.1 kB/s eta 0:00:15\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   --------------------------------- ------ 8.4/10.0 MB 108.7 kB/s eta 0:00:16\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 109.5 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 109.5 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 109.5 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 109.5 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 8.7/10.0 MB 109.5 kB/s eta 0:00:13\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 8.9/10.0 MB 114.2 kB/s eta 0:00:10\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 9.2/10.0 MB 108.8 kB/s eta 0:00:08\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 9.4/10.0 MB 110.3 kB/s eta 0:00:06\n",
      "   -------------------------------------- - 9.7/10.0 MB 107.7 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 9.7/10.0 MB 107.7 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 9.7/10.0 MB 107.7 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 9.7/10.0 MB 107.7 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 9.7/10.0 MB 107.7 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 9.7/10.0 MB 107.7 kB/s eta 0:00:04\n",
      "   ---------------------------------------  10.0/10.0 MB 110.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 110.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 110.6 kB/s eta 0:00:00\n",
      "Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, Cython, statsmodels, pmdarima\n",
      "Successfully installed Cython-3.1.2 patsy-1.0.1 pmdarima-2.0.4 statsmodels-0.14.1\n"
     ]
    }
   ],
   "source": [
    "%pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4771404-773c-4300-9768-7068e8c00e50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: keras in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (2.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow keras scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94d0a0c-a8d5-4664-b707-7d7d8bb165c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.43-cp38-cp38-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting tqdm (from optuna)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Using cached greenlet-3.1.1-cp38-cp38-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp38-cp38-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   --------- ------------------------------ 0.5/2.1 MB 202.1 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   -------------- ------------------------- 0.8/2.1 MB 190.7 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 1.0/2.1 MB 148.9 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 1.0/2.1 MB 148.9 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 1.0/2.1 MB 148.9 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 1.0/2.1 MB 148.9 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 1.0/2.1 MB 148.9 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 1.3/2.1 MB 163.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 1.3/2.1 MB 163.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 1.3/2.1 MB 163.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 1.3/2.1 MB 163.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 1.3/2.1 MB 163.7 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 1.3/2.1 MB 163.7 kB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 172.6 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 165.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 165.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 165.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 165.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 165.0 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 165.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 2.1/2.1 MB 171.4 kB/s eta 0:00:00\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached greenlet-3.1.1-cp38-cp38-win_amd64.whl (298 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed Mako-1.3.10 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.4.0 sqlalchemy-2.0.43 tqdm-4.67.1 typing-extensions-4.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec91ce8-0818-4aa6-a1c2-afec09d48bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikerasNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading scikeras-0.12.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikeras) (25.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikeras) (1.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem<0.32,>=0.23.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikeras) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mariy\\pycharmprojects\\copy_dp\\.venv\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (3.5.0)\n",
      "Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.12.0\n"
     ]
    }
   ],
   "source": [
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "644fe7ab-29cd-4c19-8d0a-63bc2168c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PolynomialFeatures\n",
    "import ta\n",
    "from ta.trend import SMAIndicator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c7317b-b2be-4cfe-a2bd-32e0c7cc8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_1 = pd.read_csv('merged_company_1.csv')\n",
    "merged_df_2 = pd.read_csv('merged_company_2.csv')\n",
    "merged_df_6 = pd.read_csv('merged_company_6.csv')\n",
    "merged_df_7 = pd.read_csv('merged_company_7.csv')\n",
    "merged_df_8 = pd.read_csv('merged_company_8.csv')\n",
    "merged_df_9 = pd.read_csv('merged_company_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1fff8f6-02bc-400c-8541-378ccb9077ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriches_data_st(df):\n",
    "  \"\"\"\n",
    "    ,     \n",
    "  (   5 ,    20 ,\n",
    "     (RSI),  ,\n",
    "     ,         .).\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  df['SMA_5'] = ta.trend.SMAIndicator(close=df['CLOSE'], window=5).sma_indicator()\n",
    "  df['SMA_20'] = ta.trend.SMAIndicator(close=df['CLOSE'], window=20).sma_indicator()\n",
    "  df['RSI'] = ta.momentum.RSIIndicator(close=df['CLOSE'], window=14).rsi()\n",
    "  stoch = ta.momentum.StochasticOscillator(high=df['HIGH'],low=df['LOW'],close=df['CLOSE'],window=14,smooth_window=3)\n",
    "  df['%K'] = stoch.stoch()\n",
    "  df['%D'] = stoch.stoch_signal()\n",
    "  df['MACD'] = ta.trend.MACD(close=df['CLOSE'], window_slow=26, window_fast=12).macd()\n",
    "  df['MACD_signal'] = ta.trend.MACD(close=df['CLOSE'], window_slow=26, window_fast=12).macd_signal()\n",
    "  df['Target_MACD'] = df['CLOSE'].shift(-1) > df['CLOSE']\n",
    "  df['Target_MACD'] = df['Target_MACD'].astype(int)\n",
    "  df['Target'] = (df['CLOSE'].shift(-1) > df['CLOSE']).astype(int)\n",
    "\n",
    "  df['Price_Change'] = df['CLOSE'].diff()\n",
    "  df['Price_Change_Percent'] = (df['CLOSE'] / df['CLOSE'].shift(1) - 1) * 100\n",
    "  df['year'] = df['date'].dt.year\n",
    "  df['month'] = df['date'].dt.month\n",
    "  df['day'] = df['date'].dt.day\n",
    "  df['day_of_week'] = df['date'].dt.dayofweek\n",
    "  df['is_weekend'] = df['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "  df['quarter'] = df['date'].dt.quarter\n",
    "\n",
    "  df.fillna(method='bfill', inplace=True)\n",
    "  df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd0b1ae2-3015-4104-8c66-108254cfe370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriches_data_key_rate(df):\n",
    "\n",
    "  \"\"\"\n",
    "    ,     \n",
    "  (   5 ,    20 ,\n",
    "        ,\n",
    "         ).\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  enriches_data_st(df)\n",
    "\n",
    "  df['key_rate_SMA_5'] = df['value_key_rate'].rolling(window=5).mean()\n",
    "  df['key_rate_SMA_20'] = df['value_key_rate'].rolling(window=20).mean()\n",
    "  df['key_rate_change'] = df['value_key_rate'].pct_change()\n",
    "  df['key_rate_close_interaction'] = df['value_key_rate'] * df['CLOSE']\n",
    "\n",
    "  df.fillna(method='bfill', inplace=True)\n",
    "  df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3004e893-abac-4fff-8277-2d4d086afab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriches_data_currency(df):\n",
    "\n",
    "  \"\"\"\n",
    "    ,     \n",
    "  (   5 ,    20 ,\n",
    "        ,\n",
    "         ).\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  enriches_data_st(df)\n",
    "\n",
    "  df['currency_SMA_5'] = df['value_currency'].rolling(window=5).mean()\n",
    "  df['currency_SMA_20'] = df['value_currency'].rolling(window=20).mean()\n",
    "  df['currency_change'] = df['value_currency'].pct_change()\n",
    "  df['currency_close_interaction'] = df['value_currency'] * df['CLOSE']\n",
    "\n",
    "  df.fillna(method='bfill', inplace=True)\n",
    "  df.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d94b66-0534-4934-ba16-f37d05fb07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enriches_data_all(df):\n",
    "\n",
    "  enriches_data_st(df)\n",
    "  enriches_data_key_rate(df)\n",
    "  enriches_data_currency(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6660324-cfd4-4b0a-8f0c-2c63b8fccf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_1['date'] = pd.to_datetime(merged_df_1['date'])\n",
    "merged_df_2['date'] = pd.to_datetime(merged_df_2['date'])\n",
    "merged_df_6['date'] = pd.to_datetime(merged_df_6['date'])\n",
    "merged_df_7['date'] = pd.to_datetime(merged_df_7['date'])\n",
    "merged_df_8['date'] = pd.to_datetime(merged_df_8['date'])\n",
    "merged_df_9['date'] = pd.to_datetime(merged_df_9['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b5e24b4-a7d5-488b-86c1-4c827d13b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriches_data_st(merged_df_6)\n",
    "enriches_data_st(merged_df_7)\n",
    "enriches_data_st(merged_df_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27bd6558-13ef-4471-830d-c6470c63fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriches_data_key_rate(merged_df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214032bb-9eeb-4962-a8fb-c729f667e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriches_data_currency(merged_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e862fc6c-c0c1-4bc8-8bab-4552c59acbf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enriches_data_all(merged_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4499e1d2-2906-4cdb-a2a3-007f67515774",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_6_7_9 = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOL', 'value_key_rate', 'value_petroleum', 'value_currency', 'SMA_5', 'SMA_20', 'RSI', '%K', '%D', 'MACD', 'MACD_signal', 'Price_Change', 'Price_Change_Percent']\n",
    "features_8 = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOL', 'value_key_rate', 'value_petroleum', 'value_currency', 'SMA_5', 'SMA_20', 'RSI', '%K', '%D', 'MACD', 'MACD_signal', 'Price_Change', 'Price_Change_Percent', 'key_rate_SMA_5', 'key_rate_SMA_20', 'key_rate_change', 'key_rate_close_interaction']\n",
    "features_2 = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOL', 'value_key_rate', 'value_petroleum', 'value_currency', 'SMA_5', 'SMA_20', 'RSI', '%K', '%D', 'MACD', 'MACD_signal', 'Price_Change', 'Price_Change_Percent', 'currency_SMA_5', 'currency_SMA_20', 'currency_change', 'currency_close_interaction']\n",
    "features_1 = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOL', 'value_key_rate', 'value_petroleum', 'value_currency', 'SMA_5', 'SMA_20', 'RSI', '%K', '%D', 'MACD', 'MACD_signal', 'Price_Change', 'Price_Change_Percent', 'key_rate_SMA_5', 'key_rate_SMA_20', 'key_rate_change', 'key_rate_close_interaction', 'currency_SMA_5', 'currency_SMA_20', 'currency_change', 'currency_close_interaction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd60507-e79f-41f2-a38f-bf420818846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizes_data(df, features):\n",
    "    \"\"\"\n",
    "      () ,  RobustScaler,\n",
    "       'CLOSE'.\n",
    "    \"\"\"\n",
    "\n",
    "    df_normalized = df.copy()\n",
    "\n",
    "    features_to_scale = features + ['CLOSE']\n",
    "    X = df_normalized[features_to_scale]\n",
    "\n",
    "    scaler = RobustScaler()\n",
    "\n",
    "    X = scaler.fit_transform(X)\n",
    "    df_normalized[features_to_scale] = X\n",
    "\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50d78318-cd3f-4b78-ab94-9f38018a0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizes_df_1 = normalizes_data(merged_df_1, features_1)\n",
    "normalizes_df_2 = normalizes_data(merged_df_2, features_2)\n",
    "normalizes_df_6 = normalizes_data(merged_df_6, features_6_7_9)\n",
    "normalizes_df_7 = normalizes_data(merged_df_7, features_6_7_9)\n",
    "normalizes_df_8 = normalizes_data(merged_df_8, features_8)\n",
    "normalizes_df_9 = normalizes_data(merged_df_9, features_6_7_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a89e298-9fbc-41f6-919a-aeb5ed6b47de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1178 entries, 0 to 1177\n",
      "Data columns (total 27 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   TICKER                1178 non-null   object        \n",
      " 1   date                  1178 non-null   datetime64[ns]\n",
      " 2   OPEN                  1178 non-null   float64       \n",
      " 3   HIGH                  1178 non-null   float64       \n",
      " 4   LOW                   1178 non-null   float64       \n",
      " 5   CLOSE                 1178 non-null   float64       \n",
      " 6   VOL                   1178 non-null   float64       \n",
      " 7   value_key_rate        1178 non-null   float64       \n",
      " 8   value_petroleum       1178 non-null   float64       \n",
      " 9   value_currency        1178 non-null   float64       \n",
      " 10  SMA_5                 1178 non-null   float64       \n",
      " 11  SMA_20                1178 non-null   float64       \n",
      " 12  RSI                   1178 non-null   float64       \n",
      " 13  %K                    1178 non-null   float64       \n",
      " 14  %D                    1178 non-null   float64       \n",
      " 15  MACD                  1178 non-null   float64       \n",
      " 16  MACD_signal           1178 non-null   float64       \n",
      " 17  Target_MACD           1178 non-null   int32         \n",
      " 18  Target                1178 non-null   int32         \n",
      " 19  Price_Change          1178 non-null   float64       \n",
      " 20  Price_Change_Percent  1178 non-null   float64       \n",
      " 21  year                  1178 non-null   int32         \n",
      " 22  month                 1178 non-null   int32         \n",
      " 23  day                   1178 non-null   int32         \n",
      " 24  day_of_week           1178 non-null   int32         \n",
      " 25  is_weekend            1178 non-null   int64         \n",
      " 26  quarter               1178 non-null   int32         \n",
      "dtypes: datetime64[ns](1), float64(17), int32(7), int64(1), object(1)\n",
      "memory usage: 216.4+ KB\n"
     ]
    }
   ],
   "source": [
    "normalizes_df_9.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ea5920-3334-4f5f-8ed6-64f34a98b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divides_into_samples(df):\n",
    "    \"\"\" DataFrame  ,     \n",
    "      Timestamp   .\"\"\"\n",
    "\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].astype(np.int64) // 10**9\n",
    "\n",
    "    df = df.select_dtypes(include=[np.number])\n",
    "    if 'CLOSE' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain a 'CLOSE' column.\")\n",
    "\n",
    "    X = df.drop('CLOSE', axis=1)\n",
    "    y = df['CLOSE']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "    return X_train, X_test, X_val, y_val, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7af57ad7-945a-4637-b9c4-5ceb6b55b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression_testing(df):\n",
    "\n",
    "    \"\"\"\n",
    "           \n",
    "      .   GridSearchCV  \n",
    "            \n",
    "     .\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    df = df.drop(columns=['TICKER', 'date'], axis=1) \n",
    "    X_train, X_test, X_val, y_val, y_train, y_test = divides_into_samples(df)\n",
    "\n",
    "    param_grid = {'polynomialfeatures__degree': np.arange(1, 11)}\n",
    "\n",
    "    pipe = Pipeline([('polynomialfeatures', PolynomialFeatures()),\n",
    "                     ('linearregression', LinearRegression())])\n",
    "\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    print(\" :\", grid.best_params_)\n",
    "    print(\" cross-validation score:\", -grid.best_score_)\n",
    "\n",
    "    y_pred_val = grid.predict(X_val)\n",
    "\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    print(f\"MSE   : {mse_val}\")\n",
    "\n",
    "    y_pred_test = grid.predict(X_test)\n",
    "\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    print(f\"MSE   : {mse_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d5d5144-8215-4c06-8164-bce717c9491f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.9 GiB for an array with shape (771, 2760681) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.9 GiB for an array with shape (772, 2760681) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 88.4 GiB for an array with shape (771, 15380937) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 88.5 GiB for an array with shape (772, 15380937) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 442. GiB for an array with shape (771, 76904685) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 442. GiB for an array with shape (772, 76904685) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.97 TiB for an array with shape (771, 350343565) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.97 TiB for an array with shape (772, 350343565) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.25 TiB for an array with shape (771, 1471442973) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 8.27 TiB for an array with shape (772, 1471442973) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-8.57389599e-05 -1.51345055e-05 -7.11837160e-04 -8.64178888e-04\n",
      " -8.70204343e-04             nan             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : {'polynomialfeatures__degree': 2}\n",
      " cross-validation score: 1.5134505483518034e-05\n",
      "MSE   : 5.692116208988932e-06\n",
      "MSE   : 1.9825169527664904e-06\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_testing_1 = polynomial_regression_testing(normalizes_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ba6779-4c3c-40f2-b81e-6c77fa8a006c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 693, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 238, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 986, in check_array\n",
      "    array = _asarray_with_order(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 378, in _asarray_with_order\n",
      "    array = numpy.array(array, order=order, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 7.74 GiB for an array with shape (772, 1344904) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 693, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 238, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 986, in check_array\n",
      "    array = _asarray_with_order(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 378, in _asarray_with_order\n",
      "    array = numpy.array(array, order=order, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 7.75 GiB for an array with shape (773, 1344904) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.7 GiB for an array with shape (772, 6724520) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.7 GiB for an array with shape (773, 6724520) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 174. GiB for an array with shape (772, 30260340) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 174. GiB for an array with shape (773, 30260340) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 716. GiB for an array with shape (772, 124403620) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 716. GiB for an array with shape (773, 124403620) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.66 TiB for an array with shape (772, 472733756) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.66 TiB for an array with shape (773, 472733756) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-1.32135088e-04 -3.98753615e-06 -1.23054837e-05 -1.20829288e-05\n",
      " -1.22231267e-05             nan             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : {'polynomialfeatures__degree': 2}\n",
      " cross-validation score: 3.987536151713038e-06\n",
      "MSE   : 5.9309905272914595e-06\n",
      "MSE   : 0.00014148056128369\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_testing_1 = polynomial_regression_testing(normalizes_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c17b5de9-696a-4362-9819-a58d19f2d894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : {'polynomialfeatures__degree': 1}\n",
      " cross-validation score: 0.00014577971549082315\n",
      "MSE   : 0.0001610168488163948\n",
      "MSE   : 0.00023999421737314045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 GiB for an array with shape (772, 2629575) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 GiB for an array with shape (773, 2629575) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 60.5 GiB for an array with shape (772, 10518300) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 60.6 GiB for an array with shape (773, 10518300) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 222. GiB for an array with shape (772, 38567100) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 222. GiB for an array with shape (773, 38567100) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 754. GiB for an array with shape (772, 131128140) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 755. GiB for an array with shape (773, 131128140) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-0.00014578 -0.00028277 -0.00542464 -0.00415026 -0.00426905 -0.00421005\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_testing_1 = polynomial_regression_testing(normalizes_df_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d5cab7e-84ae-41fa-988a-c775dcabc1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : {'polynomialfeatures__degree': 1}\n",
      " cross-validation score: 0.0001387556827289939\n",
      "MSE   : 0.00015228668754870757\n",
      "MSE   : 0.0003995253021665673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 GiB for an array with shape (772, 2629575) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 15.1 GiB for an array with shape (773, 2629575) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 60.5 GiB for an array with shape (772, 10518300) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 60.6 GiB for an array with shape (773, 10518300) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 222. GiB for an array with shape (772, 38567100) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 222. GiB for an array with shape (773, 38567100) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 754. GiB for an array with shape (772, 131128140) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 755. GiB for an array with shape (773, 131128140) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-0.00013876 -0.00022636 -0.0115377  -0.01838231 -0.01840791 -0.01860848\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_testing_1 = polynomial_regression_testing(normalizes_df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8caeca41-5c39-4dc4-b31b-f3a9160a8a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : {'polynomialfeatures__degree': 1}\n",
      " cross-validation score: 7.643469336893053e-05\n",
      "MSE   : 3.7227923531386444e-05\n",
      "MSE   : 0.00010600556740012477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 693, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 238, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 986, in check_array\n",
      "    array = _asarray_with_order(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 378, in _asarray_with_order\n",
      "    array = numpy.array(array, order=order, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 7.72 GiB for an array with shape (770, 1344904) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 427, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 693, in fit\n",
      "    X, y, X_offset, y_offset, X_scale = _preprocess_data(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\", line 238, in _preprocess_data\n",
      "    X = check_array(X, copy=copy, accept_sparse=[\"csr\", \"csc\"], dtype=FLOAT_DTYPES)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 986, in check_array\n",
      "    array = _asarray_with_order(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 378, in _asarray_with_order\n",
      "    array = numpy.array(array, order=order, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 7.73 GiB for an array with shape (771, 1344904) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.6 GiB for an array with shape (770, 6724520) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 38.6 GiB for an array with shape (771, 6724520) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 174. GiB for an array with shape (770, 30260340) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 174. GiB for an array with shape (771, 30260340) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 714. GiB for an array with shape (770, 124403620) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 715. GiB for an array with shape (771, 124403620) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.65 TiB for an array with shape (770, 472733756) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.65 TiB for an array with shape (771, 472733756) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-7.64346934e-05 -1.33300030e-04 -8.63905742e-03 -9.84557746e-03\n",
      " -9.91528614e-03             nan             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_testing_1 = polynomial_regression_testing(normalizes_df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "270dab8a-d2bf-47d9-bea1-a92b45d56a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " : {'polynomialfeatures__degree': 1}\n",
      " cross-validation score: 6.528222075662133e-05\n",
      "MSE   : 9.63424948724584e-05\n",
      "MSE   : 6.051644377374832e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.8 GiB for an array with shape (753, 2629575) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.8 GiB for an array with shape (754, 2629575) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 59.0 GiB for an array with shape (753, 10518300) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 59.1 GiB for an array with shape (754, 10518300) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 216. GiB for an array with shape (753, 38567100) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 217. GiB for an array with shape (754, 38567100) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 736. GiB for an array with shape (753, 131128140) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py\", line 507, in transform\n",
      "    XP = np.empty(\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 737. GiB for an array with shape (754, 131128140) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [-6.52822208e-05 -6.95741925e-05 -2.85689871e-03 -1.91616085e-03\n",
      " -1.91279801e-03 -1.90905080e-03             nan             nan\n",
      "             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression_testing_1 = polynomial_regression_testing(normalizes_df_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6e75795-5ede-4cd2-8137-44645d567c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps):\n",
    "    \"\"\"\n",
    "          ,   \n",
    "     LSTM.\n",
    "\n",
    "    \"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)] \n",
    "        Xs.append(v)\n",
    "        if isinstance(y, pd.Series):\n",
    "            ys.append(y.iloc[i + time_steps])\n",
    "        else:\n",
    "            ys.append(y[i + time_steps])\n",
    "\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "935cc523-8027-4cff-a7ba-8e965259c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, time_steps):\n",
    "    \"\"\"\n",
    "            ,   LSTM.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, X_val, y_val, y_train, y_test = divides_into_samples(df)\n",
    "\n",
    "    X_train, y_train = create_dataset(X_train.to_numpy(), y_train.to_numpy(), time_steps)\n",
    "    X_val, y_val = create_dataset(X_val.to_numpy(), y_val.to_numpy(), time_steps)\n",
    "    X_test, y_test = create_dataset(X_test.to_numpy(), y_test.to_numpy(), time_steps)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66963fa5-32ee-40ed-850e-7efca26e0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(trial, input_shape):\n",
    "    \"\"\"  RNN  LSTM .\"\"\"\n",
    "    model = Sequential()\n",
    "    lstm_units = trial.suggest_int('lstm_units', 50, 100)\n",
    "\n",
    "    model.add(LSTM(lstm_units, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(lstm_units))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, time_steps):\n",
    "    \"\"\"   Optuna.\"\"\"\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = create_rnn_model(trial, input_shape)\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    return mse_val\n",
    "\n",
    "def RNN_testing(df):\n",
    "    \"\"\"  RNN,  Optuna  .\"\"\"\n",
    "\n",
    "    time_steps = 10\n",
    "    X_train, X_test, X_val, y_val, y_train, y_test = divides_into_samples(df)\n",
    "\n",
    "    X_train, y_train = create_dataset(X_train.to_numpy(), y_train.to_numpy(), time_steps)\n",
    "    X_val, y_val = create_dataset(X_val.to_numpy(), y_val.to_numpy(), time_steps)\n",
    "    X_test, y_test = create_dataset(X_test.to_numpy(), y_test.to_numpy(), time_steps)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "    def objective_wrapper(trial):\n",
    "        return objective(trial, X_train, y_train, X_val, y_val, time_steps)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective_wrapper, n_trials=100)\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best validation MSE:\", study.best_value)\n",
    "\n",
    "    best_lstm_units = study.best_params['lstm_units']\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = create_rnn_model(study.best_trial, input_shape)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=best_learning_rate), loss='mean_squared_error')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    print(f\"MSE   : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dce1565e-e123-4ec9-8467-77afeb4860f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:51:37,817] A new study created in memory with name: no-name-f9f8bf4b-222b-4c0b-9004-ea5d3a3a0291\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:51:46,710] Trial 0 finished with value: 0.4114159112556903 and parameters: {'lstm_units': 68, 'learning_rate': 0.0022591583481271814}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114159112556903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:51:58,780] Trial 1 finished with value: 0.4129115056264966 and parameters: {'lstm_units': 100, 'learning_rate': 0.0005702618625551567}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129115056264966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:52:12,342] Trial 2 finished with value: 0.41148918000031465 and parameters: {'lstm_units': 98, 'learning_rate': 0.009138162346484825}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148918000031465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:52:21,981] Trial 3 finished with value: 0.4142107800290218 and parameters: {'lstm_units': 72, 'learning_rate': 0.00011186941265205872}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4142107800290218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:52:30,202] Trial 4 finished with value: 0.4115125433888109 and parameters: {'lstm_units': 56, 'learning_rate': 0.00875730067260126}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115125433888109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:52:36,401] Trial 5 finished with value: 0.41512005841112104 and parameters: {'lstm_units': 54, 'learning_rate': 0.0003515952466568785}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41512005841112104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:52:47,561] Trial 6 finished with value: 0.41163262325890954 and parameters: {'lstm_units': 95, 'learning_rate': 0.002654311285789457}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41163262325890954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:52:57,213] Trial 7 finished with value: 0.4121713031484376 and parameters: {'lstm_units': 62, 'learning_rate': 0.00525809767285229}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4121713031484376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:53:06,379] Trial 8 finished with value: 0.4135265967785024 and parameters: {'lstm_units': 78, 'learning_rate': 0.00015915144799059816}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4135265967785024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:53:16,386] Trial 9 finished with value: 0.41149602174424593 and parameters: {'lstm_units': 57, 'learning_rate': 0.0005433437888747274}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149602174424593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:53:25,165] Trial 10 finished with value: 0.4119133212761786 and parameters: {'lstm_units': 79, 'learning_rate': 0.0018196657202089461}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119133212761786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:53:38,167] Trial 11 finished with value: 0.41192139856478355 and parameters: {'lstm_units': 88, 'learning_rate': 0.0032834465650969473}. Best is trial 0 with value: 0.4114159112556903.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41192139856478355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:53:46,880] Trial 12 finished with value: 0.4113859020142228 and parameters: {'lstm_units': 68, 'learning_rate': 0.00135118311806066}. Best is trial 12 with value: 0.4113859020142228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113859020142228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:53:55,417] Trial 13 finished with value: 0.41161293804618104 and parameters: {'lstm_units': 67, 'learning_rate': 0.001584425184581415}. Best is trial 12 with value: 0.4113859020142228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41161293804618104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:54:07,107] Trial 14 finished with value: 0.41159655661570677 and parameters: {'lstm_units': 70, 'learning_rate': 0.0010843763016655668}. Best is trial 12 with value: 0.4113859020142228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41159655661570677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:54:15,357] Trial 15 finished with value: 0.41144688593163853 and parameters: {'lstm_units': 64, 'learning_rate': 0.0009093148003487981}. Best is trial 12 with value: 0.4113859020142228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144688593163853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:54:23,741] Trial 16 finished with value: 0.41410762862446576 and parameters: {'lstm_units': 84, 'learning_rate': 0.0037692886774571143}. Best is trial 12 with value: 0.4113859020142228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41410762862446576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:54:32,339] Trial 17 finished with value: 0.41138521821471713 and parameters: {'lstm_units': 74, 'learning_rate': 0.0018104700676828504}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138521821471713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:54:41,487] Trial 18 finished with value: 0.41367170671218423 and parameters: {'lstm_units': 75, 'learning_rate': 0.001131324811760622}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41367170671218423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:54:49,096] Trial 19 finished with value: 0.41141875213169116 and parameters: {'lstm_units': 50, 'learning_rate': 0.00029238062856170406}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141875213169116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:55:06,963] Trial 20 finished with value: 0.41302646376334395 and parameters: {'lstm_units': 84, 'learning_rate': 0.004812803591063325}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41302646376334395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:55:14,021] Trial 21 finished with value: 0.4114014187186202 and parameters: {'lstm_units': 62, 'learning_rate': 0.002360117425807455}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114014187186202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:55:22,273] Trial 22 finished with value: 0.4114437499876365 and parameters: {'lstm_units': 61, 'learning_rate': 0.0013735172946036608}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114437499876365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:55:34,476] Trial 23 finished with value: 0.411569115330879 and parameters: {'lstm_units': 74, 'learning_rate': 0.0008305206180393935}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411569115330879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:55:41,840] Trial 24 finished with value: 0.41305378787025415 and parameters: {'lstm_units': 66, 'learning_rate': 0.0020726319940270843}. Best is trial 17 with value: 0.41138521821471713.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41305378787025415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:55:51,689] Trial 25 finished with value: 0.41138487540895147 and parameters: {'lstm_units': 59, 'learning_rate': 0.0006244213755332416}. Best is trial 25 with value: 0.41138487540895147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138487540895147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:56:00,735] Trial 26 finished with value: 0.41140947395655814 and parameters: {'lstm_units': 58, 'learning_rate': 0.0005604365486261152}. Best is trial 25 with value: 0.41138487540895147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140947395655814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:56:08,323] Trial 27 finished with value: 0.41200071664041404 and parameters: {'lstm_units': 50, 'learning_rate': 0.0003363564054582737}. Best is trial 25 with value: 0.41138487540895147.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41200071664041404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:56:17,949] Trial 28 finished with value: 0.41138400858577734 and parameters: {'lstm_units': 78, 'learning_rate': 0.0006257727897449997}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138400858577734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:56:27,510] Trial 29 finished with value: 0.41140467882011755 and parameters: {'lstm_units': 79, 'learning_rate': 0.0007234984995596049}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140467882011755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:56:42,161] Trial 30 finished with value: 0.41146844103028807 and parameters: {'lstm_units': 84, 'learning_rate': 0.00042379365709799494}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146844103028807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:56:54,379] Trial 31 finished with value: 0.41140320241261086 and parameters: {'lstm_units': 71, 'learning_rate': 0.0012931564608306034}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140320241261086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:57:04,745] Trial 32 finished with value: 0.4119517125317526 and parameters: {'lstm_units': 68, 'learning_rate': 0.0006988827181938547}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119517125317526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:57:24,197] Trial 33 finished with value: 0.41138524716817554 and parameters: {'lstm_units': 78, 'learning_rate': 0.0004352636157682222}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138524716817554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:57:36,306] Trial 34 finished with value: 0.4115007328448741 and parameters: {'lstm_units': 91, 'learning_rate': 0.00021420446483697957}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115007328448741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:57:47,104] Trial 35 finished with value: 0.4114435166317094 and parameters: {'lstm_units': 81, 'learning_rate': 0.00045279730327911326}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114435166317094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:57:55,862] Trial 36 finished with value: 0.41148090243815466 and parameters: {'lstm_units': 88, 'learning_rate': 0.0002500961574066644}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148090243815466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:58:04,235] Trial 37 finished with value: 0.4118441472340911 and parameters: {'lstm_units': 76, 'learning_rate': 0.0006377620136759436}. Best is trial 28 with value: 0.41138400858577734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118441472340911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:58:17,231] Trial 38 finished with value: 0.41080613484751854 and parameters: {'lstm_units': 82, 'learning_rate': 0.0001745461359652833}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41080613484751854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:58:27,303] Trial 39 finished with value: 0.41115307847256877 and parameters: {'lstm_units': 95, 'learning_rate': 0.00013922843906076277}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41115307847256877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:58:41,332] Trial 40 finished with value: 0.4120015311143788 and parameters: {'lstm_units': 99, 'learning_rate': 0.00011117054265563722}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120015311143788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:58:57,616] Trial 41 finished with value: 0.41187379900532645 and parameters: {'lstm_units': 94, 'learning_rate': 0.0001434305879001077}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41187379900532645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:59:07,964] Trial 42 finished with value: 0.41179013269771686 and parameters: {'lstm_units': 82, 'learning_rate': 0.0001612250712013887}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41179013269771686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:59:20,570] Trial 43 finished with value: 0.4113871492130185 and parameters: {'lstm_units': 95, 'learning_rate': 0.0001932104072111087}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113871492130185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:59:29,525] Trial 44 finished with value: 0.41141071078702346 and parameters: {'lstm_units': 89, 'learning_rate': 0.00013892597316798657}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141071078702346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:59:38,537] Trial 45 finished with value: 0.41138382299821646 and parameters: {'lstm_units': 91, 'learning_rate': 0.0001012483666564024}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138382299821646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 18:59:53,817] Trial 46 finished with value: 0.4113260947497296 and parameters: {'lstm_units': 93, 'learning_rate': 0.0001057124073673756}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113260947497296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:00:02,918] Trial 47 finished with value: 0.41337415027127916 and parameters: {'lstm_units': 97, 'learning_rate': 0.00010628322480887499}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41337415027127916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:00:16,543] Trial 48 finished with value: 0.4115689057711703 and parameters: {'lstm_units': 92, 'learning_rate': 0.00012952851076428258}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115689057711703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:00:27,761] Trial 49 finished with value: 0.4113696338136961 and parameters: {'lstm_units': 100, 'learning_rate': 0.00017685601838267448}. Best is trial 38 with value: 0.41080613484751854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113696338136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:00:38,330] Trial 50 finished with value: 0.41066186328808457 and parameters: {'lstm_units': 100, 'learning_rate': 0.00019688377824839074}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41066186328808457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:00:50,654] Trial 51 finished with value: 0.4119565283526661 and parameters: {'lstm_units': 100, 'learning_rate': 0.00017787339984515966}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119565283526661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:01:00,185] Trial 52 finished with value: 0.41291183236790235 and parameters: {'lstm_units': 97, 'learning_rate': 0.0002270499473062316}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41291183236790235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:01:12,396] Trial 53 finished with value: 0.4106821547169416 and parameters: {'lstm_units': 93, 'learning_rate': 0.00010021157023286798}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4106821547169416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:01:24,017] Trial 54 finished with value: 0.4112763379634597 and parameters: {'lstm_units': 94, 'learning_rate': 0.0001288731958732756}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4112763379634597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:01:35,168] Trial 55 finished with value: 0.41182864700355537 and parameters: {'lstm_units': 93, 'learning_rate': 0.00012813966525366405}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41182864700355537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:01:50,976] Trial 56 finished with value: 0.411648503442187 and parameters: {'lstm_units': 96, 'learning_rate': 0.00028188254216377547}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411648503442187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:02:03,170] Trial 57 finished with value: 0.41214697634266784 and parameters: {'lstm_units': 88, 'learning_rate': 0.00012736215493461847}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41214697634266784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:02:16,364] Trial 58 finished with value: 0.4113639153611947 and parameters: {'lstm_units': 90, 'learning_rate': 0.00015554306143972886}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113639153611947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:02:31,898] Trial 59 finished with value: 0.4114800622565741 and parameters: {'lstm_units': 98, 'learning_rate': 0.00019676389158084404}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114800622565741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:02:43,137] Trial 60 finished with value: 0.41089687751294757 and parameters: {'lstm_units': 87, 'learning_rate': 0.00011840586258611193}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41089687751294757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:02:55,324] Trial 61 finished with value: 0.4115909047932676 and parameters: {'lstm_units': 86, 'learning_rate': 0.0001232296170487932}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115909047932676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:03:08,489] Trial 62 finished with value: 0.41166511293021485 and parameters: {'lstm_units': 94, 'learning_rate': 0.00010458632156112036}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41166511293021485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:03:20,660] Trial 63 finished with value: 0.411284945754718 and parameters: {'lstm_units': 86, 'learning_rate': 0.0001527104744188785}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411284945754718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:03:28,917] Trial 64 finished with value: 0.4115040375834766 and parameters: {'lstm_units': 86, 'learning_rate': 0.0001551851074422358}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115040375834766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:03:37,546] Trial 65 finished with value: 0.4118183273347885 and parameters: {'lstm_units': 86, 'learning_rate': 0.008134829871953244}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118183273347885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:03:45,002] Trial 66 finished with value: 0.4112984391535309 and parameters: {'lstm_units': 82, 'learning_rate': 0.0002479454198507569}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4112984391535309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:03:54,308] Trial 67 finished with value: 0.4113842228707831 and parameters: {'lstm_units': 96, 'learning_rate': 0.0001735859775765734}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113842228707831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:04:04,930] Trial 68 finished with value: 0.4113975741307573 and parameters: {'lstm_units': 90, 'learning_rate': 0.0003397694887706785}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113975741307573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:04:16,083] Trial 69 finished with value: 0.41157232030261287 and parameters: {'lstm_units': 98, 'learning_rate': 0.00020207139297018955}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41157232030261287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:04:25,617] Trial 70 finished with value: 0.41196740608957594 and parameters: {'lstm_units': 87, 'learning_rate': 0.00012039402424693198}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41196740608957594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:04:33,143] Trial 71 finished with value: 0.41145244555598104 and parameters: {'lstm_units': 82, 'learning_rate': 0.0002449334187615165}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145244555598104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:04:42,583] Trial 72 finished with value: 0.4113839818228537 and parameters: {'lstm_units': 84, 'learning_rate': 0.0002834231024349365}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113839818228537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:04:52,497] Trial 73 finished with value: 0.41116424392286605 and parameters: {'lstm_units': 83, 'learning_rate': 0.00015837897958644498}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41116424392286605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:05,792] Trial 74 finished with value: 0.411485390916614 and parameters: {'lstm_units': 80, 'learning_rate': 0.00014076173364078063}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411485390916614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:16,482] Trial 75 finished with value: 0.413141454994222 and parameters: {'lstm_units': 92, 'learning_rate': 0.0001489402121364212}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.413141454994222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:24,568] Trial 76 finished with value: 0.41139027559027785 and parameters: {'lstm_units': 85, 'learning_rate': 0.00011816238811477246}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139027559027785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:32,295] Trial 77 finished with value: 0.41183260144602435 and parameters: {'lstm_units': 89, 'learning_rate': 0.00017469975492967113}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41183260144602435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:41,268] Trial 78 finished with value: 0.411813657066001 and parameters: {'lstm_units': 76, 'learning_rate': 0.00021894008442453422}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411813657066001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:49,060] Trial 79 finished with value: 0.41073295250442715 and parameters: {'lstm_units': 96, 'learning_rate': 0.0001342195395926913}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41073295250442715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:05:57,336] Trial 80 finished with value: 0.4110613207416657 and parameters: {'lstm_units': 96, 'learning_rate': 0.00011552637440479697}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4110613207416657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:06:06,012] Trial 81 finished with value: 0.4114559824584264 and parameters: {'lstm_units': 95, 'learning_rate': 0.00011388927858984975}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114559824584264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:06:15,220] Trial 82 finished with value: 0.41116994706932664 and parameters: {'lstm_units': 99, 'learning_rate': 0.00013466841389023275}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41116994706932664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:06:31,888] Trial 83 finished with value: 0.41145156799602645 and parameters: {'lstm_units': 98, 'learning_rate': 0.00018550778507707636}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145156799602645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:06:45,045] Trial 84 finished with value: 0.412321005773086 and parameters: {'lstm_units': 99, 'learning_rate': 0.00010161539837793845}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.412321005773086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:06:53,822] Trial 85 finished with value: 0.4114051753539999 and parameters: {'lstm_units': 96, 'learning_rate': 0.00013851264873322044}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114051753539999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:07:04,545] Trial 86 finished with value: 0.4128668701118814 and parameters: {'lstm_units': 100, 'learning_rate': 0.00016504576159588675}. Best is trial 50 with value: 0.41066186328808457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4128668701118814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:07:14,500] Trial 87 finished with value: 0.41061684482826427 and parameters: {'lstm_units': 93, 'learning_rate': 0.00011677448827640953}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41061684482826427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:07:23,617] Trial 88 finished with value: 0.41203969462784706 and parameters: {'lstm_units': 92, 'learning_rate': 0.000116428902651087}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41203969462784706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:07:37,808] Trial 89 finished with value: 0.4115935761722953 and parameters: {'lstm_units': 93, 'learning_rate': 0.0002049917556812824}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115935761722953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:07:51,287] Trial 90 finished with value: 0.41309957910221007 and parameters: {'lstm_units': 95, 'learning_rate': 0.00011333609347742818}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41309957910221007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:08:01,391] Trial 91 finished with value: 0.41237532335237637 and parameters: {'lstm_units': 97, 'learning_rate': 0.0001003288856056221}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41237532335237637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:08:13,449] Trial 92 finished with value: 0.41166895535755 and parameters: {'lstm_units': 99, 'learning_rate': 0.00014646101660618062}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41166895535755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:08:32,029] Trial 93 finished with value: 0.41194930254288964 and parameters: {'lstm_units': 97, 'learning_rate': 0.00013413578192012667}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41194930254288964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:08:42,740] Trial 94 finished with value: 0.41156665486941074 and parameters: {'lstm_units': 90, 'learning_rate': 0.00016828678680785}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41156665486941074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:08:53,965] Trial 95 finished with value: 0.41138852871703674 and parameters: {'lstm_units': 94, 'learning_rate': 0.00013544257103250646}. Best is trial 87 with value: 0.41061684482826427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138852871703674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:09:04,364] Trial 96 finished with value: 0.40497513032304905 and parameters: {'lstm_units': 100, 'learning_rate': 0.00011990552323904927}. Best is trial 96 with value: 0.40497513032304905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.40497513032304905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:09:13,530] Trial 97 finished with value: 0.4113911507198201 and parameters: {'lstm_units': 91, 'learning_rate': 0.00011650713908948613}. Best is trial 96 with value: 0.40497513032304905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113911507198201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:09:32,819] Trial 98 finished with value: 0.41141479211451276 and parameters: {'lstm_units': 96, 'learning_rate': 0.0001879087451130968}. Best is trial 96 with value: 0.40497513032304905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141479211451276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:09:42,734] Trial 99 finished with value: 0.4127675157807627 and parameters: {'lstm_units': 83, 'learning_rate': 0.00015891084133795157}. Best is trial 96 with value: 0.40497513032304905.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4127675157807627\n",
      "Best hyperparameters: {'lstm_units': 100, 'learning_rate': 0.00011990552323904927}\n",
      "Best validation MSE: 0.40497513032304905\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "MSE   : 0.46440637959424075\n"
     ]
    }
   ],
   "source": [
    "RNN_testing_1 = RNN_testing(normalizes_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9c9e4a4-c509-40f9-86d1-61971d362783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:11:59,298] A new study created in memory with name: no-name-a98d8f06-4791-4b4e-879c-e32dfcec6681\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:12:08,317] Trial 0 finished with value: 0.4114434342391606 and parameters: {'lstm_units': 91, 'learning_rate': 0.003385039531647299}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114434342391606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:12:15,705] Trial 1 finished with value: 0.4134529121942006 and parameters: {'lstm_units': 67, 'learning_rate': 0.00022519687674118534}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4134529121942006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:12:27,358] Trial 2 finished with value: 0.4116151450584899 and parameters: {'lstm_units': 92, 'learning_rate': 0.0005432781779955193}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116151450584899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:12:34,389] Trial 3 finished with value: 0.4114668124061468 and parameters: {'lstm_units': 69, 'learning_rate': 0.0010123345287561774}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114668124061468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:12:43,522] Trial 4 finished with value: 0.41168192608641196 and parameters: {'lstm_units': 51, 'learning_rate': 0.0004491153271474676}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41168192608641196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:12:52,407] Trial 5 finished with value: 0.41231156356182747 and parameters: {'lstm_units': 77, 'learning_rate': 0.008201649717790397}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41231156356182747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:13:04,224] Trial 6 finished with value: 0.412439380850209 and parameters: {'lstm_units': 71, 'learning_rate': 0.00013637233727509945}. Best is trial 0 with value: 0.4114434342391606.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.412439380850209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:13:12,696] Trial 7 finished with value: 0.4113858296540548 and parameters: {'lstm_units': 62, 'learning_rate': 0.004821091750774162}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113858296540548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:13:22,465] Trial 8 finished with value: 0.4113887892695346 and parameters: {'lstm_units': 80, 'learning_rate': 0.0008913323869066472}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113887892695346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:13:32,053] Trial 9 finished with value: 0.41184143892809755 and parameters: {'lstm_units': 59, 'learning_rate': 0.006354348054438126}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41184143892809755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:13:40,673] Trial 10 finished with value: 0.4114493714257554 and parameters: {'lstm_units': 50, 'learning_rate': 0.002855596108301568}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114493714257554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:13:49,556] Trial 11 finished with value: 0.4118600770418451 and parameters: {'lstm_units': 82, 'learning_rate': 0.001419351491351507}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118600770418451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:00,623] Trial 12 finished with value: 0.41138703559330736 and parameters: {'lstm_units': 81, 'learning_rate': 0.002125307486983219}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138703559330736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:07,728] Trial 13 finished with value: 0.41145317359072253 and parameters: {'lstm_units': 62, 'learning_rate': 0.0028890730941449547}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145317359072253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:16,404] Trial 14 finished with value: 0.41173704301200403 and parameters: {'lstm_units': 99, 'learning_rate': 0.00490172807715866}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41173704301200403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:26,249] Trial 15 finished with value: 0.4113915623199393 and parameters: {'lstm_units': 87, 'learning_rate': 0.0019115865673394051}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113915623199393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:34,459] Trial 16 finished with value: 0.4115290072263716 and parameters: {'lstm_units': 59, 'learning_rate': 0.009065753652666505}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115290072263716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:42,137] Trial 17 finished with value: 0.4115794380655319 and parameters: {'lstm_units': 75, 'learning_rate': 0.00463932324129278}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115794380655319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:50,430] Trial 18 finished with value: 0.4117822578075201 and parameters: {'lstm_units': 65, 'learning_rate': 0.0017093119626917462}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117822578075201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:14:59,582] Trial 19 finished with value: 0.41212569861346027 and parameters: {'lstm_units': 56, 'learning_rate': 0.0022854451351941177}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41212569861346027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:15:09,388] Trial 20 finished with value: 0.41144590041626844 and parameters: {'lstm_units': 74, 'learning_rate': 0.00438492032688252}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144590041626844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:15:18,835] Trial 21 finished with value: 0.41138923110221504 and parameters: {'lstm_units': 81, 'learning_rate': 0.0006955543509295857}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138923110221504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:15:29,848] Trial 22 finished with value: 0.41140145904394676 and parameters: {'lstm_units': 83, 'learning_rate': 0.0009512417173090793}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140145904394676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:15:39,051] Trial 23 finished with value: 0.4115184297177896 and parameters: {'lstm_units': 87, 'learning_rate': 0.0013119079737181915}. Best is trial 7 with value: 0.4113858296540548.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115184297177896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:15:46,574] Trial 24 finished with value: 0.4113600495378092 and parameters: {'lstm_units': 78, 'learning_rate': 0.0003533910006442672}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113600495378092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:15:55,730] Trial 25 finished with value: 0.4114769474862125 and parameters: {'lstm_units': 72, 'learning_rate': 0.00031403456685499955}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114769474862125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:16:04,946] Trial 26 finished with value: 0.41628696795598275 and parameters: {'lstm_units': 76, 'learning_rate': 0.00010078958976264694}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41628696795598275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:16:13,258] Trial 27 finished with value: 0.4119393248247627 and parameters: {'lstm_units': 87, 'learning_rate': 0.0003141281189794569}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119393248247627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:16:25,396] Trial 28 finished with value: 0.41303165574163575 and parameters: {'lstm_units': 79, 'learning_rate': 0.00019323204201006337}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41303165574163575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:16:36,370] Trial 29 finished with value: 0.4122213048676734 and parameters: {'lstm_units': 96, 'learning_rate': 0.003972868556698448}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122213048676734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:16:44,087] Trial 30 finished with value: 0.4130387169132838 and parameters: {'lstm_units': 93, 'learning_rate': 0.0065628384197739245}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4130387169132838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:16:56,278] Trial 31 finished with value: 0.4115247897861798 and parameters: {'lstm_units': 85, 'learning_rate': 0.0007680293712712136}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115247897861798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:17:09,406] Trial 32 finished with value: 0.411470091752518 and parameters: {'lstm_units': 78, 'learning_rate': 0.0004030501788926088}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411470091752518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:17:16,592] Trial 33 finished with value: 0.4115772115988882 and parameters: {'lstm_units': 68, 'learning_rate': 0.0005853662445923332}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115772115988882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:17:25,470] Trial 34 finished with value: 0.4114932064301906 and parameters: {'lstm_units': 80, 'learning_rate': 0.0010440561837676589}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114932064301906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:17:33,522] Trial 35 finished with value: 0.41143611572009475 and parameters: {'lstm_units': 89, 'learning_rate': 0.002734427116906214}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143611572009475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:17:42,170] Trial 36 finished with value: 0.4116279626243061 and parameters: {'lstm_units': 72, 'learning_rate': 0.00021267222559170795}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116279626243061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:17:49,965] Trial 37 finished with value: 0.4113867051967798 and parameters: {'lstm_units': 65, 'learning_rate': 0.0020757822610572843}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113867051967798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:00,056] Trial 38 finished with value: 0.41170023271947864 and parameters: {'lstm_units': 64, 'learning_rate': 0.0021382349605686126}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41170023271947864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:07,239] Trial 39 finished with value: 0.41148476325618266 and parameters: {'lstm_units': 55, 'learning_rate': 0.0013787294402080065}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148476325618266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:15,060] Trial 40 finished with value: 0.4124775432506595 and parameters: {'lstm_units': 70, 'learning_rate': 0.0035209844143656486}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124775432506595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:24,529] Trial 41 finished with value: 0.4117643589177492 and parameters: {'lstm_units': 67, 'learning_rate': 0.00567373871326027}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117643589177492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:31,734] Trial 42 finished with value: 0.411385154676941 and parameters: {'lstm_units': 61, 'learning_rate': 0.0008530761017676078}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411385154676941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:41,938] Trial 43 finished with value: 0.4113903734060449 and parameters: {'lstm_units': 61, 'learning_rate': 0.0004802435081872345}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113903734060449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:18:50,604] Trial 44 finished with value: 0.41138829838383195 and parameters: {'lstm_units': 55, 'learning_rate': 0.00119154337007496}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138829838383195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:00,673] Trial 45 finished with value: 0.4114452269313248 and parameters: {'lstm_units': 52, 'learning_rate': 0.0024466629867992513}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114452269313248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:08,723] Trial 46 finished with value: 0.4114017410566031 and parameters: {'lstm_units': 64, 'learning_rate': 0.0015592324027234588}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114017410566031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:17,272] Trial 47 finished with value: 0.41138900568121595 and parameters: {'lstm_units': 59, 'learning_rate': 0.003437481846560147}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138900568121595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:24,002] Trial 48 finished with value: 0.4119448602323448 and parameters: {'lstm_units': 61, 'learning_rate': 0.0017467319450909476}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119448602323448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:30,965] Trial 49 finished with value: 0.4139892573221346 and parameters: {'lstm_units': 57, 'learning_rate': 0.00016729976497788335}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4139892573221346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:40,603] Trial 50 finished with value: 0.41142758260657913 and parameters: {'lstm_units': 66, 'learning_rate': 0.007554504621212657}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142758260657913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:49,079] Trial 51 finished with value: 0.41217533032181713 and parameters: {'lstm_units': 53, 'learning_rate': 0.0012244273321230243}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41217533032181713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:19:56,173] Trial 52 finished with value: 0.41175975152594196 and parameters: {'lstm_units': 62, 'learning_rate': 0.0011535525988866366}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41175975152594196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:20:03,256] Trial 53 finished with value: 0.41283906810415816 and parameters: {'lstm_units': 58, 'learning_rate': 0.0007600515567190381}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41283906810415816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:20:11,293] Trial 54 finished with value: 0.41151601734425136 and parameters: {'lstm_units': 55, 'learning_rate': 0.001932991556015435}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41151601734425136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:20:19,201] Trial 55 finished with value: 0.4117993213302325 and parameters: {'lstm_units': 50, 'learning_rate': 0.0006257289136605465}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117993213302325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:20:33,188] Trial 56 finished with value: 0.41136463569904774 and parameters: {'lstm_units': 74, 'learning_rate': 0.0003561737905538942}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41136463569904774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:20:43,699] Trial 57 finished with value: 0.41144549563064725 and parameters: {'lstm_units': 74, 'learning_rate': 0.009943500933590893}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144549563064725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:20:54,967] Trial 58 finished with value: 0.4117126123885362 and parameters: {'lstm_units': 84, 'learning_rate': 0.0003225312628536272}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117126123885362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:21:03,921] Trial 59 finished with value: 0.41137353737955445 and parameters: {'lstm_units': 76, 'learning_rate': 0.00041460216085486884}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41137353737955445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:21:13,766] Trial 60 finished with value: 0.41142555571446837 and parameters: {'lstm_units': 71, 'learning_rate': 0.0003840480503984424}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142555571446837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:21:24,940] Trial 61 finished with value: 0.4114471550819946 and parameters: {'lstm_units': 77, 'learning_rate': 0.0004601525694784764}. Best is trial 24 with value: 0.4113600495378092.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114471550819946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:21:32,996] Trial 62 finished with value: 0.41099645804349266 and parameters: {'lstm_units': 74, 'learning_rate': 0.0002581334945336627}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41099645804349266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:21:41,564] Trial 63 finished with value: 0.4118091779256579 and parameters: {'lstm_units': 73, 'learning_rate': 0.00025902512452674235}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118091779256579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:21:49,995] Trial 64 finished with value: 0.4116299212050268 and parameters: {'lstm_units': 69, 'learning_rate': 0.0002460202007554284}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116299212050268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:02,652] Trial 65 finished with value: 0.41173634484758276 and parameters: {'lstm_units': 76, 'learning_rate': 0.0003891724407586986}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41173634484758276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:11,921] Trial 66 finished with value: 0.41143201589663697 and parameters: {'lstm_units': 78, 'learning_rate': 0.0002786952593197196}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143201589663697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:19,197] Trial 67 finished with value: 0.4113305247332005 and parameters: {'lstm_units': 63, 'learning_rate': 0.00015247657154660266}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113305247332005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:29,220] Trial 68 finished with value: 0.41163150127882675 and parameters: {'lstm_units': 75, 'learning_rate': 0.0001345875484185131}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41163150127882675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:39,801] Trial 69 finished with value: 0.4122077474245823 and parameters: {'lstm_units': 69, 'learning_rate': 0.00014925173927868852}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122077474245823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:49,381] Trial 70 finished with value: 0.41194048531314925 and parameters: {'lstm_units': 81, 'learning_rate': 0.00011977655648986028}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41194048531314925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:22:57,813] Trial 71 finished with value: 0.41169846748872335 and parameters: {'lstm_units': 64, 'learning_rate': 0.00019760002067047684}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41169846748872335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:23:09,148] Trial 72 finished with value: 0.41150663521350883 and parameters: {'lstm_units': 60, 'learning_rate': 0.00034462616791208344}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41150663521350883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:23:16,941] Trial 73 finished with value: 0.4113743936271204 and parameters: {'lstm_units': 63, 'learning_rate': 0.0005101942427489118}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113743936271204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:23:27,689] Trial 74 finished with value: 0.411386633003963 and parameters: {'lstm_units': 62, 'learning_rate': 0.000547214424406282}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411386633003963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:23:37,110] Trial 75 finished with value: 0.4114677156581819 and parameters: {'lstm_units': 67, 'learning_rate': 0.0005109156975116739}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114677156581819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:23:46,994] Trial 76 finished with value: 0.41143940591239664 and parameters: {'lstm_units': 63, 'learning_rate': 0.0002844613682521176}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143940591239664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:23:57,060] Trial 77 finished with value: 0.4118328555970337 and parameters: {'lstm_units': 71, 'learning_rate': 0.0008434886958618031}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118328555970337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:04,063] Trial 78 finished with value: 0.4115868643655426 and parameters: {'lstm_units': 73, 'learning_rate': 0.0004238885033617606}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115868643655426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:12,956] Trial 79 finished with value: 0.41190232877018373 and parameters: {'lstm_units': 82, 'learning_rate': 0.00023003034103150479}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41190232877018373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:23,470] Trial 80 finished with value: 0.41141702420162407 and parameters: {'lstm_units': 79, 'learning_rate': 0.00035551036657534497}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141702420162407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:33,263] Trial 81 finished with value: 0.41149420604983966 and parameters: {'lstm_units': 62, 'learning_rate': 0.0005882945359797659}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149420604983966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:42,248] Trial 82 finished with value: 0.41197665987746074 and parameters: {'lstm_units': 66, 'learning_rate': 0.0006692908635082027}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41197665987746074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:50,360] Trial 83 finished with value: 0.411474579741456 and parameters: {'lstm_units': 60, 'learning_rate': 0.0005308434973332754}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411474579741456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:24:57,239] Trial 84 finished with value: 0.4118519026100137 and parameters: {'lstm_units': 57, 'learning_rate': 0.0004240758353250401}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118519026100137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:05,829] Trial 85 finished with value: 0.41376913065846405 and parameters: {'lstm_units': 63, 'learning_rate': 0.00017194276098117322}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41376913065846405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:14,106] Trial 86 finished with value: 0.4113926707485953 and parameters: {'lstm_units': 76, 'learning_rate': 0.0008969247054286281}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113926707485953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:23,074] Trial 87 finished with value: 0.4115169089871384 and parameters: {'lstm_units': 65, 'learning_rate': 0.0002943352558303077}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115169089871384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:31,779] Trial 88 finished with value: 0.4115780040333469 and parameters: {'lstm_units': 60, 'learning_rate': 0.0004850324568385259}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115780040333469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:38,808] Trial 89 finished with value: 0.4115022160580407 and parameters: {'lstm_units': 62, 'learning_rate': 0.0007434689647483956}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115022160580407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:49,598] Trial 90 finished with value: 0.413257476762245 and parameters: {'lstm_units': 68, 'learning_rate': 0.00010436549043425525}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.413257476762245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:25:59,560] Trial 91 finished with value: 0.41144773854187844 and parameters: {'lstm_units': 65, 'learning_rate': 0.0005796118991041939}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144773854187844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:26:07,344] Trial 92 finished with value: 0.411538368610659 and parameters: {'lstm_units': 74, 'learning_rate': 0.00035027639388466697}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411538368610659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:26:14,908] Trial 93 finished with value: 0.4114093485858607 and parameters: {'lstm_units': 58, 'learning_rate': 0.001070065556848216}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114093485858607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:26:22,541] Trial 94 finished with value: 0.41328296153806293 and parameters: {'lstm_units': 70, 'learning_rate': 0.0049438410680046445}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41328296153806293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:26:30,801] Trial 95 finished with value: 0.41162743096995524 and parameters: {'lstm_units': 61, 'learning_rate': 0.0006575634461008093}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41162743096995524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:26:46,606] Trial 96 finished with value: 0.41154510238981834 and parameters: {'lstm_units': 78, 'learning_rate': 0.0004386710187777268}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154510238981834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:26:54,444] Trial 97 finished with value: 0.41140663564746943 and parameters: {'lstm_units': 63, 'learning_rate': 0.0005406034166486675}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140663564746943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:27:04,067] Trial 98 finished with value: 0.4114001655773838 and parameters: {'lstm_units': 59, 'learning_rate': 0.0029341739851839513}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114001655773838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 19:27:13,608] Trial 99 finished with value: 0.41310223630328907 and parameters: {'lstm_units': 66, 'learning_rate': 0.00025747681466367026}. Best is trial 62 with value: 0.41099645804349266.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41310223630328907\n",
      "Best hyperparameters: {'lstm_units': 74, 'learning_rate': 0.0002581334945336627}\n",
      "Best validation MSE: 0.41099645804349266\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.26501732503605413\n"
     ]
    }
   ],
   "source": [
    "RNN_testing_2 = RNN_testing(normalizes_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93c6741a-a2aa-4faf-84ab-b07e2224b506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:42:28,704] A new study created in memory with name: no-name-ec410c16-dcaf-47aa-a5a3-5452242d563f\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:42:38,714] Trial 0 finished with value: 0.411569070813785 and parameters: {'lstm_units': 79, 'learning_rate': 0.00022819103765939607}. Best is trial 0 with value: 0.411569070813785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411569070813785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:42:50,341] Trial 1 finished with value: 0.411383893743166 and parameters: {'lstm_units': 99, 'learning_rate': 0.0005349966058632996}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411383893743166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:42:59,312] Trial 2 finished with value: 0.41143550133654616 and parameters: {'lstm_units': 53, 'learning_rate': 0.001015516553430444}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143550133654616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:43:10,084] Trial 3 finished with value: 0.41207318245719393 and parameters: {'lstm_units': 77, 'learning_rate': 0.0017680555247922352}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41207318245719393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:43:17,275] Trial 4 finished with value: 0.4114819106783417 and parameters: {'lstm_units': 75, 'learning_rate': 0.00297890782612453}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114819106783417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:43:27,518] Trial 5 finished with value: 0.41145460557003083 and parameters: {'lstm_units': 68, 'learning_rate': 0.0006324891674529201}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145460557003083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:43:38,380] Trial 6 finished with value: 0.4117782988711134 and parameters: {'lstm_units': 52, 'learning_rate': 0.002299187790062063}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117782988711134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:43:46,582] Trial 7 finished with value: 0.4124229437525999 and parameters: {'lstm_units': 56, 'learning_rate': 0.00031263307648067134}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124229437525999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:44:05,057] Trial 8 finished with value: 0.411412119453104 and parameters: {'lstm_units': 94, 'learning_rate': 0.0006227570929800988}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411412119453104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:44:15,303] Trial 9 finished with value: 0.4113987338528976 and parameters: {'lstm_units': 94, 'learning_rate': 0.0014213645436966119}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113987338528976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:44:27,712] Trial 10 finished with value: 0.4120649591380415 and parameters: {'lstm_units': 100, 'learning_rate': 0.00011799976620252784}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120649591380415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:44:37,627] Trial 11 finished with value: 0.4116404992000615 and parameters: {'lstm_units': 90, 'learning_rate': 0.005103108141662022}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116404992000615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:44:48,088] Trial 12 finished with value: 0.41163856333468446 and parameters: {'lstm_units': 89, 'learning_rate': 0.007826702222208428}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41163856333468446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:45:02,202] Trial 13 finished with value: 0.4114044299633054 and parameters: {'lstm_units': 100, 'learning_rate': 0.0009872236401873749}. Best is trial 1 with value: 0.411383893743166.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114044299633054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:45:11,830] Trial 14 finished with value: 0.41132626903018243 and parameters: {'lstm_units': 85, 'learning_rate': 0.00032173700739251927}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41132626903018243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:45:23,272] Trial 15 finished with value: 0.41267367523982146 and parameters: {'lstm_units': 81, 'learning_rate': 0.0002835559130510984}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41267367523982146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:45:38,632] Trial 16 finished with value: 0.41264450435014893 and parameters: {'lstm_units': 85, 'learning_rate': 0.00010709714767071347}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41264450435014893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:45:46,472] Trial 17 finished with value: 0.4125299487181579 and parameters: {'lstm_units': 68, 'learning_rate': 0.0004645930412139883}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4125299487181579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:45:53,776] Trial 18 finished with value: 0.4142548120229933 and parameters: {'lstm_units': 70, 'learning_rate': 0.00018495468029286068}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4142548120229933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:46:15,443] Trial 19 finished with value: 0.4113801450710257 and parameters: {'lstm_units': 86, 'learning_rate': 0.00044962882503467094}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113801450710257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:46:29,277] Trial 20 finished with value: 0.4114089256516617 and parameters: {'lstm_units': 84, 'learning_rate': 0.00016631447890600254}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114089256516617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:46:38,992] Trial 21 finished with value: 0.41146486292587303 and parameters: {'lstm_units': 94, 'learning_rate': 0.00038298247386569053}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146486292587303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:46:51,955] Trial 22 finished with value: 0.4113907682958895 and parameters: {'lstm_units': 87, 'learning_rate': 0.0006447231018389143}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113907682958895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:03,471] Trial 23 finished with value: 0.4114009252011113 and parameters: {'lstm_units': 96, 'learning_rate': 0.0004780295949362655}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114009252011113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:19,069] Trial 24 finished with value: 0.411444338530183 and parameters: {'lstm_units': 83, 'learning_rate': 0.0009947682554027188}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411444338530183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:26,505] Trial 25 finished with value: 0.411922746556733 and parameters: {'lstm_units': 72, 'learning_rate': 0.00032339181889461414}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411922746556733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:34,759] Trial 26 finished with value: 0.4114218294773454 and parameters: {'lstm_units': 92, 'learning_rate': 0.0007597086567714992}. Best is trial 14 with value: 0.41132626903018243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114218294773454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:42,045] Trial 27 finished with value: 0.40646391408337484 and parameters: {'lstm_units': 63, 'learning_rate': 0.0002297012098098433}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.40646391408337484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:49,830] Trial 28 finished with value: 0.41157928737272326 and parameters: {'lstm_units': 62, 'learning_rate': 0.00016428770692642503}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41157928737272326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:47:58,894] Trial 29 finished with value: 0.4116522510315347 and parameters: {'lstm_units': 62, 'learning_rate': 0.00023262809087920105}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116522510315347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:48:10,931] Trial 30 finished with value: 0.4113256276442164 and parameters: {'lstm_units': 79, 'learning_rate': 0.00022796215906037618}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113256276442164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:48:19,296] Trial 31 finished with value: 0.41147224458656645 and parameters: {'lstm_units': 80, 'learning_rate': 0.00023606950352777914}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41147224458656645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:48:31,935] Trial 32 finished with value: 0.41138867234069465 and parameters: {'lstm_units': 78, 'learning_rate': 0.00038851566531016046}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138867234069465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:48:40,922] Trial 33 finished with value: 0.4119820208368079 and parameters: {'lstm_units': 73, 'learning_rate': 0.00012952672534416966}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119820208368079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:48:51,772] Trial 34 finished with value: 0.4128880566905167 and parameters: {'lstm_units': 63, 'learning_rate': 0.00019874846628964557}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4128880566905167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:48:59,042] Trial 35 finished with value: 0.41146781326553755 and parameters: {'lstm_units': 76, 'learning_rate': 0.00026201156721450576}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146781326553755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:49:09,756] Trial 36 finished with value: 0.4113696206252255 and parameters: {'lstm_units': 87, 'learning_rate': 0.00039347495220608047}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113696206252255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:49:16,644] Trial 37 finished with value: 0.41577748363212846 and parameters: {'lstm_units': 56, 'learning_rate': 0.00014426491287156132}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41577748363212846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:49:26,933] Trial 38 finished with value: 0.4117138701644304 and parameters: {'lstm_units': 82, 'learning_rate': 0.0003591594351463621}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117138701644304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:49:38,077] Trial 39 finished with value: 0.41143094136807323 and parameters: {'lstm_units': 79, 'learning_rate': 0.00020907198802683362}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143094136807323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:49:45,780] Trial 40 finished with value: 0.4117450587404415 and parameters: {'lstm_units': 65, 'learning_rate': 0.00028823464803991774}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117450587404415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:49:58,697] Trial 41 finished with value: 0.41140857688265364 and parameters: {'lstm_units': 87, 'learning_rate': 0.0004719171087394185}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140857688265364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:50:11,779] Trial 42 finished with value: 0.4115852039411625 and parameters: {'lstm_units': 86, 'learning_rate': 0.0007822273176194332}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115852039411625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:50:31,529] Trial 43 finished with value: 0.4113830111627459 and parameters: {'lstm_units': 91, 'learning_rate': 0.0005508881532505209}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113830111627459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:50:39,939] Trial 44 finished with value: 0.41138528318846396 and parameters: {'lstm_units': 75, 'learning_rate': 0.0013972779992862743}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138528318846396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:50:50,620] Trial 45 finished with value: 0.4114033298442277 and parameters: {'lstm_units': 97, 'learning_rate': 0.0004077147926007044}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114033298442277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:51:00,808] Trial 46 finished with value: 0.4124855785130331 and parameters: {'lstm_units': 50, 'learning_rate': 0.0003149512997904264}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124855785130331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:51:19,139] Trial 47 finished with value: 0.41164352453759645 and parameters: {'lstm_units': 89, 'learning_rate': 0.00024288993912533982}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41164352453759645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:51:27,588] Trial 48 finished with value: 0.4114655541481995 and parameters: {'lstm_units': 59, 'learning_rate': 0.00014940673960820146}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114655541481995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:51:40,796] Trial 49 finished with value: 0.41245652833958907 and parameters: {'lstm_units': 82, 'learning_rate': 0.00010144673487343811}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41245652833958907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:51:56,435] Trial 50 finished with value: 0.4113945311454748 and parameters: {'lstm_units': 85, 'learning_rate': 0.0006918643009304415}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113945311454748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:52:05,519] Trial 51 finished with value: 0.41149176483208366 and parameters: {'lstm_units': 91, 'learning_rate': 0.0005514645506745632}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149176483208366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:52:13,864] Trial 52 finished with value: 0.4115265014248933 and parameters: {'lstm_units': 88, 'learning_rate': 0.0005364004895582024}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115265014248933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:52:24,701] Trial 53 finished with value: 0.41140293309174236 and parameters: {'lstm_units': 93, 'learning_rate': 0.0008587112779265491}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140293309174236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:52:33,110] Trial 54 finished with value: 0.4116225251124755 and parameters: {'lstm_units': 90, 'learning_rate': 0.00044263791400035485}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116225251124755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:52:43,877] Trial 55 finished with value: 0.4114603285935672 and parameters: {'lstm_units': 96, 'learning_rate': 0.0003249177270427864}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114603285935672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:52:54,416] Trial 56 finished with value: 0.41154591758995024 and parameters: {'lstm_units': 84, 'learning_rate': 0.0005867961757196957}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154591758995024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:53:02,962] Trial 57 finished with value: 0.41142546012566855 and parameters: {'lstm_units': 80, 'learning_rate': 0.0030620695150403187}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142546012566855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:53:12,851] Trial 58 finished with value: 0.411393072794715 and parameters: {'lstm_units': 86, 'learning_rate': 0.0012420389114079888}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411393072794715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:53:21,148] Trial 59 finished with value: 0.41276583555370966 and parameters: {'lstm_units': 74, 'learning_rate': 0.00018903617135994323}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41276583555370966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:53:29,920] Trial 60 finished with value: 0.41207684885185863 and parameters: {'lstm_units': 77, 'learning_rate': 0.00038675820294047585}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41207684885185863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:53:38,306] Trial 61 finished with value: 0.41093112244875685 and parameters: {'lstm_units': 98, 'learning_rate': 0.00027594296655063277}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41093112244875685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:53:54,138] Trial 62 finished with value: 0.41145640645415665 and parameters: {'lstm_units': 98, 'learning_rate': 0.0002681047096282568}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145640645415665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:54:02,613] Trial 63 finished with value: 0.41102180064421695 and parameters: {'lstm_units': 95, 'learning_rate': 0.0003603157546862027}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41102180064421695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:54:25,309] Trial 64 finished with value: 0.4113860866949064 and parameters: {'lstm_units': 100, 'learning_rate': 0.0002149457250073195}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113860866949064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:54:37,773] Trial 65 finished with value: 0.41177420729030395 and parameters: {'lstm_units': 94, 'learning_rate': 0.00032503137779631456}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41177420729030395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:54:49,280] Trial 66 finished with value: 0.4122621615295901 and parameters: {'lstm_units': 96, 'learning_rate': 0.00026960867983362853}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122621615295901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:54:58,291] Trial 67 finished with value: 0.4118370240751227 and parameters: {'lstm_units': 69, 'learning_rate': 0.00017439205197517557}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118370240751227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:55:10,444] Trial 68 finished with value: 0.41165262486210974 and parameters: {'lstm_units': 71, 'learning_rate': 0.00035437401837949223}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41165262486210974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:55:22,085] Trial 69 finished with value: 0.41332122247182745 and parameters: {'lstm_units': 83, 'learning_rate': 0.00012924522276418668}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41332122247182745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:55:38,450] Trial 70 finished with value: 0.41139333136141487 and parameters: {'lstm_units': 98, 'learning_rate': 0.00042412181195381377}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139333136141487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:55:48,441] Trial 71 finished with value: 0.4116592709435851 and parameters: {'lstm_units': 92, 'learning_rate': 0.0004981451329137235}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116592709435851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:56:03,997] Trial 72 finished with value: 0.4112531836810129 and parameters: {'lstm_units': 89, 'learning_rate': 0.00029465583022065427}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4112531836810129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:56:12,107] Trial 73 finished with value: 0.41131800063590257 and parameters: {'lstm_units': 89, 'learning_rate': 0.00022906917962457244}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41131800063590257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:56:24,084] Trial 74 finished with value: 0.4134510992284021 and parameters: {'lstm_units': 88, 'learning_rate': 0.0002497063960069881}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4134510992284021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:56:36,219] Trial 75 finished with value: 0.4114049377480351 and parameters: {'lstm_units': 90, 'learning_rate': 0.00021928652347028834}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114049377480351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:56:48,384] Trial 76 finished with value: 0.41238454185793166 and parameters: {'lstm_units': 96, 'learning_rate': 0.0003022826664843773}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41238454185793166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:57:00,527] Trial 77 finished with value: 0.41179141798669744 and parameters: {'lstm_units': 94, 'learning_rate': 0.00014820529714658996}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41179141798669744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:57:11,449] Trial 78 finished with value: 0.411849958844136 and parameters: {'lstm_units': 88, 'learning_rate': 0.00018628245818472054}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411849958844136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:57:25,689] Trial 79 finished with value: 0.4116183757748063 and parameters: {'lstm_units': 92, 'learning_rate': 0.00035030076708445504}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116183757748063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:57:33,859] Trial 80 finished with value: 0.4113847217597607 and parameters: {'lstm_units': 84, 'learning_rate': 0.008045810666180306}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113847217597607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:57:43,315] Trial 81 finished with value: 0.41155262106319507 and parameters: {'lstm_units': 86, 'learning_rate': 0.00028625612967741337}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41155262106319507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:57:57,019] Trial 82 finished with value: 0.411637715556448 and parameters: {'lstm_units': 81, 'learning_rate': 0.0002354351639601384}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411637715556448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:58:06,024] Trial 83 finished with value: 0.41135580511468034 and parameters: {'lstm_units': 87, 'learning_rate': 0.0002015502250201023}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41135580511468034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:58:14,004] Trial 84 finished with value: 0.4127322432921318 and parameters: {'lstm_units': 89, 'learning_rate': 0.00016006433060187955}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4127322432921318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:58:24,831] Trial 85 finished with value: 0.4114713628054043 and parameters: {'lstm_units': 67, 'learning_rate': 0.00021102701174498524}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114713628054043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:58:34,464] Trial 86 finished with value: 0.41111487158488297 and parameters: {'lstm_units': 95, 'learning_rate': 0.00012000233055585859}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41111487158488297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:58:43,336] Trial 87 finished with value: 0.4126899137760009 and parameters: {'lstm_units': 95, 'learning_rate': 0.00011390998863621267}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4126899137760009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:58:55,712] Trial 88 finished with value: 0.41161589883556204 and parameters: {'lstm_units': 100, 'learning_rate': 0.00012831675525604576}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41161589883556204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:59:05,062] Trial 89 finished with value: 0.41186449650931123 and parameters: {'lstm_units': 98, 'learning_rate': 0.00019791179929824702}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41186449650931123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:59:18,166] Trial 90 finished with value: 0.41158758144412144 and parameters: {'lstm_units': 93, 'learning_rate': 0.00016802359189772604}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41158758144412144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:59:28,505] Trial 91 finished with value: 0.4114647622438455 and parameters: {'lstm_units': 91, 'learning_rate': 0.0002562286628652297}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114647622438455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:59:37,082] Trial 92 finished with value: 0.41185499864415687 and parameters: {'lstm_units': 85, 'learning_rate': 0.00029108098307384866}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41185499864415687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:59:48,523] Trial 93 finished with value: 0.4120867608179021 and parameters: {'lstm_units': 87, 'learning_rate': 0.0003637006647092993}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120867608179021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 20:59:59,184] Trial 94 finished with value: 0.41247654869339545 and parameters: {'lstm_units': 89, 'learning_rate': 0.0002242546752992786}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41247654869339545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:00:11,488] Trial 95 finished with value: 0.4116130291506342 and parameters: {'lstm_units': 82, 'learning_rate': 0.00014011530578893162}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116130291506342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:00:21,062] Trial 96 finished with value: 0.41154089503199254 and parameters: {'lstm_units': 95, 'learning_rate': 0.0019166779490882814}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154089503199254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:00:28,762] Trial 97 finished with value: 0.4113857341246867 and parameters: {'lstm_units': 53, 'learning_rate': 0.005969276521536511}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113857341246867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:00:39,424] Trial 98 finished with value: 0.4116359048274629 and parameters: {'lstm_units': 79, 'learning_rate': 0.00033135739696553754}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116359048274629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:00:50,000] Trial 99 finished with value: 0.4143453688092706 and parameters: {'lstm_units': 59, 'learning_rate': 0.00017806101965247605}. Best is trial 27 with value: 0.40646391408337484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4143453688092706\n",
      "Best hyperparameters: {'lstm_units': 63, 'learning_rate': 0.0002297012098098433}\n",
      "Best validation MSE: 0.40646391408337484\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.2687212946794741\n"
     ]
    }
   ],
   "source": [
    "RNN_testing_6 = RNN_testing(normalizes_df_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fde3372a-048c-475f-aba3-9199a29db2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:32:44,317] A new study created in memory with name: no-name-1864f69d-a8bc-4a5c-a21c-908d75c019cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:32:53,646] Trial 0 finished with value: 0.589059434419067 and parameters: {'lstm_units': 84, 'learning_rate': 0.004634146978041529}. Best is trial 0 with value: 0.589059434419067.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:33:00,351] Trial 1 finished with value: 0.5890555094032953 and parameters: {'lstm_units': 61, 'learning_rate': 0.0034423996610968705}. Best is trial 1 with value: 0.5890555094032953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:33:08,068] Trial 2 finished with value: 0.589497645597873 and parameters: {'lstm_units': 75, 'learning_rate': 0.0025847694238792626}. Best is trial 1 with value: 0.5890555094032953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:33:13,956] Trial 3 finished with value: 0.589223394574763 and parameters: {'lstm_units': 62, 'learning_rate': 0.001019794198386229}. Best is trial 1 with value: 0.5890555094032953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:33:24,953] Trial 4 finished with value: 0.5893919970518893 and parameters: {'lstm_units': 71, 'learning_rate': 0.008880312379037265}. Best is trial 1 with value: 0.5890555094032953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:33:34,272] Trial 5 finished with value: 0.5890751312041349 and parameters: {'lstm_units': 85, 'learning_rate': 0.008056286230580221}. Best is trial 1 with value: 0.5890555094032953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:33:44,623] Trial 6 finished with value: 0.5892012416769382 and parameters: {'lstm_units': 68, 'learning_rate': 0.0002525230200718244}. Best is trial 1 with value: 0.5890555094032953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:34:03,241] Trial 7 finished with value: 0.5890552883972227 and parameters: {'lstm_units': 99, 'learning_rate': 0.0023009906916364284}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:34:13,301] Trial 8 finished with value: 0.5898462302119134 and parameters: {'lstm_units': 86, 'learning_rate': 0.002466332227608986}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:34:24,193] Trial 9 finished with value: 0.5900072295601895 and parameters: {'lstm_units': 81, 'learning_rate': 0.008071665483198353}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:34:40,168] Trial 10 finished with value: 0.5891063167899652 and parameters: {'lstm_units': 98, 'learning_rate': 0.00015873954571709572}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:34:47,790] Trial 11 finished with value: 0.5892118154567417 and parameters: {'lstm_units': 56, 'learning_rate': 0.0010117494207931494}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:34:56,306] Trial 12 finished with value: 0.5890603170142508 and parameters: {'lstm_units': 50, 'learning_rate': 0.0016014573989834495}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:35:05,628] Trial 13 finished with value: 0.5891815910343718 and parameters: {'lstm_units': 98, 'learning_rate': 0.0005443824513537784}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:35:13,240] Trial 14 finished with value: 0.5890745148120308 and parameters: {'lstm_units': 63, 'learning_rate': 0.003139686068069187}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:35:28,447] Trial 15 finished with value: 0.5891064921904086 and parameters: {'lstm_units': 92, 'learning_rate': 0.0005432006783771259}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:35:37,764] Trial 16 finished with value: 0.5895204387706008 and parameters: {'lstm_units': 58, 'learning_rate': 0.004559269929177471}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:35:47,456] Trial 17 finished with value: 0.5890613144221777 and parameters: {'lstm_units': 78, 'learning_rate': 0.0019354791342511843}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:02,278] Trial 18 finished with value: 0.5891369419655116 and parameters: {'lstm_units': 92, 'learning_rate': 0.004463810583575763}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:10,242] Trial 19 finished with value: 0.5890553560010121 and parameters: {'lstm_units': 50, 'learning_rate': 0.0004964206106735844}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:17,833] Trial 20 finished with value: 0.5890615180334638 and parameters: {'lstm_units': 51, 'learning_rate': 0.00048379903266626583}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:25,752] Trial 21 finished with value: 0.5893797932039989 and parameters: {'lstm_units': 55, 'learning_rate': 0.0014852910705017062}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:33,872] Trial 22 finished with value: 0.5891023372388787 and parameters: {'lstm_units': 66, 'learning_rate': 0.00038894917655115215}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:43,418] Trial 23 finished with value: 0.5891330421899562 and parameters: {'lstm_units': 61, 'learning_rate': 0.0007551284624229667}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:50,379] Trial 24 finished with value: 0.5891086296252822 and parameters: {'lstm_units': 53, 'learning_rate': 0.00033674650376550356}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:36:59,522] Trial 25 finished with value: 0.590066520974298 and parameters: {'lstm_units': 72, 'learning_rate': 0.00011989319889595583}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:37:06,512] Trial 26 finished with value: 0.5890578145033317 and parameters: {'lstm_units': 58, 'learning_rate': 0.001354953568971148}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:37:14,652] Trial 27 finished with value: 0.589912955841262 and parameters: {'lstm_units': 68, 'learning_rate': 0.0007954436581736177}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:37:29,575] Trial 28 finished with value: 0.5890564815600431 and parameters: {'lstm_units': 91, 'learning_rate': 0.0034271530992699114}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:37:45,093] Trial 29 finished with value: 0.5892504573007491 and parameters: {'lstm_units': 100, 'learning_rate': 0.00023369421055195833}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:37:52,385] Trial 30 finished with value: 0.5897714007828214 and parameters: {'lstm_units': 60, 'learning_rate': 0.00672371183005704}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:38:03,113] Trial 31 finished with value: 0.5890659399120842 and parameters: {'lstm_units': 93, 'learning_rate': 0.003570358836631011}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:38:16,441] Trial 32 finished with value: 0.5891199219963793 and parameters: {'lstm_units': 89, 'learning_rate': 0.0023347235923208234}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:38:28,959] Trial 33 finished with value: 0.5894205773873086 and parameters: {'lstm_units': 96, 'learning_rate': 0.005332776003118151}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:38:39,605] Trial 34 finished with value: 0.5890608864433411 and parameters: {'lstm_units': 76, 'learning_rate': 0.001920512607251465}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:38:47,218] Trial 35 finished with value: 0.5893900689529628 and parameters: {'lstm_units': 81, 'learning_rate': 0.003391166157501183}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:39:02,772] Trial 36 finished with value: 0.5891177179520228 and parameters: {'lstm_units': 95, 'learning_rate': 0.0011618925858034054}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:39:12,341] Trial 37 finished with value: 0.5894271569269062 and parameters: {'lstm_units': 88, 'learning_rate': 0.0053202363392301395}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:39:20,926] Trial 38 finished with value: 0.5896590565336923 and parameters: {'lstm_units': 64, 'learning_rate': 0.003129140125416421}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:39:31,132] Trial 39 finished with value: 0.5891421663580846 and parameters: {'lstm_units': 73, 'learning_rate': 0.0008074931235194542}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:39:43,635] Trial 40 finished with value: 0.5897589041569786 and parameters: {'lstm_units': 69, 'learning_rate': 0.009570978280822547}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:39:56,812] Trial 41 finished with value: 0.5890560868876225 and parameters: {'lstm_units': 58, 'learning_rate': 0.0011735460462971125}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:04,745] Trial 42 finished with value: 0.5895584006784098 and parameters: {'lstm_units': 54, 'learning_rate': 0.00217940422104159}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:11,617] Trial 43 finished with value: 0.5890768603677119 and parameters: {'lstm_units': 59, 'learning_rate': 0.002562199902056549}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:19,109] Trial 44 finished with value: 0.5891511206117164 and parameters: {'lstm_units': 53, 'learning_rate': 0.0017398565417734498}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:27,370] Trial 45 finished with value: 0.589094698362019 and parameters: {'lstm_units': 50, 'learning_rate': 0.004007449839909597}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:40,062] Trial 46 finished with value: 0.5890843327512572 and parameters: {'lstm_units': 100, 'learning_rate': 0.0011628064708557526}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:50,278] Trial 47 finished with value: 0.5891346365840399 and parameters: {'lstm_units': 65, 'learning_rate': 0.0029599789770018837}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:40:59,576] Trial 48 finished with value: 0.5894786702817775 and parameters: {'lstm_units': 82, 'learning_rate': 0.006663985004248345}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:41:13,488] Trial 49 finished with value: 0.5891054820576532 and parameters: {'lstm_units': 90, 'learning_rate': 0.0006304662740342623}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:41:21,205] Trial 50 finished with value: 0.5892422996090345 and parameters: {'lstm_units': 57, 'learning_rate': 0.0013018854281315868}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:41:33,787] Trial 51 finished with value: 0.5890589278171755 and parameters: {'lstm_units': 61, 'learning_rate': 0.0013101008177922122}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:41:41,676] Trial 52 finished with value: 0.5892690650848668 and parameters: {'lstm_units': 58, 'learning_rate': 0.0008995133875032986}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:41:51,131] Trial 53 finished with value: 0.5892364821932602 and parameters: {'lstm_units': 52, 'learning_rate': 0.0015772587090147688}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:41:59,393] Trial 54 finished with value: 0.5890558807987115 and parameters: {'lstm_units': 56, 'learning_rate': 0.0027983657197803912}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:42:08,324] Trial 55 finished with value: 0.5890678946703635 and parameters: {'lstm_units': 55, 'learning_rate': 0.0027753280588684857}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:42:19,876] Trial 56 finished with value: 0.5892485698443954 and parameters: {'lstm_units': 62, 'learning_rate': 0.0021564713033972427}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:42:26,599] Trial 57 finished with value: 0.5894348462200155 and parameters: {'lstm_units': 56, 'learning_rate': 0.003950191364290518}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:42:38,059] Trial 58 finished with value: 0.5890710713156587 and parameters: {'lstm_units': 85, 'learning_rate': 0.0004260304980839215}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:42:46,429] Trial 59 finished with value: 0.5912688053486239 and parameters: {'lstm_units': 50, 'learning_rate': 0.00020380369700968476}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:43:04,311] Trial 60 finished with value: 0.589057389327669 and parameters: {'lstm_units': 78, 'learning_rate': 0.002684952202636083}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:43:14,718] Trial 61 finished with value: 0.5890979582922663 and parameters: {'lstm_units': 78, 'learning_rate': 0.005495154781068698}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:43:35,512] Trial 62 finished with value: 0.5891423731692732 and parameters: {'lstm_units': 97, 'learning_rate': 0.0019251671751894064}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:43:51,268] Trial 63 finished with value: 0.5895210850809952 and parameters: {'lstm_units': 87, 'learning_rate': 0.0038270032973047054}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:44:02,293] Trial 64 finished with value: 0.5890924675264535 and parameters: {'lstm_units': 94, 'learning_rate': 0.0003212726846007033}. Best is trial 7 with value: 0.5890552883972227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:44:14,673] Trial 65 finished with value: 0.5890552595634788 and parameters: {'lstm_units': 91, 'learning_rate': 0.00260586275385209}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:44:27,162] Trial 66 finished with value: 0.5893490468436169 and parameters: {'lstm_units': 91, 'learning_rate': 0.0047593249852508}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:44:37,251] Trial 67 finished with value: 0.5893845630968979 and parameters: {'lstm_units': 98, 'learning_rate': 0.0023888903038210762}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:44:46,567] Trial 68 finished with value: 0.5890569153575734 and parameters: {'lstm_units': 53, 'learning_rate': 0.0006117232444746471}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:44:57,506] Trial 69 finished with value: 0.5890555775258949 and parameters: {'lstm_units': 84, 'learning_rate': 0.003378004576757646}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:45:08,786] Trial 70 finished with value: 0.5890706378283385 and parameters: {'lstm_units': 56, 'learning_rate': 0.0068594769399375755}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:45:18,707] Trial 71 finished with value: 0.5890856261907856 and parameters: {'lstm_units': 83, 'learning_rate': 0.003349436772536336}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:45:28,035] Trial 72 finished with value: 0.5892790139579533 and parameters: {'lstm_units': 93, 'learning_rate': 0.0017147072232356504}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:45:38,524] Trial 73 finished with value: 0.5890580423601434 and parameters: {'lstm_units': 85, 'learning_rate': 0.0029609055098978204}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:45:48,836] Trial 74 finished with value: 0.5891476692656551 and parameters: {'lstm_units': 89, 'learning_rate': 0.004530919780046798}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:45:59,827] Trial 75 finished with value: 0.5903092117083591 and parameters: {'lstm_units': 96, 'learning_rate': 0.0035708329854223474}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:46:13,708] Trial 76 finished with value: 0.5890649733410628 and parameters: {'lstm_units': 80, 'learning_rate': 0.0020580718441423895}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:46:22,479] Trial 77 finished with value: 0.5894208504497431 and parameters: {'lstm_units': 75, 'learning_rate': 0.0025020023999180983}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:46:33,320] Trial 78 finished with value: 0.5890700172543344 and parameters: {'lstm_units': 87, 'learning_rate': 0.0010463893443455896}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:46:43,145] Trial 79 finished with value: 0.5890804318616567 and parameters: {'lstm_units': 51, 'learning_rate': 0.0040754573777029325}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:46:50,033] Trial 80 finished with value: 0.5893561350580537 and parameters: {'lstm_units': 60, 'learning_rate': 0.0031716014652346043}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:47:01,820] Trial 81 finished with value: 0.5890607661952408 and parameters: {'lstm_units': 53, 'learning_rate': 0.0004403609991413807}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:47:10,037] Trial 82 finished with value: 0.5891235348700387 and parameters: {'lstm_units': 55, 'learning_rate': 0.0006561663332275733}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:47:18,745] Trial 83 finished with value: 0.589055273190986 and parameters: {'lstm_units': 54, 'learning_rate': 0.000536033760018327}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:47:25,942] Trial 84 finished with value: 0.5892816198976746 and parameters: {'lstm_units': 59, 'learning_rate': 0.0003024887736476759}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:47:35,131] Trial 85 finished with value: 0.5890620822986644 and parameters: {'lstm_units': 52, 'learning_rate': 0.00047681962713431666}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:47:50,421] Trial 86 finished with value: 0.5890554085796772 and parameters: {'lstm_units': 99, 'learning_rate': 0.0005240560975602892}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:02,594] Trial 87 finished with value: 0.5890579450636491 and parameters: {'lstm_units': 100, 'learning_rate': 0.0005218364203334002}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:14,334] Trial 88 finished with value: 0.5892435026843515 and parameters: {'lstm_units': 99, 'learning_rate': 0.0009087587965179282}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:23,593] Trial 89 finished with value: 0.5890552893203373 and parameters: {'lstm_units': 70, 'learning_rate': 0.00040228831166963286}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:31,793] Trial 90 finished with value: 0.5890578500467794 and parameters: {'lstm_units': 67, 'learning_rate': 0.00037252731555963375}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:42,616] Trial 91 finished with value: 0.5890574127541667 and parameters: {'lstm_units': 63, 'learning_rate': 0.0005879831885270474}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:50,977] Trial 92 finished with value: 0.5893637560537002 and parameters: {'lstm_units': 57, 'learning_rate': 0.0006943426516651289}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:48:59,043] Trial 93 finished with value: 0.5892140185259949 and parameters: {'lstm_units': 70, 'learning_rate': 0.000263921106992504}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:49:12,120] Trial 94 finished with value: 0.5890574132462023 and parameters: {'lstm_units': 94, 'learning_rate': 0.0003883887094977802}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:49:23,391] Trial 95 finished with value: 0.5892380436857101 and parameters: {'lstm_units': 73, 'learning_rate': 0.0005394174254838323}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:49:33,246] Trial 96 finished with value: 0.589055990857196 and parameters: {'lstm_units': 54, 'learning_rate': 0.0004651915889008769}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:49:42,633] Trial 97 finished with value: 0.5890553379943473 and parameters: {'lstm_units': 54, 'learning_rate': 0.0003522532294180409}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:49:49,982] Trial 98 finished with value: 0.5898678871293929 and parameters: {'lstm_units': 51, 'learning_rate': 0.00035434818985280393}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 18:50:08,908] Trial 99 finished with value: 0.589063717626009 and parameters: {'lstm_units': 97, 'learning_rate': 0.0003062155887468703}. Best is trial 65 with value: 0.5890552595634788.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lstm_units': 91, 'learning_rate': 0.00260586275385209}\n",
      "Best validation MSE: 0.5890552595634788\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 4s 38ms/step - loss: 0.6406 - val_loss: 0.5892\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5669 - val_loss: 0.6005\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5632 - val_loss: 0.5982\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5717 - val_loss: 0.5923\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5579 - val_loss: 0.5938\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5535 - val_loss: 0.5945\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5592 - val_loss: 0.6100\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5613 - val_loss: 0.5995\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5541 - val_loss: 0.5940\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5522 - val_loss: 0.5908\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.5515 - val_loss: 0.6166\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "MSE   : 0.4949931047223687\n"
     ]
    }
   ],
   "source": [
    "RNN_testing_7 = RNN_testing(normalizes_df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "023e794f-69d3-4ccb-ad75-7763b957015e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:20:26,671] A new study created in memory with name: no-name-1e99f8a2-5153-4100-9b29-7971a832348d\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:20:40,685] Trial 0 finished with value: 0.41167410649979874 and parameters: {'lstm_units': 80, 'learning_rate': 0.004558081754966352}. Best is trial 0 with value: 0.41167410649979874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41167410649979874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:20:50,455] Trial 1 finished with value: 0.411390149361827 and parameters: {'lstm_units': 80, 'learning_rate': 0.005819066258369839}. Best is trial 1 with value: 0.411390149361827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411390149361827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:20:59,541] Trial 2 finished with value: 0.41169329321909626 and parameters: {'lstm_units': 56, 'learning_rate': 0.003506668530738227}. Best is trial 1 with value: 0.411390149361827.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41169329321909626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:21:09,999] Trial 3 finished with value: 0.41138605992620814 and parameters: {'lstm_units': 82, 'learning_rate': 0.004881575402853082}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138605992620814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:21:18,019] Trial 4 finished with value: 0.4113954789325163 and parameters: {'lstm_units': 57, 'learning_rate': 0.002463271822005113}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113954789325163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:21:29,446] Trial 5 finished with value: 0.41141671862618473 and parameters: {'lstm_units': 67, 'learning_rate': 0.00015713451559260191}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141671862618473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:21:40,008] Trial 6 finished with value: 0.4117010953119345 and parameters: {'lstm_units': 69, 'learning_rate': 0.0003937693821889754}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117010953119345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:21:51,396] Trial 7 finished with value: 0.4113903440346576 and parameters: {'lstm_units': 64, 'learning_rate': 0.006828042463133265}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113903440346576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:22:00,284] Trial 8 finished with value: 0.41399954956001045 and parameters: {'lstm_units': 86, 'learning_rate': 0.005423857209726681}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41399954956001045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:22:10,623] Trial 9 finished with value: 0.41139332601942985 and parameters: {'lstm_units': 85, 'learning_rate': 0.0005628054111645608}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139332601942985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:22:22,201] Trial 10 finished with value: 0.41257566091089276 and parameters: {'lstm_units': 95, 'learning_rate': 0.001304730871404246}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41257566091089276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:22:34,477] Trial 11 finished with value: 0.4114885485940853 and parameters: {'lstm_units': 99, 'learning_rate': 0.009688098178399846}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114885485940853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:22:42,409] Trial 12 finished with value: 0.41167921123095047 and parameters: {'lstm_units': 75, 'learning_rate': 0.0019732993196870307}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41167921123095047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:22:59,032] Trial 13 finished with value: 0.41141961374456093 and parameters: {'lstm_units': 91, 'learning_rate': 0.0008921438195924368}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141961374456093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:23:09,728] Trial 14 finished with value: 0.41146030740253314 and parameters: {'lstm_units': 76, 'learning_rate': 0.009801751715424883}. Best is trial 3 with value: 0.41138605992620814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146030740253314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:23:18,108] Trial 15 finished with value: 0.41138471628915424 and parameters: {'lstm_units': 83, 'learning_rate': 0.00253762029143747}. Best is trial 15 with value: 0.41138471628915424.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138471628915424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:23:29,434] Trial 16 finished with value: 0.41138461914954483 and parameters: {'lstm_units': 87, 'learning_rate': 0.00248494192521158}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138461914954483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:23:43,342] Trial 17 finished with value: 0.41158646159089884 and parameters: {'lstm_units': 91, 'learning_rate': 0.0015661503505583266}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41158646159089884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:23:51,999] Trial 18 finished with value: 0.4114059713833965 and parameters: {'lstm_units': 89, 'learning_rate': 0.0008856775861792955}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114059713833965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:24:02,927] Trial 19 finished with value: 0.4115833466605741 and parameters: {'lstm_units': 50, 'learning_rate': 0.0029455498905432667}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115833466605741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:24:11,810] Trial 20 finished with value: 0.4129793334425179 and parameters: {'lstm_units': 72, 'learning_rate': 0.0001029065654695332}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129793334425179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:24:20,830] Trial 21 finished with value: 0.41145427491699205 and parameters: {'lstm_units': 82, 'learning_rate': 0.0032915764892234595}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145427491699205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:24:30,927] Trial 22 finished with value: 0.4118982526014714 and parameters: {'lstm_units': 85, 'learning_rate': 0.0020631472286629774}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118982526014714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:24:40,013] Trial 23 finished with value: 0.4138258941579942 and parameters: {'lstm_units': 96, 'learning_rate': 0.003994789751819631}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4138258941579942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:24:48,779] Trial 24 finished with value: 0.4114020879454673 and parameters: {'lstm_units': 77, 'learning_rate': 0.0013083087357610161}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114020879454673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:25:03,511] Trial 25 finished with value: 0.4116544565314853 and parameters: {'lstm_units': 88, 'learning_rate': 0.0005994117628738734}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116544565314853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:25:14,220] Trial 26 finished with value: 0.4115454860849557 and parameters: {'lstm_units': 82, 'learning_rate': 0.0022843841927303855}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115454860849557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:25:22,527] Trial 27 finished with value: 0.4115900326663102 and parameters: {'lstm_units': 94, 'learning_rate': 0.007182564239482275}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115900326663102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:25:34,188] Trial 28 finished with value: 0.411392120506135 and parameters: {'lstm_units': 100, 'learning_rate': 0.00443320250012674}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411392120506135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:25:43,239] Trial 29 finished with value: 0.41142097658547416 and parameters: {'lstm_units': 82, 'learning_rate': 0.0016337161030065075}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142097658547416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:25:53,759] Trial 30 finished with value: 0.41148881504228907 and parameters: {'lstm_units': 78, 'learning_rate': 0.00463859014602809}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148881504228907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:26:02,915] Trial 31 finished with value: 0.4120383653644315 and parameters: {'lstm_units': 79, 'learning_rate': 0.006291009356836943}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120383653644315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:26:16,082] Trial 32 finished with value: 0.41190710870409536 and parameters: {'lstm_units': 72, 'learning_rate': 0.003260477824874012}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41190710870409536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:26:26,237] Trial 33 finished with value: 0.41140268608461217 and parameters: {'lstm_units': 81, 'learning_rate': 0.005202601883515855}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140268608461217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:26:38,661] Trial 34 finished with value: 0.4113973186896925 and parameters: {'lstm_units': 74, 'learning_rate': 0.0028059100508983914}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113973186896925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:26:51,533] Trial 35 finished with value: 0.4113852611251074 and parameters: {'lstm_units': 85, 'learning_rate': 0.0037780159833368477}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113852611251074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:27:03,544] Trial 36 finished with value: 0.4114559293108262 and parameters: {'lstm_units': 86, 'learning_rate': 0.0036504296192630048}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114559293108262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:27:14,836] Trial 37 finished with value: 0.41142484614191527 and parameters: {'lstm_units': 90, 'learning_rate': 0.0002416926115636712}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142484614191527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:27:24,223] Trial 38 finished with value: 0.41207825795740194 and parameters: {'lstm_units': 84, 'learning_rate': 0.0024029096893651153}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41207825795740194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:27:32,712] Trial 39 finished with value: 0.41144000985973794 and parameters: {'lstm_units': 64, 'learning_rate': 0.008224997068386468}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144000985973794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:27:47,555] Trial 40 finished with value: 0.4113869034504644 and parameters: {'lstm_units': 87, 'learning_rate': 0.0011997155002682572}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113869034504644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:27:58,851] Trial 41 finished with value: 0.4113856010199724 and parameters: {'lstm_units': 93, 'learning_rate': 0.0011771433379110326}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113856010199724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:28:08,145] Trial 42 finished with value: 0.41180483118845507 and parameters: {'lstm_units': 92, 'learning_rate': 0.0006676523429735505}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41180483118845507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:28:24,219] Trial 43 finished with value: 0.4113890957150897 and parameters: {'lstm_units': 97, 'learning_rate': 0.001724211556512066}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113890957150897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:28:37,164] Trial 44 finished with value: 0.4114011442442503 and parameters: {'lstm_units': 93, 'learning_rate': 0.00037261234767186203}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114011442442503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:28:45,017] Trial 45 finished with value: 0.41139745495534 and parameters: {'lstm_units': 84, 'learning_rate': 0.002645684648451766}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139745495534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:28:55,392] Trial 46 finished with value: 0.4121031434092594 and parameters: {'lstm_units': 89, 'learning_rate': 0.0010624474935363945}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4121031434092594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:29:05,115] Trial 47 finished with value: 0.4114305815347136 and parameters: {'lstm_units': 79, 'learning_rate': 0.004733249343948046}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114305815347136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:29:13,358] Trial 48 finished with value: 0.41241061185947436 and parameters: {'lstm_units': 87, 'learning_rate': 0.006131005952919532}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41241061185947436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:29:23,972] Trial 49 finished with value: 0.41145003142534986 and parameters: {'lstm_units': 84, 'learning_rate': 0.0018649958064796085}. Best is trial 16 with value: 0.41138461914954483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145003142534986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:29:38,648] Trial 50 finished with value: 0.41109884525295826 and parameters: {'lstm_units': 98, 'learning_rate': 0.000779058877585361}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41109884525295826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:29:48,116] Trial 51 finished with value: 0.4121152154556108 and parameters: {'lstm_units': 97, 'learning_rate': 0.0008268265234594999}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4121152154556108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:30:02,128] Trial 52 finished with value: 0.4122941230691831 and parameters: {'lstm_units': 98, 'learning_rate': 0.000457559938410802}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122941230691831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:30:19,462] Trial 53 finished with value: 0.41147569716589155 and parameters: {'lstm_units': 94, 'learning_rate': 0.0007409865443996915}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41147569716589155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:30:32,532] Trial 54 finished with value: 0.41139840871295225 and parameters: {'lstm_units': 90, 'learning_rate': 0.001311213941166864}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139840871295225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:30:41,969] Trial 55 finished with value: 0.41140857279926407 and parameters: {'lstm_units': 92, 'learning_rate': 0.0010087951444526274}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140857279926407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:30:53,077] Trial 56 finished with value: 0.4115495379304006 and parameters: {'lstm_units': 95, 'learning_rate': 0.0038754904765486106}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115495379304006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:31:03,624] Trial 57 finished with value: 0.41142045139669237 and parameters: {'lstm_units': 100, 'learning_rate': 0.00047263113820522693}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142045139669237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:31:13,780] Trial 58 finished with value: 0.4113935153184381 and parameters: {'lstm_units': 89, 'learning_rate': 0.0030675729094576166}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113935153184381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:31:22,013] Trial 59 finished with value: 0.41165389016407555 and parameters: {'lstm_units': 81, 'learning_rate': 0.0021853125756175554}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41165389016407555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:31:35,876] Trial 60 finished with value: 0.41144891507644826 and parameters: {'lstm_units': 83, 'learning_rate': 0.0014714989376600038}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144891507644826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:31:44,911] Trial 61 finished with value: 0.4131475714613134 and parameters: {'lstm_units': 87, 'learning_rate': 0.0011126285015298572}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4131475714613134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:31:54,739] Trial 62 finished with value: 0.41138848482017976 and parameters: {'lstm_units': 86, 'learning_rate': 0.001228770616409819}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138848482017976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:32:05,429] Trial 63 finished with value: 0.412265855321267 and parameters: {'lstm_units': 88, 'learning_rate': 0.0008515152816519198}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.412265855321267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:32:13,548] Trial 64 finished with value: 0.41178446324046764 and parameters: {'lstm_units': 80, 'learning_rate': 0.0002921850437741808}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41178446324046764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:32:24,386] Trial 65 finished with value: 0.41139462845445923 and parameters: {'lstm_units': 91, 'learning_rate': 0.0019667797626700184}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139462845445923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:32:34,308] Trial 66 finished with value: 0.41138521834482666 and parameters: {'lstm_units': 85, 'learning_rate': 0.0015018441922580745}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138521834482666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:32:44,552] Trial 67 finished with value: 0.41182930063763185 and parameters: {'lstm_units': 76, 'learning_rate': 0.0025656230629246216}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41182930063763185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:32:51,476] Trial 68 finished with value: 0.411641391765007 and parameters: {'lstm_units': 59, 'learning_rate': 0.0013907961513593052}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411641391765007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:33:06,269] Trial 69 finished with value: 0.4121606347215654 and parameters: {'lstm_units': 85, 'learning_rate': 0.005319912261533548}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4121606347215654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:33:17,863] Trial 70 finished with value: 0.41140486447173474 and parameters: {'lstm_units': 93, 'learning_rate': 0.0017238919535437218}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140486447173474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:33:31,974] Trial 71 finished with value: 0.41143799112538526 and parameters: {'lstm_units': 87, 'learning_rate': 0.0011916358156042032}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143799112538526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:33:44,802] Trial 72 finished with value: 0.41148743756996836 and parameters: {'lstm_units': 85, 'learning_rate': 0.0034691819696109297}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148743756996836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:33:56,686] Trial 73 finished with value: 0.4118490534007938 and parameters: {'lstm_units': 82, 'learning_rate': 0.0009194200352693407}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118490534007938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:34:09,619] Trial 74 finished with value: 0.41138753684989093 and parameters: {'lstm_units': 83, 'learning_rate': 0.004199952355545013}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138753684989093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:34:18,472] Trial 75 finished with value: 0.4113852185179963 and parameters: {'lstm_units': 96, 'learning_rate': 0.0006968596572750519}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113852185179963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:34:33,731] Trial 76 finished with value: 0.4114313191077992 and parameters: {'lstm_units': 94, 'learning_rate': 0.000539707091882902}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114313191077992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:34:47,282] Trial 77 finished with value: 0.4114000365709085 and parameters: {'lstm_units': 98, 'learning_rate': 0.000689984137192144}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114000365709085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:34:56,887] Trial 78 finished with value: 0.41260737002179054 and parameters: {'lstm_units': 95, 'learning_rate': 0.008195132798329268}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41260737002179054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:35:06,577] Trial 79 finished with value: 0.41156784713175526 and parameters: {'lstm_units': 96, 'learning_rate': 0.002210791949949209}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41156784713175526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:35:22,294] Trial 80 finished with value: 0.4113881859173037 and parameters: {'lstm_units': 91, 'learning_rate': 0.002906149782039979}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113881859173037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:35:33,186] Trial 81 finished with value: 0.41151260105835696 and parameters: {'lstm_units': 88, 'learning_rate': 0.0007657754902314349}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41151260105835696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:35:44,437] Trial 82 finished with value: 0.41219391089676816 and parameters: {'lstm_units': 99, 'learning_rate': 0.0006060582747197323}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41219391089676816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:35:54,055] Trial 83 finished with value: 0.4113975119580415 and parameters: {'lstm_units': 79, 'learning_rate': 0.0009389250099506505}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113975119580415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:36:04,276] Trial 84 finished with value: 0.4114790079565893 and parameters: {'lstm_units': 89, 'learning_rate': 0.0015084183708537935}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114790079565893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:36:14,463] Trial 85 finished with value: 0.4114025243135217 and parameters: {'lstm_units': 86, 'learning_rate': 0.0010708596140855053}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114025243135217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:36:25,006] Trial 86 finished with value: 0.4114893174426173 and parameters: {'lstm_units': 81, 'learning_rate': 0.001906896679678308}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114893174426173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:36:37,728] Trial 87 finished with value: 0.4117772794298417 and parameters: {'lstm_units': 83, 'learning_rate': 0.00484339910875971}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117772794298417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:36:48,571] Trial 88 finished with value: 0.411658036894879 and parameters: {'lstm_units': 92, 'learning_rate': 0.003737387152650417}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411658036894879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:37:00,487] Trial 89 finished with value: 0.4119413412782995 and parameters: {'lstm_units': 96, 'learning_rate': 0.0025078313647898423}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119413412782995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:37:11,353] Trial 90 finished with value: 0.41205301117625065 and parameters: {'lstm_units': 78, 'learning_rate': 0.0031543647197927933}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41205301117625065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:37:28,262] Trial 91 finished with value: 0.4118596747799684 and parameters: {'lstm_units': 83, 'learning_rate': 0.0040266682792873}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118596747799684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:37:40,822] Trial 92 finished with value: 0.4115432375795857 and parameters: {'lstm_units': 84, 'learning_rate': 0.006128607605252928}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115432375795857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:37:49,444] Trial 93 finished with value: 0.41159423429655384 and parameters: {'lstm_units': 86, 'learning_rate': 0.004101870447998642}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41159423429655384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:38:03,701] Trial 94 finished with value: 0.41294177157070405 and parameters: {'lstm_units': 80, 'learning_rate': 0.004502078433520416}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41294177157070405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:38:17,149] Trial 95 finished with value: 0.41138966086307316 and parameters: {'lstm_units': 74, 'learning_rate': 0.007289917580345204}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138966086307316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:38:28,740] Trial 96 finished with value: 0.41178001095138733 and parameters: {'lstm_units': 90, 'learning_rate': 0.005549920726640517}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41178001095138733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:38:40,713] Trial 97 finished with value: 0.4113875483890294 and parameters: {'lstm_units': 83, 'learning_rate': 0.0016855790302690425}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113875483890294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:38:51,566] Trial 98 finished with value: 0.41332858924479043 and parameters: {'lstm_units': 88, 'learning_rate': 0.0008007765700413533}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41332858924479043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:38:58,432] Trial 99 finished with value: 0.4114183578921948 and parameters: {'lstm_units': 51, 'learning_rate': 0.0011704077535975006}. Best is trial 50 with value: 0.41109884525295826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114183578921948\n",
      "Best hyperparameters: {'lstm_units': 98, 'learning_rate': 0.000779058877585361}\n",
      "Best validation MSE: 0.41109884525295826\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "MSE   : 0.4163272217114901\n"
     ]
    }
   ],
   "source": [
    "RNN_testing_8 = RNN_testing(normalizes_df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a9d7742-cbcf-4567-9938-75345a1b23eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:39:10,827] A new study created in memory with name: no-name-0626b784-5598-461b-a132-5760c2a2f543\n",
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:39:24,294] Trial 0 finished with value: 0.41167587318706983 and parameters: {'lstm_units': 72, 'learning_rate': 0.009086584766116462}. Best is trial 0 with value: 0.41167587318706983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41167587318706983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:39:37,102] Trial 1 finished with value: 0.4136024263210696 and parameters: {'lstm_units': 85, 'learning_rate': 0.00019627272551537783}. Best is trial 0 with value: 0.41167587318706983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4136024263210696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:39:45,304] Trial 2 finished with value: 0.4144309068497582 and parameters: {'lstm_units': 53, 'learning_rate': 0.0001068042587034519}. Best is trial 0 with value: 0.41167587318706983.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4144309068497582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:39:58,718] Trial 3 finished with value: 0.4114572945079633 and parameters: {'lstm_units': 81, 'learning_rate': 0.0001475842041470258}. Best is trial 3 with value: 0.4114572945079633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114572945079633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:40:11,357] Trial 4 finished with value: 0.411543078738853 and parameters: {'lstm_units': 88, 'learning_rate': 0.0007797083763678454}. Best is trial 3 with value: 0.4114572945079633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411543078738853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:40:19,858] Trial 5 finished with value: 0.4114180808588761 and parameters: {'lstm_units': 79, 'learning_rate': 0.00171256845294514}. Best is trial 5 with value: 0.4114180808588761.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114180808588761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:40:30,633] Trial 6 finished with value: 0.41149445165100806 and parameters: {'lstm_units': 78, 'learning_rate': 0.0008710850963000193}. Best is trial 5 with value: 0.4114180808588761.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149445165100806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:40:44,045] Trial 7 finished with value: 0.4109331578888425 and parameters: {'lstm_units': 86, 'learning_rate': 0.0001314573115111655}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4109331578888425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:40:53,148] Trial 8 finished with value: 0.41151021296432505 and parameters: {'lstm_units': 76, 'learning_rate': 0.0036691564142164322}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41151021296432505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:41:03,197] Trial 9 finished with value: 0.41153114630088594 and parameters: {'lstm_units': 79, 'learning_rate': 0.004371973227941868}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41153114630088594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:41:18,227] Trial 10 finished with value: 0.41145971705136436 and parameters: {'lstm_units': 99, 'learning_rate': 0.00036234315557823015}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145971705136436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:41:25,881] Trial 11 finished with value: 0.4115012514909087 and parameters: {'lstm_units': 64, 'learning_rate': 0.00193710640279639}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115012514909087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:41:37,449] Trial 12 finished with value: 0.41139179596812003 and parameters: {'lstm_units': 94, 'learning_rate': 0.0003873508377839397}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139179596812003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:41:53,940] Trial 13 finished with value: 0.411310856290017 and parameters: {'lstm_units': 96, 'learning_rate': 0.000347940133309486}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411310856290017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:42:04,429] Trial 14 finished with value: 0.4113926420624333 and parameters: {'lstm_units': 92, 'learning_rate': 0.00031781907197143375}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113926420624333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:42:14,077] Trial 15 finished with value: 0.41371185222919543 and parameters: {'lstm_units': 99, 'learning_rate': 0.00023016056082838222}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41371185222919543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:42:30,941] Trial 16 finished with value: 0.41150392127173213 and parameters: {'lstm_units': 92, 'learning_rate': 0.0005758042628136414}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41150392127173213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:42:40,038] Trial 17 finished with value: 0.4145740494837229 and parameters: {'lstm_units': 67, 'learning_rate': 0.00015918151307763639}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4145740494837229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:42:55,262] Trial 18 finished with value: 0.41150427466886197 and parameters: {'lstm_units': 86, 'learning_rate': 0.000493117119589104}. Best is trial 7 with value: 0.4109331578888425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41150427466886197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:43:08,007] Trial 19 finished with value: 0.41075995537944227 and parameters: {'lstm_units': 100, 'learning_rate': 0.00010006784963143796}. Best is trial 19 with value: 0.41075995537944227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41075995537944227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:43:14,566] Trial 20 finished with value: 0.41396150391679826 and parameters: {'lstm_units': 51, 'learning_rate': 0.0001361535227445063}. Best is trial 19 with value: 0.41075995537944227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41396150391679826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:43:26,889] Trial 21 finished with value: 0.41159461000260483 and parameters: {'lstm_units': 100, 'learning_rate': 0.00010079726088087473}. Best is trial 19 with value: 0.41075995537944227.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41159461000260483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:43:36,609] Trial 22 finished with value: 0.41059669755056966 and parameters: {'lstm_units': 95, 'learning_rate': 0.0002661311001311557}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41059669755056966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:43:45,850] Trial 23 finished with value: 0.4114354600407627 and parameters: {'lstm_units': 89, 'learning_rate': 0.00023718469861408334}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114354600407627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:43:58,061] Trial 24 finished with value: 0.41156216048396843 and parameters: {'lstm_units': 95, 'learning_rate': 0.00023357977942760943}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41156216048396843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:44:08,145] Trial 25 finished with value: 0.4122903772164142 and parameters: {'lstm_units': 83, 'learning_rate': 0.00011060380956014404}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122903772164142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:44:18,026] Trial 26 finished with value: 0.41279861691474523 and parameters: {'lstm_units': 91, 'learning_rate': 0.00015409516264801643}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41279861691474523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:44:29,334] Trial 27 finished with value: 0.4118104402038622 and parameters: {'lstm_units': 96, 'learning_rate': 0.0001774188261167062}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118104402038622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:44:38,971] Trial 28 finished with value: 0.4114409046728713 and parameters: {'lstm_units': 88, 'learning_rate': 0.0005455548610933094}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114409046728713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:44:50,837] Trial 29 finished with value: 0.41146469734090996 and parameters: {'lstm_units': 68, 'learning_rate': 0.001270853682260705}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146469734090996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:45:01,341] Trial 30 finished with value: 0.41154839100547486 and parameters: {'lstm_units': 58, 'learning_rate': 0.00026603876838527914}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154839100547486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:45:19,062] Trial 31 finished with value: 0.411392296279027 and parameters: {'lstm_units': 95, 'learning_rate': 0.000300401021451089}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411392296279027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:45:31,894] Trial 32 finished with value: 0.4116001770320881 and parameters: {'lstm_units': 100, 'learning_rate': 0.00019217554962533596}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116001770320881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:45:47,369] Trial 33 finished with value: 0.4113359821389815 and parameters: {'lstm_units': 97, 'learning_rate': 0.00013861835728351977}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113359821389815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:45:59,330] Trial 34 finished with value: 0.4113780361974929 and parameters: {'lstm_units': 84, 'learning_rate': 0.00042790784009558977}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113780361974929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:46:10,124] Trial 35 finished with value: 0.41151469249819483 and parameters: {'lstm_units': 73, 'learning_rate': 0.0006776766996813214}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41151469249819483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:46:31,396] Trial 36 finished with value: 0.4108793892977608 and parameters: {'lstm_units': 90, 'learning_rate': 0.00011923514537271184}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4108793892977608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:46:41,428] Trial 37 finished with value: 0.4118172923929665 and parameters: {'lstm_units': 89, 'learning_rate': 0.00011973781953361852}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118172923929665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:46:58,635] Trial 38 finished with value: 0.41400160175592765 and parameters: {'lstm_units': 82, 'learning_rate': 0.00010334715818607723}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41400160175592765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:47:07,822] Trial 39 finished with value: 0.41114328955510976 and parameters: {'lstm_units': 86, 'learning_rate': 0.00018337479553223482}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41114328955510976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:47:17,551] Trial 40 finished with value: 0.41146196191480355 and parameters: {'lstm_units': 92, 'learning_rate': 0.009106258600083171}. Best is trial 22 with value: 0.41059669755056966.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146196191480355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:47:26,161] Trial 41 finished with value: 0.41058438095781297 and parameters: {'lstm_units': 86, 'learning_rate': 0.0001872147152898811}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41058438095781297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:47:37,110] Trial 42 finished with value: 0.4125183590964589 and parameters: {'lstm_units': 80, 'learning_rate': 0.000130694489134705}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4125183590964589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:47:46,936] Trial 43 finished with value: 0.4115038903728259 and parameters: {'lstm_units': 85, 'learning_rate': 0.00018723890162657461}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115038903728259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:48:00,378] Trial 44 finished with value: 0.4139041745364766 and parameters: {'lstm_units': 76, 'learning_rate': 0.00013575289113821687}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4139041745364766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:48:13,397] Trial 45 finished with value: 0.4114067874412405 and parameters: {'lstm_units': 93, 'learning_rate': 0.00021902841992113025}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114067874412405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:48:24,572] Trial 46 finished with value: 0.41139428737726463 and parameters: {'lstm_units': 90, 'learning_rate': 0.0029351764858655165}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139428737726463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:48:34,679] Trial 47 finished with value: 0.41138093425902617 and parameters: {'lstm_units': 98, 'learning_rate': 0.00028609973898036393}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138093425902617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:48:43,485] Trial 48 finished with value: 0.41221416631334024 and parameters: {'lstm_units': 87, 'learning_rate': 0.006846561770278261}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41221416631334024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:48:52,790] Trial 49 finished with value: 0.4113790170421155 and parameters: {'lstm_units': 94, 'learning_rate': 0.00015706465032485262}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113790170421155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:49:08,438] Trial 50 finished with value: 0.4132138807329626 and parameters: {'lstm_units': 97, 'learning_rate': 0.00011510453578365436}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4132138807329626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:49:17,710] Trial 51 finished with value: 0.4113952694420824 and parameters: {'lstm_units': 86, 'learning_rate': 0.0001906303792333109}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113952694420824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:49:27,622] Trial 52 finished with value: 0.41149176766087414 and parameters: {'lstm_units': 90, 'learning_rate': 0.0001620728584587456}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149176766087414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:49:42,604] Trial 53 finished with value: 0.41463697776195274 and parameters: {'lstm_units': 78, 'learning_rate': 0.00010099546429008822}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41463697776195274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:49:57,732] Trial 54 finished with value: 0.4120227632041427 and parameters: {'lstm_units': 83, 'learning_rate': 0.00022120459945665412}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120227632041427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:50:11,316] Trial 55 finished with value: 0.41209226686989175 and parameters: {'lstm_units': 87, 'learning_rate': 0.00013039167149745423}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41209226686989175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:50:22,467] Trial 56 finished with value: 0.4113960461929852 and parameters: {'lstm_units': 81, 'learning_rate': 0.00037065958727869905}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113960461929852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:50:31,167] Trial 57 finished with value: 0.4133290926006851 and parameters: {'lstm_units': 93, 'learning_rate': 0.00025584480485749524}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4133290926006851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:50:46,268] Trial 58 finished with value: 0.4115382957783915 and parameters: {'lstm_units': 98, 'learning_rate': 0.0010910453160041002}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115382957783915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:51:01,797] Trial 59 finished with value: 0.411525099332104 and parameters: {'lstm_units': 91, 'learning_rate': 0.00016930569080962366}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411525099332104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:51:11,609] Trial 60 finished with value: 0.41230979573162063 and parameters: {'lstm_units': 88, 'learning_rate': 0.00021185056299812365}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41230979573162063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:51:22,242] Trial 61 finished with value: 0.4116003176659798 and parameters: {'lstm_units': 95, 'learning_rate': 0.00031457040609919596}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116003176659798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:51:38,021] Trial 62 finished with value: 0.4122529870245127 and parameters: {'lstm_units': 100, 'learning_rate': 0.0001204225584871957}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122529870245127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:51:48,143] Trial 63 finished with value: 0.4132241395904009 and parameters: {'lstm_units': 96, 'learning_rate': 0.0003371617382306176}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4132241395904009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:52:02,247] Trial 64 finished with value: 0.41137758343285646 and parameters: {'lstm_units': 85, 'learning_rate': 0.0004457583383945756}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41137758343285646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:52:16,586] Trial 65 finished with value: 0.4111715011239332 and parameters: {'lstm_units': 93, 'learning_rate': 0.00014932209342668755}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4111715011239332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:52:30,453] Trial 66 finished with value: 0.41200642791104064 and parameters: {'lstm_units': 93, 'learning_rate': 0.00014377104564201767}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41200642791104064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:52:45,022] Trial 67 finished with value: 0.411034897924309 and parameters: {'lstm_units': 90, 'learning_rate': 0.00017339435090373256}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411034897924309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:52:54,779] Trial 68 finished with value: 0.41141629771870925 and parameters: {'lstm_units': 90, 'learning_rate': 0.00017922190487249786}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141629771870925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:53:07,455] Trial 69 finished with value: 0.41202915788126454 and parameters: {'lstm_units': 88, 'learning_rate': 0.0002551610772006112}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41202915788126454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:53:15,765] Trial 70 finished with value: 0.4144266396458202 and parameters: {'lstm_units': 83, 'learning_rate': 0.00012372398674086912}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4144266396458202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:53:27,226] Trial 71 finished with value: 0.4114318889954255 and parameters: {'lstm_units': 91, 'learning_rate': 0.00015055063413013938}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114318889954255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:53:39,663] Trial 72 finished with value: 0.41137230983971973 and parameters: {'lstm_units': 94, 'learning_rate': 0.00020583037085925376}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41137230983971973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:53:51,436] Trial 73 finished with value: 0.4129764474450677 and parameters: {'lstm_units': 86, 'learning_rate': 0.00010776865221252662}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129764474450677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:54:03,137] Trial 74 finished with value: 0.4114305045355854 and parameters: {'lstm_units': 58, 'learning_rate': 0.00016957554896842588}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114305045355854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:54:12,770] Trial 75 finished with value: 0.41205365035098523 and parameters: {'lstm_units': 98, 'learning_rate': 0.0001440734793044702}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41205365035098523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:54:23,872] Trial 76 finished with value: 0.41341208204308133 and parameters: {'lstm_units': 89, 'learning_rate': 0.00011705179560142366}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41341208204308133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:54:33,442] Trial 77 finished with value: 0.4112146700362612 and parameters: {'lstm_units': 96, 'learning_rate': 0.00019504796666436913}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4112146700362612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:54:41,991] Trial 78 finished with value: 0.4148106441227456 and parameters: {'lstm_units': 92, 'learning_rate': 0.0001582109440960845}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4148106441227456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:54:52,228] Trial 79 finished with value: 0.41147614151330025 and parameters: {'lstm_units': 85, 'learning_rate': 0.0015776721804301608}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41147614151330025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:55:01,543] Trial 80 finished with value: 0.4120207981860268 and parameters: {'lstm_units': 79, 'learning_rate': 0.00024009148230969018}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120207981860268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:55:12,681] Trial 81 finished with value: 0.41060861007448224 and parameters: {'lstm_units': 97, 'learning_rate': 0.00019338754527875013}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41060861007448224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:55:23,033] Trial 82 finished with value: 0.4110828767248026 and parameters: {'lstm_units': 94, 'learning_rate': 0.0001337250489487701}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4110828767248026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:55:38,623] Trial 83 finished with value: 0.41161602741237946 and parameters: {'lstm_units': 100, 'learning_rate': 0.00010161413292000209}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41161602741237946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:55:53,360] Trial 84 finished with value: 0.4115594674030378 and parameters: {'lstm_units': 97, 'learning_rate': 0.0002758642870933395}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115594674030378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:56:02,215] Trial 85 finished with value: 0.41143030585948187 and parameters: {'lstm_units': 95, 'learning_rate': 0.00013096044737296954}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143030585948187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:56:15,979] Trial 86 finished with value: 0.4114817388369005 and parameters: {'lstm_units': 99, 'learning_rate': 0.00018226561270075114}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114817388369005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:56:25,583] Trial 87 finished with value: 0.41434769822762557 and parameters: {'lstm_units': 87, 'learning_rate': 0.00011277316485617069}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41434769822762557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:56:37,949] Trial 88 finished with value: 0.41389047388339484 and parameters: {'lstm_units': 91, 'learning_rate': 0.00012999976038465907}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41389047388339484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:56:48,058] Trial 89 finished with value: 0.4114000851627196 and parameters: {'lstm_units': 94, 'learning_rate': 0.0002290345184375381}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114000851627196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:56:57,840] Trial 90 finished with value: 0.41165017121556796 and parameters: {'lstm_units': 98, 'learning_rate': 0.00020467690793868657}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41165017121556796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:57:08,389] Trial 91 finished with value: 0.41266632286702715 and parameters: {'lstm_units': 93, 'learning_rate': 0.0001533287401106333}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41266632286702715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:57:24,092] Trial 92 finished with value: 0.41139899693269794 and parameters: {'lstm_units': 89, 'learning_rate': 0.00014159206661204908}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139899693269794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:57:35,488] Trial 93 finished with value: 0.4114346476659946 and parameters: {'lstm_units': 92, 'learning_rate': 0.00016408600004118272}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114346476659946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:57:48,624] Trial 94 finished with value: 0.4126680009491114 and parameters: {'lstm_units': 90, 'learning_rate': 0.000179708728858831}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4126680009491114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:58:02,411] Trial 95 finished with value: 0.4114188851702828 and parameters: {'lstm_units': 96, 'learning_rate': 0.00075823242950409}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114188851702828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:58:14,123] Trial 96 finished with value: 0.41246441905612397 and parameters: {'lstm_units': 97, 'learning_rate': 0.00011494110784846292}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41246441905612397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:58:22,601] Trial 97 finished with value: 0.4114001360211867 and parameters: {'lstm_units': 95, 'learning_rate': 0.00013889371311311176}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114001360211867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:58:35,803] Trial 98 finished with value: 0.4119670223556217 and parameters: {'lstm_units': 84, 'learning_rate': 0.00017649806123036876}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119670223556217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariy\\PycharmProjects\\Copy_dp\\.venv\\lib\\site-packages\\optuna\\trial\\_trial.py:682: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'step': None, 'low': 0.0001, 'high': 0.01, 'log': True}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 21:58:45,076] Trial 99 finished with value: 0.41157586290210274 and parameters: {'lstm_units': 99, 'learning_rate': 0.00231663873100617}. Best is trial 41 with value: 0.41058438095781297.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41157586290210274\n",
      "Best hyperparameters: {'lstm_units': 86, 'learning_rate': 0.0001872147152898811}\n",
      "Best validation MSE: 0.41058438095781297\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "MSE   : 0.29290808611612407\n"
     ]
    }
   ],
   "source": [
    "RNN_testing_9 = RNN_testing(normalizes_df_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0759427-5c65-4f8d-869b-da5f86722b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(trial, time_steps, input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "     LSTM   ,  Optuna.\n",
    "    \"\"\"\n",
    "    \n",
    "    units = trial.suggest_int('units', 32, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, time_steps):\n",
    "    \n",
    "    \"\"\"\n",
    "       Optuna: ,    LSTM .\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    epochs = trial.suggest_int('epochs', 50, 200)\n",
    "\n",
    "    input_shape = X_train.shape[2]\n",
    "    model = create_lstm_model(trial, time_steps, input_shape)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    return mse_val\n",
    "\n",
    "def LSTM_testing(df):\n",
    "    \"\"\"\n",
    "     LSTM ,  Optuna   .\n",
    "    \"\"\"\n",
    "\n",
    "    time_steps = 10\n",
    "    X_train, X_test, X_val, y_val, y_train, y_test = divides_into_samples(df)\n",
    "\n",
    "    X_train, y_train = create_dataset(X_train.to_numpy(), y_train.to_numpy(), time_steps)\n",
    "    X_val, y_val = create_dataset(X_val.to_numpy(), y_val.to_numpy(), time_steps)\n",
    "    X_test, y_test = create_dataset(X_test.to_numpy(), y_test.to_numpy(), time_steps)\n",
    "\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2]))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))\n",
    "\n",
    "    def objective_wrapper(trial):\n",
    "        return objective(trial, X_train, y_train, X_val, y_val, time_steps)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective_wrapper, n_trials=100)\n",
    "\n",
    "    print(\"Best Trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    best_units = trial.params['units']\n",
    "    best_learning_rate = trial.params['learning_rate']\n",
    "    best_epochs = trial.params['epochs']\n",
    "    best_batch_size = trial.params['batch_size']\n",
    "\n",
    "    input_shape = X_train.shape[2]\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=best_units, return_sequences=True, input_shape=(time_steps, input_shape)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer=Adam(learning_rate=best_learning_rate), loss='mean_squared_error')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=best_epochs, batch_size=best_batch_size, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    print(f\"MSE   : {mse_val}\")\n",
    "    \n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    print(f\"MSE   : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcf43fd5-dc14-4f5b-81ea-750fa2cb6df7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:01:24,228] A new study created in memory with name: no-name-3adab289-a11c-47dd-a591-2d96c970a56e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:01:33,441] Trial 0 finished with value: 0.4116478084170598 and parameters: {'lstm_units': 78, 'learning_rate': 0.002612099314663446}. Best is trial 0 with value: 0.4116478084170598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116478084170598\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:01:40,672] Trial 1 finished with value: 0.41132770117008566 and parameters: {'lstm_units': 94, 'learning_rate': 0.00026465432010695116}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41132770117008566\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:01:47,832] Trial 2 finished with value: 0.411440899010699 and parameters: {'lstm_units': 84, 'learning_rate': 0.0022349961047230973}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411440899010699\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:01,328] Trial 3 finished with value: 0.4121573080420339 and parameters: {'lstm_units': 96, 'learning_rate': 0.0002472107838970124}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4121573080420339\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:08,098] Trial 4 finished with value: 0.4116473852955454 and parameters: {'lstm_units': 72, 'learning_rate': 0.005761456013154028}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116473852955454\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:14,997] Trial 5 finished with value: 0.41354748725307844 and parameters: {'lstm_units': 55, 'learning_rate': 0.005937393731894835}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41354748725307844\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:22,526] Trial 6 finished with value: 0.4114175877372069 and parameters: {'lstm_units': 68, 'learning_rate': 0.0005258029788860514}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114175877372069\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:30,023] Trial 7 finished with value: 0.4115120898809961 and parameters: {'lstm_units': 38, 'learning_rate': 0.006393602749964468}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115120898809961\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:42,345] Trial 8 finished with value: 0.41313815108146434 and parameters: {'lstm_units': 126, 'learning_rate': 0.0002798137247062062}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41313815108146434\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:02:50,656] Trial 9 finished with value: 0.41139682516963383 and parameters: {'lstm_units': 95, 'learning_rate': 0.0017754122534994119}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139682516963383\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:03:02,661] Trial 10 finished with value: 0.41271547956755467 and parameters: {'lstm_units': 120, 'learning_rate': 0.00010136636383482952}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41271547956755467\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:03:11,628] Trial 11 finished with value: 0.4113857510113003 and parameters: {'lstm_units': 100, 'learning_rate': 0.001083953664060954}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113857510113003\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:03:27,082] Trial 12 finished with value: 0.4114691890653573 and parameters: {'lstm_units': 108, 'learning_rate': 0.0006334280562003944}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114691890653573\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:03:38,177] Trial 13 finished with value: 0.41150933145858826 and parameters: {'lstm_units': 106, 'learning_rate': 0.0009621819844388134}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41150933145858826\n",
      "4/4 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:03:46,161] Trial 14 finished with value: 0.4119320225733366 and parameters: {'lstm_units': 91, 'learning_rate': 0.00011557666799973812}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119320225733366\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:03:58,742] Trial 15 finished with value: 0.4117973970373197 and parameters: {'lstm_units': 111, 'learning_rate': 0.00031231989688803566}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117973970373197\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:04:08,854] Trial 16 finished with value: 0.4120414743619248 and parameters: {'lstm_units': 56, 'learning_rate': 0.0011983794425716445}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120414743619248\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:04:18,854] Trial 17 finished with value: 0.4113996418694799 and parameters: {'lstm_units': 102, 'learning_rate': 0.0004992984673332287}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113996418694799\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:04:31,106] Trial 18 finished with value: 0.41170122414735644 and parameters: {'lstm_units': 115, 'learning_rate': 0.00017625550254286968}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41170122414735644\n",
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:04:39,581] Trial 19 finished with value: 0.41199211103214073 and parameters: {'lstm_units': 86, 'learning_rate': 0.0031589040167296864}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41199211103214073\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:04:49,244] Trial 20 finished with value: 0.41145357436984065 and parameters: {'lstm_units': 63, 'learning_rate': 0.0009334411816767959}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145357436984065\n",
      "4/4 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:04:59,068] Trial 21 finished with value: 0.41309478902462077 and parameters: {'lstm_units': 98, 'learning_rate': 0.001480520804835907}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41309478902462077\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:05:14,960] Trial 22 finished with value: 0.4118691588510473 and parameters: {'lstm_units': 92, 'learning_rate': 0.0014752334801805117}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118691588510473\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:05:24,385] Trial 23 finished with value: 0.41152740268321175 and parameters: {'lstm_units': 78, 'learning_rate': 0.002101522848118953}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41152740268321175\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:05:34,135] Trial 24 finished with value: 0.4114614533725242 and parameters: {'lstm_units': 101, 'learning_rate': 0.0038012442358599514}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114614533725242\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:05:43,545] Trial 25 finished with value: 0.4113858447873196 and parameters: {'lstm_units': 91, 'learning_rate': 0.00975559871891548}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113858447873196\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:05:50,835] Trial 26 finished with value: 0.41138925192599246 and parameters: {'lstm_units': 88, 'learning_rate': 0.008180002909444532}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138925192599246\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:05:58,472] Trial 27 finished with value: 0.41164031055582406 and parameters: {'lstm_units': 116, 'learning_rate': 0.0041862480332292545}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41164031055582406\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:06:08,923] Trial 28 finished with value: 0.41139733509085796 and parameters: {'lstm_units': 128, 'learning_rate': 0.00039084720947953354}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139733509085796\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:06:20,856] Trial 29 finished with value: 0.4116150612305722 and parameters: {'lstm_units': 80, 'learning_rate': 0.009617796114081437}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116150612305722\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:06:31,872] Trial 30 finished with value: 0.4119867361492168 and parameters: {'lstm_units': 75, 'learning_rate': 0.00017039704897306652}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119867361492168\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:06:40,550] Trial 31 finished with value: 0.41140158116030195 and parameters: {'lstm_units': 88, 'learning_rate': 0.009365106105458782}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140158116030195\n",
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:06:51,933] Trial 32 finished with value: 0.413428225331297 and parameters: {'lstm_units': 83, 'learning_rate': 0.007274861115606405}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.413428225331297\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:04,733] Trial 33 finished with value: 0.41159013579882714 and parameters: {'lstm_units': 104, 'learning_rate': 0.004515207573952407}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41159013579882714\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:14,508] Trial 34 finished with value: 0.4115214229277759 and parameters: {'lstm_units': 97, 'learning_rate': 0.002601180829420784}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115214229277759\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:23,706] Trial 35 finished with value: 0.4115998758577617 and parameters: {'lstm_units': 85, 'learning_rate': 0.0007320245410298791}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115998758577617\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:33,106] Trial 36 finished with value: 0.4115364162325605 and parameters: {'lstm_units': 91, 'learning_rate': 0.007789788653065166}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115364162325605\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:42,622] Trial 37 finished with value: 0.41215722009476297 and parameters: {'lstm_units': 72, 'learning_rate': 0.004866484695980508}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41215722009476297\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:51,333] Trial 38 finished with value: 0.4130945931010363 and parameters: {'lstm_units': 66, 'learning_rate': 0.0001886517361052187}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4130945931010363\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:07:58,920] Trial 39 finished with value: 0.4133062170140099 and parameters: {'lstm_units': 96, 'learning_rate': 0.003186148912078784}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4133062170140099\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:07,927] Trial 40 finished with value: 0.4113891842972651 and parameters: {'lstm_units': 80, 'learning_rate': 0.005666831188341716}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113891842972651\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:17,389] Trial 41 finished with value: 0.41145902664697154 and parameters: {'lstm_units': 83, 'learning_rate': 0.005541362065060098}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145902664697154\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:23,931] Trial 42 finished with value: 0.4116697979332668 and parameters: {'lstm_units': 79, 'learning_rate': 0.0073000097878711135}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116697979332668\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:31,894] Trial 43 finished with value: 0.41138469850770487 and parameters: {'lstm_units': 41, 'learning_rate': 0.009356770921582405}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138469850770487\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:37,832] Trial 44 finished with value: 0.4114919029244322 and parameters: {'lstm_units': 43, 'learning_rate': 0.00586421463449945}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114919029244322\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:45,111] Trial 45 finished with value: 0.4124818775484237 and parameters: {'lstm_units': 35, 'learning_rate': 0.009160854924338368}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124818775484237\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:52,419] Trial 46 finished with value: 0.41227719930283957 and parameters: {'lstm_units': 42, 'learning_rate': 0.006282712688289506}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41227719930283957\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:08:59,867] Trial 47 finished with value: 0.4129225621815482 and parameters: {'lstm_units': 49, 'learning_rate': 0.0003666438789828923}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129225621815482\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:06,871] Trial 48 finished with value: 0.4113365858190964 and parameters: {'lstm_units': 59, 'learning_rate': 0.0006738687252871886}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113365858190964\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:16,997] Trial 49 finished with value: 0.41254434405133217 and parameters: {'lstm_units': 59, 'learning_rate': 0.00024334648005690425}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41254434405133217\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:25,822] Trial 50 finished with value: 0.41273537935512566 and parameters: {'lstm_units': 46, 'learning_rate': 0.0007448682007034989}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41273537935512566\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:32,004] Trial 51 finished with value: 0.4113853507598931 and parameters: {'lstm_units': 51, 'learning_rate': 0.0005912872179849748}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113853507598931\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:40,926] Trial 52 finished with value: 0.4126749857233816 and parameters: {'lstm_units': 51, 'learning_rate': 0.0005469026977682886}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4126749857233816\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:50,640] Trial 53 finished with value: 0.41212612043890945 and parameters: {'lstm_units': 34, 'learning_rate': 0.00041470160813573276}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41212612043890945\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:09:58,885] Trial 54 finished with value: 0.41159996151682954 and parameters: {'lstm_units': 39, 'learning_rate': 0.0009314543404749286}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41159996151682954\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:10:07,477] Trial 55 finished with value: 0.4113977590476697 and parameters: {'lstm_units': 52, 'learning_rate': 0.0011121807301450219}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113977590476697\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:10:14,107] Trial 56 finished with value: 0.41354850948080296 and parameters: {'lstm_units': 59, 'learning_rate': 0.00014362743086124147}. Best is trial 1 with value: 0.41132770117008566.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41354850948080296\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:10:27,106] Trial 57 finished with value: 0.4112257270868466 and parameters: {'lstm_units': 107, 'learning_rate': 0.0004962413046453412}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4112257270868466\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:10:37,123] Trial 58 finished with value: 0.4114519114899117 and parameters: {'lstm_units': 113, 'learning_rate': 0.0004609934680343967}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114519114899117\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:10:45,326] Trial 59 finished with value: 0.41148676176739063 and parameters: {'lstm_units': 109, 'learning_rate': 0.0003195139736683191}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148676176739063\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:10:54,682] Trial 60 finished with value: 0.4116127604823572 and parameters: {'lstm_units': 120, 'learning_rate': 0.0005793480680629858}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116127604823572\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:11:08,656] Trial 61 finished with value: 0.4113854421729615 and parameters: {'lstm_units': 101, 'learning_rate': 0.0007045065725545495}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113854421729615\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:11:20,178] Trial 62 finished with value: 0.411400252820556 and parameters: {'lstm_units': 100, 'learning_rate': 0.0007781780271240483}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411400252820556\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:11:29,115] Trial 63 finished with value: 0.4115049459952571 and parameters: {'lstm_units': 108, 'learning_rate': 0.00024872471392402073}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115049459952571\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:11:39,011] Trial 64 finished with value: 0.4113956082927258 and parameters: {'lstm_units': 105, 'learning_rate': 0.0006466904970816696}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113956082927258\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:11:51,232] Trial 65 finished with value: 0.41138527157579075 and parameters: {'lstm_units': 119, 'learning_rate': 0.0012456191077889007}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138527157579075\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:12:02,131] Trial 66 finished with value: 0.4114104989776305 and parameters: {'lstm_units': 120, 'learning_rate': 0.0014706743477862095}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114104989776305\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:12:13,400] Trial 67 finished with value: 0.4114913213178707 and parameters: {'lstm_units': 116, 'learning_rate': 0.0008950685367041885}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114913213178707\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:12:28,807] Trial 68 finished with value: 0.4114156153080424 and parameters: {'lstm_units': 125, 'learning_rate': 0.0006655543892580241}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114156153080424\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:12:36,247] Trial 69 finished with value: 0.4114750893045641 and parameters: {'lstm_units': 55, 'learning_rate': 0.0013112564534349116}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114750893045641\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:12:43,429] Trial 70 finished with value: 0.4122043366115855 and parameters: {'lstm_units': 46, 'learning_rate': 0.00046687182170928134}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122043366115855\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:12:55,469] Trial 71 finished with value: 0.4115351797035336 and parameters: {'lstm_units': 93, 'learning_rate': 0.0018585646334853482}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115351797035336\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:13:11,006] Trial 72 finished with value: 0.4115939834808718 and parameters: {'lstm_units': 100, 'learning_rate': 0.0010602316066613516}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115939834808718\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:13:21,858] Trial 73 finished with value: 0.4114721283522994 and parameters: {'lstm_units': 103, 'learning_rate': 0.0008825045680929755}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114721283522994\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:13:33,310] Trial 74 finished with value: 0.41193472904559353 and parameters: {'lstm_units': 110, 'learning_rate': 0.00034370754252075603}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41193472904559353\n",
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:13:40,985] Trial 75 finished with value: 0.4114033331790239 and parameters: {'lstm_units': 106, 'learning_rate': 0.0005878192977608828}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114033331790239\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:13:57,753] Trial 76 finished with value: 0.41181030512237554 and parameters: {'lstm_units': 113, 'learning_rate': 0.0012378165161275219}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41181030512237554\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:14:07,604] Trial 77 finished with value: 0.4114050309067979 and parameters: {'lstm_units': 119, 'learning_rate': 0.0008110174303275832}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114050309067979\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:14:15,670] Trial 78 finished with value: 0.4115886066701409 and parameters: {'lstm_units': 38, 'learning_rate': 0.000423846903517412}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115886066701409\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:14:26,460] Trial 79 finished with value: 0.4121133992511997 and parameters: {'lstm_units': 94, 'learning_rate': 0.0002725328137472497}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4121133992511997\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:14:34,985] Trial 80 finished with value: 0.41198297421015645 and parameters: {'lstm_units': 88, 'learning_rate': 0.00020265984929151583}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41198297421015645\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:14:44,309] Trial 81 finished with value: 0.4133434539443101 and parameters: {'lstm_units': 98, 'learning_rate': 0.0004885651542153642}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4133434539443101\n",
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:14:56,209] Trial 82 finished with value: 0.4124991902441947 and parameters: {'lstm_units': 90, 'learning_rate': 0.001670897703292141}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124991902441947\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:15:05,824] Trial 83 finished with value: 0.41160574989022136 and parameters: {'lstm_units': 95, 'learning_rate': 0.0022970722877720747}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41160574989022136\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:15:16,004] Trial 84 finished with value: 0.41242928732976686 and parameters: {'lstm_units': 32, 'learning_rate': 0.0006811413546464191}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41242928732976686\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:15:25,650] Trial 85 finished with value: 0.41295134095845504 and parameters: {'lstm_units': 102, 'learning_rate': 0.0001259506336722225}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41295134095845504\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:15:33,173] Trial 86 finished with value: 0.41140636353920185 and parameters: {'lstm_units': 71, 'learning_rate': 0.0005246607225473787}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140636353920185\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:15:43,232] Trial 87 finished with value: 0.41151657708557365 and parameters: {'lstm_units': 98, 'learning_rate': 0.001051395659972256}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41151657708557365\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:15:51,252] Trial 88 finished with value: 0.41211046478795854 and parameters: {'lstm_units': 46, 'learning_rate': 0.0036483519194046013}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41211046478795854\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:16:05,233] Trial 89 finished with value: 0.41139705346943517 and parameters: {'lstm_units': 124, 'learning_rate': 0.009982870300137201}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139705346943517\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:16:13,747] Trial 90 finished with value: 0.41162873220278323 and parameters: {'lstm_units': 63, 'learning_rate': 0.0083608981757527}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41162873220278323\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:16:21,788] Trial 91 finished with value: 0.41322038416699464 and parameters: {'lstm_units': 89, 'learning_rate': 0.006835398077067013}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41322038416699464\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:16:34,884] Trial 92 finished with value: 0.41181157901205634 and parameters: {'lstm_units': 106, 'learning_rate': 0.00082977742523129}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41181157901205634\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:16:43,192] Trial 93 finished with value: 0.4114068506838133 and parameters: {'lstm_units': 86, 'learning_rate': 0.00818671875277151}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114068506838133\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:16:49,888] Trial 94 finished with value: 0.4115993287727683 and parameters: {'lstm_units': 41, 'learning_rate': 0.005419664424568186}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115993287727683\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:17:03,587] Trial 95 finished with value: 0.4113987395175631 and parameters: {'lstm_units': 81, 'learning_rate': 0.0007017129329591529}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113987395175631\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:17:11,707] Trial 96 finished with value: 0.4117119859507996 and parameters: {'lstm_units': 60, 'learning_rate': 0.0006126976565723411}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117119859507996\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:17:25,015] Trial 97 finished with value: 0.41229454097595586 and parameters: {'lstm_units': 77, 'learning_rate': 0.0050988553264650965}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41229454097595586\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:17:38,462] Trial 98 finished with value: 0.4122634381581553 and parameters: {'lstm_units': 100, 'learning_rate': 0.0013392290417277505}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122634381581553\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:17:46,489] Trial 99 finished with value: 0.41144312277008316 and parameters: {'lstm_units': 52, 'learning_rate': 0.0091638047237351}. Best is trial 57 with value: 0.4112257270868466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144312277008316\n",
      "Best Trial:\n",
      "  Value: 0.4112257270868466\n",
      "  Params: \n",
      "    lstm_units: 107\n",
      "    learning_rate: 0.0004962413046453412\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "MSE   : 0.47249612855128725\n"
     ]
    }
   ],
   "source": [
    "LSTM_testing_1 = LSTM_testing(normalizes_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46a3fd9e-1ea0-427c-8960-8e8dc1ab216a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:19:45,689] A new study created in memory with name: no-name-0ce1bfae-2d7a-421b-8d16-8aee5d85867f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:20:00,285] Trial 0 finished with value: 0.4113847562068758 and parameters: {'lstm_units': 119, 'learning_rate': 0.005102397411829767}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113847562068758\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:20:16,922] Trial 1 finished with value: 0.41260054304698035 and parameters: {'lstm_units': 128, 'learning_rate': 0.003344490608084064}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41260054304698035\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:20:25,352] Trial 2 finished with value: 0.41483296816101517 and parameters: {'lstm_units': 81, 'learning_rate': 0.00010977254955648894}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41483296816101517\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:20:35,250] Trial 3 finished with value: 0.4113925284201326 and parameters: {'lstm_units': 57, 'learning_rate': 0.0004912115055379231}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113925284201326\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:20:46,606] Trial 4 finished with value: 0.41139735145896217 and parameters: {'lstm_units': 124, 'learning_rate': 0.003399994094739714}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139735145896217\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:20:55,425] Trial 5 finished with value: 0.4114855378531991 and parameters: {'lstm_units': 55, 'learning_rate': 0.0008475249717229202}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114855378531991\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:21:04,254] Trial 6 finished with value: 0.4132326323187636 and parameters: {'lstm_units': 32, 'learning_rate': 0.00016653694512743476}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4132326323187636\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:21:18,669] Trial 7 finished with value: 0.41147212964333263 and parameters: {'lstm_units': 125, 'learning_rate': 0.002435639632304509}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41147212964333263\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:21:28,906] Trial 8 finished with value: 0.4116628195960851 and parameters: {'lstm_units': 48, 'learning_rate': 0.00031667364857072025}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116628195960851\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:21:40,409] Trial 9 finished with value: 0.4114030638305823 and parameters: {'lstm_units': 81, 'learning_rate': 0.0010427680897299306}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114030638305823\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:21:49,662] Trial 10 finished with value: 0.41149250923092046 and parameters: {'lstm_units': 104, 'learning_rate': 0.009041238315048768}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149250923092046\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:21:57,601] Trial 11 finished with value: 0.41139934231228054 and parameters: {'lstm_units': 67, 'learning_rate': 0.0005386903081450546}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139934231228054\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:22:05,872] Trial 12 finished with value: 0.41143336330356883 and parameters: {'lstm_units': 98, 'learning_rate': 0.0015178907142966284}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143336330356883\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:22:17,775] Trial 13 finished with value: 0.4115937402266679 and parameters: {'lstm_units': 98, 'learning_rate': 0.006083099210330485}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115937402266679\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:22:28,274] Trial 14 finished with value: 0.4115549804873821 and parameters: {'lstm_units': 64, 'learning_rate': 0.00037193065660857374}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115549804873821\n",
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:22:35,646] Trial 15 finished with value: 0.413026683243774 and parameters: {'lstm_units': 40, 'learning_rate': 0.00023296505523898455}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.413026683243774\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:22:48,134] Trial 16 finished with value: 0.41192070615927884 and parameters: {'lstm_units': 110, 'learning_rate': 0.0006617453331570661}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41192070615927884\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:22:57,738] Trial 17 finished with value: 0.41143073405769526 and parameters: {'lstm_units': 68, 'learning_rate': 0.0013091250624669602}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143073405769526\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:23:06,047] Trial 18 finished with value: 0.41139774525889455 and parameters: {'lstm_units': 87, 'learning_rate': 0.0018515606111847906}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139774525889455\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:23:15,332] Trial 19 finished with value: 0.41245803763660777 and parameters: {'lstm_units': 58, 'learning_rate': 0.0068222287627773435}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41245803763660777\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:23:24,771] Trial 20 finished with value: 0.411756771222598 and parameters: {'lstm_units': 111, 'learning_rate': 0.0005192335357637201}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411756771222598\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:23:32,922] Trial 21 finished with value: 0.41139003581347666 and parameters: {'lstm_units': 121, 'learning_rate': 0.004175288267390681}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139003581347666\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:23:47,195] Trial 22 finished with value: 0.4139649314083782 and parameters: {'lstm_units': 119, 'learning_rate': 0.004536343187236199}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4139649314083782\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:23:55,797] Trial 23 finished with value: 0.41164964036695073 and parameters: {'lstm_units': 113, 'learning_rate': 0.002553666491514243}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41164964036695073\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:24:03,904] Trial 24 finished with value: 0.4129235349273402 and parameters: {'lstm_units': 96, 'learning_rate': 0.009292681592799378}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129235349273402\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:24:13,219] Trial 25 finished with value: 0.4114201865028372 and parameters: {'lstm_units': 89, 'learning_rate': 0.004810476711513847}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114201865028372\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:24:22,733] Trial 26 finished with value: 0.4113873147208287 and parameters: {'lstm_units': 73, 'learning_rate': 0.0019457297631902241}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113873147208287\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:24:32,595] Trial 27 finished with value: 0.4114214741997891 and parameters: {'lstm_units': 76, 'learning_rate': 0.002216691698209463}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114214741997891\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:24:47,606] Trial 28 finished with value: 0.41186848939026355 and parameters: {'lstm_units': 117, 'learning_rate': 0.0037098271416398324}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41186848939026355\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:25:00,644] Trial 29 finished with value: 0.41380820203108815 and parameters: {'lstm_units': 128, 'learning_rate': 0.006064254160809255}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41380820203108815\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:25:12,256] Trial 30 finished with value: 0.41143135284938015 and parameters: {'lstm_units': 104, 'learning_rate': 0.0029981535633176546}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143135284938015\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:25:24,032] Trial 31 finished with value: 0.41161961287456655 and parameters: {'lstm_units': 72, 'learning_rate': 0.0016797232726878289}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41161961287456655\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:25:32,118] Trial 32 finished with value: 0.41144086070215596 and parameters: {'lstm_units': 58, 'learning_rate': 0.0011044034437067943}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41144086070215596\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:25:39,352] Trial 33 finished with value: 0.41257456165711776 and parameters: {'lstm_units': 88, 'learning_rate': 0.00428214937707118}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41257456165711776\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:25:53,951] Trial 34 finished with value: 0.41192169361779696 and parameters: {'lstm_units': 80, 'learning_rate': 0.003232829033867234}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41192169361779696\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:00,583] Trial 35 finished with value: 0.41143421033700184 and parameters: {'lstm_units': 45, 'learning_rate': 0.0007554411549006088}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143421033700184\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:08,389] Trial 36 finished with value: 0.41321248696415386 and parameters: {'lstm_units': 52, 'learning_rate': 0.00017596916060406517}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41321248696415386\n",
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:19,944] Trial 37 finished with value: 0.4116207865863619 and parameters: {'lstm_units': 121, 'learning_rate': 0.0019980800693013027}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116207865863619\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:28,645] Trial 38 finished with value: 0.4128950549224748 and parameters: {'lstm_units': 59, 'learning_rate': 0.007109870620923401}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4128950549224748\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:34,926] Trial 39 finished with value: 0.4147207053582766 and parameters: {'lstm_units': 32, 'learning_rate': 0.00011870413784323553}. Best is trial 0 with value: 0.4113847562068758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4147207053582766\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:43,305] Trial 40 finished with value: 0.41137875798206497 and parameters: {'lstm_units': 74, 'learning_rate': 0.0003820453037915766}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41137875798206497\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:26:54,222] Trial 41 finished with value: 0.4119665477112774 and parameters: {'lstm_units': 63, 'learning_rate': 0.0003522105197771235}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119665477112774\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:27:05,147] Trial 42 finished with value: 0.41141095608747147 and parameters: {'lstm_units': 76, 'learning_rate': 0.00044989486039361806}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141095608747147\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:27:14,084] Trial 43 finished with value: 0.4120359373403254 and parameters: {'lstm_units': 73, 'learning_rate': 0.00025475778958157513}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120359373403254\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:27:28,103] Trial 44 finished with value: 0.41187814008513707 and parameters: {'lstm_units': 83, 'learning_rate': 0.0009157898154819338}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41187814008513707\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:27:35,383] Trial 45 finished with value: 0.4115171429101829 and parameters: {'lstm_units': 51, 'learning_rate': 0.0006527009772176744}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115171429101829\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:27:48,196] Trial 46 finished with value: 0.41153547693095244 and parameters: {'lstm_units': 103, 'learning_rate': 0.0013068960542146199}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41153547693095244\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:27:57,195] Trial 47 finished with value: 0.41340022015459865 and parameters: {'lstm_units': 93, 'learning_rate': 0.0004506168992470763}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41340022015459865\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:28:09,942] Trial 48 finished with value: 0.4120057801206269 and parameters: {'lstm_units': 65, 'learning_rate': 0.00028023258017122047}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120057801206269\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:28:17,802] Trial 49 finished with value: 0.4114032315524958 and parameters: {'lstm_units': 70, 'learning_rate': 0.0028444166017711995}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114032315524958\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:28:27,714] Trial 50 finished with value: 0.4152086264971109 and parameters: {'lstm_units': 39, 'learning_rate': 0.00019127260700145667}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4152086264971109\n",
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:28:36,969] Trial 51 finished with value: 0.41146805538631986 and parameters: {'lstm_units': 125, 'learning_rate': 0.003716589402842531}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146805538631986\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:28:49,754] Trial 52 finished with value: 0.41163653258127614 and parameters: {'lstm_units': 115, 'learning_rate': 0.005582170205005773}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41163653258127614\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:28:59,245] Trial 53 finished with value: 0.41141110396526487 and parameters: {'lstm_units': 119, 'learning_rate': 0.008209359806344881}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141110396526487\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:29:07,704] Trial 54 finished with value: 0.41185840808628477 and parameters: {'lstm_units': 124, 'learning_rate': 0.002446321336308386}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41185840808628477\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:29:15,989] Trial 55 finished with value: 0.41138480861853527 and parameters: {'lstm_units': 109, 'learning_rate': 0.00506099978237682}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138480861853527\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:29:30,480] Trial 56 finished with value: 0.4120710853943886 and parameters: {'lstm_units': 110, 'learning_rate': 0.0050748932872437405}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120710853943886\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:29:38,427] Trial 57 finished with value: 0.41207242444593273 and parameters: {'lstm_units': 106, 'learning_rate': 0.007592098965158954}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41207242444593273\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:29:47,974] Trial 58 finished with value: 0.4113903066620451 and parameters: {'lstm_units': 84, 'learning_rate': 0.003973905308847621}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113903066620451\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:29:58,127] Trial 59 finished with value: 0.4113846584900163 and parameters: {'lstm_units': 83, 'learning_rate': 0.0041707399890530735}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113846584900163\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:30:09,694] Trial 60 finished with value: 0.4120908755371904 and parameters: {'lstm_units': 77, 'learning_rate': 0.005167730928313317}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120908755371904\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:30:21,406] Trial 61 finished with value: 0.4116482416061379 and parameters: {'lstm_units': 84, 'learning_rate': 0.0037938807696694227}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116482416061379\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:30:29,903] Trial 62 finished with value: 0.4114325425356945 and parameters: {'lstm_units': 92, 'learning_rate': 0.004279234502364862}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114325425356945\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:30:37,404] Trial 63 finished with value: 0.4113902747932551 and parameters: {'lstm_units': 78, 'learning_rate': 0.006639189155763519}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113902747932551\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:30:46,493] Trial 64 finished with value: 0.4116196510548812 and parameters: {'lstm_units': 80, 'learning_rate': 0.005920563107191518}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116196510548812\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:30:54,525] Trial 65 finished with value: 0.4122687088144352 and parameters: {'lstm_units': 73, 'learning_rate': 0.009739692895616842}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122687088144352\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:31:05,383] Trial 66 finished with value: 0.41146707345071676 and parameters: {'lstm_units': 107, 'learning_rate': 0.006639388396107329}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146707345071676\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:31:13,682] Trial 67 finished with value: 0.411925914997829 and parameters: {'lstm_units': 100, 'learning_rate': 0.003252979375617142}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411925914997829\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:31:23,284] Trial 68 finished with value: 0.4117566918910999 and parameters: {'lstm_units': 128, 'learning_rate': 0.00811262488222214}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117566918910999\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:31:35,878] Trial 69 finished with value: 0.4114002244852178 and parameters: {'lstm_units': 113, 'learning_rate': 0.0027621917868850807}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114002244852178\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:31:44,324] Trial 70 finished with value: 0.4116774845176867 and parameters: {'lstm_units': 122, 'learning_rate': 0.004796852668922435}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116774845176867\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:31:55,571] Trial 71 finished with value: 0.41142807686664534 and parameters: {'lstm_units': 84, 'learning_rate': 0.003908513230417546}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41142807686664534\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:32:05,319] Trial 72 finished with value: 0.4115827200816033 and parameters: {'lstm_units': 77, 'learning_rate': 0.0020697657149443965}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115827200816033\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:32:13,960] Trial 73 finished with value: 0.41147422473366063 and parameters: {'lstm_units': 67, 'learning_rate': 0.005442649628513644}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41147422473366063\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:32:25,404] Trial 74 finished with value: 0.41174798249203776 and parameters: {'lstm_units': 87, 'learning_rate': 0.006529578120270774}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41174798249203776\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:32:35,502] Trial 75 finished with value: 0.4119021091063029 and parameters: {'lstm_units': 70, 'learning_rate': 0.0041823652493402684}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119021091063029\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:32:46,534] Trial 76 finished with value: 0.41138630190694886 and parameters: {'lstm_units': 80, 'learning_rate': 0.003382697433771494}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138630190694886\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:32:59,780] Trial 77 finished with value: 0.41160416139649464 and parameters: {'lstm_units': 79, 'learning_rate': 0.0033060624914215755}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41160416139649464\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:07,768] Trial 78 finished with value: 0.41148148486063324 and parameters: {'lstm_units': 62, 'learning_rate': 0.0014817967427816158}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148148486063324\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:14,698] Trial 79 finished with value: 0.4129133354132439 and parameters: {'lstm_units': 74, 'learning_rate': 0.004556275503045166}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129133354132439\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:23,775] Trial 80 finished with value: 0.41283858407699325 and parameters: {'lstm_units': 116, 'learning_rate': 0.0024377837839184013}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41283858407699325\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:31,967] Trial 81 finished with value: 0.4114994224219659 and parameters: {'lstm_units': 90, 'learning_rate': 0.003581649730284084}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114994224219659\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:40,150] Trial 82 finished with value: 0.4116937386382486 and parameters: {'lstm_units': 82, 'learning_rate': 0.00298843217665079}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116937386382486\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:48,206] Trial 83 finished with value: 0.4119849353022002 and parameters: {'lstm_units': 70, 'learning_rate': 0.005598655629499351}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119849353022002\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:33:55,763] Trial 84 finished with value: 0.4113890168030593 and parameters: {'lstm_units': 86, 'learning_rate': 0.006284997637008299}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113890168030593\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:34:03,837] Trial 85 finished with value: 0.4129711133774615 and parameters: {'lstm_units': 95, 'learning_rate': 0.007182339916480914}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4129711133774615\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:34:10,791] Trial 86 finished with value: 0.4124994752302782 and parameters: {'lstm_units': 78, 'learning_rate': 0.008830599160531525}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124994752302782\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:34:23,113] Trial 87 finished with value: 0.4116864220424433 and parameters: {'lstm_units': 86, 'learning_rate': 0.006225242396667938}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116864220424433\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:34:30,543] Trial 88 finished with value: 0.4116192486032354 and parameters: {'lstm_units': 75, 'learning_rate': 0.004710177483845898}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116192486032354\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:34:43,275] Trial 89 finished with value: 0.41143371793716316 and parameters: {'lstm_units': 81, 'learning_rate': 0.001726110731848953}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41143371793716316\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:34:53,254] Trial 90 finished with value: 0.4150957314176731 and parameters: {'lstm_units': 66, 'learning_rate': 0.0001195266393684938}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4150957314176731\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:04,004] Trial 91 finished with value: 0.4116050469019014 and parameters: {'lstm_units': 85, 'learning_rate': 0.004315953258545505}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116050469019014\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:14,426] Trial 92 finished with value: 0.41351421666006 and parameters: {'lstm_units': 118, 'learning_rate': 0.005144616271427527}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41351421666006\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:22,375] Trial 93 finished with value: 0.4135078661564101 and parameters: {'lstm_units': 89, 'learning_rate': 0.002716561987264251}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4135078661564101\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:29,285] Trial 94 finished with value: 0.41138823534998886 and parameters: {'lstm_units': 82, 'learning_rate': 0.0038836849776390193}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138823534998886\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:35,903] Trial 95 finished with value: 0.4116903753066715 and parameters: {'lstm_units': 72, 'learning_rate': 0.003486255446322755}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116903753066715\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:45,404] Trial 96 finished with value: 0.41145427083191033 and parameters: {'lstm_units': 121, 'learning_rate': 0.0010934346193472472}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145427083191033\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:35:56,151] Trial 97 finished with value: 0.41140558236737745 and parameters: {'lstm_units': 79, 'learning_rate': 0.0022478178540497585}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140558236737745\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:03,782] Trial 98 finished with value: 0.4127709572459696 and parameters: {'lstm_units': 91, 'learning_rate': 0.005712895547990865}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4127709572459696\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:13,084] Trial 99 finished with value: 0.41186318201667904 and parameters: {'lstm_units': 94, 'learning_rate': 0.006961408129727475}. Best is trial 40 with value: 0.41137875798206497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41186318201667904\n",
      "Best Trial:\n",
      "  Value: 0.41137875798206497\n",
      "  Params: \n",
      "    lstm_units: 74\n",
      "    learning_rate: 0.0003820453037915766\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.2706513304193939\n"
     ]
    }
   ],
   "source": [
    "LSTM_testing_2 = LSTM_testing(normalizes_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "614c246a-5e71-4abb-9741-385e314ed208",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:20,775] A new study created in memory with name: no-name-29fb06cc-5017-4b61-9313-f7f669726434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:28,606] Trial 0 finished with value: 0.4115461525364006 and parameters: {'lstm_units': 59, 'learning_rate': 0.009949225552363784}. Best is trial 0 with value: 0.4115461525364006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115461525364006\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:37,859] Trial 1 finished with value: 0.411444401481972 and parameters: {'lstm_units': 128, 'learning_rate': 0.00022970399230329145}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411444401481972\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:46,839] Trial 2 finished with value: 0.4126815668715506 and parameters: {'lstm_units': 67, 'learning_rate': 0.00011749649945827147}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4126815668715506\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:36:54,168] Trial 3 finished with value: 0.41145748096514545 and parameters: {'lstm_units': 68, 'learning_rate': 0.0012253906546688253}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145748096514545\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:01,987] Trial 4 finished with value: 0.4142382900450726 and parameters: {'lstm_units': 65, 'learning_rate': 0.0001886790660541005}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4142382900450726\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:12,102] Trial 5 finished with value: 0.41329351329407227 and parameters: {'lstm_units': 47, 'learning_rate': 0.00015120596881250598}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41329351329407227\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:20,121] Trial 6 finished with value: 0.41154846668436734 and parameters: {'lstm_units': 46, 'learning_rate': 0.0005698841662093655}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154846668436734\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:29,094] Trial 7 finished with value: 0.4115779553883554 and parameters: {'lstm_units': 127, 'learning_rate': 0.00046752145091935354}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115779553883554\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:36,756] Trial 8 finished with value: 0.4119124715460561 and parameters: {'lstm_units': 56, 'learning_rate': 0.0006119037745034006}. Best is trial 1 with value: 0.411444401481972.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119124715460561\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:45,509] Trial 9 finished with value: 0.4113901457886317 and parameters: {'lstm_units': 51, 'learning_rate': 0.008836676752889487}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113901457886317\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:37:55,899] Trial 10 finished with value: 0.41166377275928423 and parameters: {'lstm_units': 96, 'learning_rate': 0.009267366260829614}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41166377275928423\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:05,636] Trial 11 finished with value: 0.41289764807495566 and parameters: {'lstm_units': 92, 'learning_rate': 0.0027707696319137424}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41289764807495566\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:13,016] Trial 12 finished with value: 0.4115545785261345 and parameters: {'lstm_units': 33, 'learning_rate': 0.0031195700807756235}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115545785261345\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:23,469] Trial 13 finished with value: 0.41293962145120355 and parameters: {'lstm_units': 123, 'learning_rate': 0.00028586608018702604}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41293962145120355\n",
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:31,570] Trial 14 finished with value: 0.4127418927634342 and parameters: {'lstm_units': 109, 'learning_rate': 0.0015712247810439571}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4127418927634342\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:39,577] Trial 15 finished with value: 0.4123827698281723 and parameters: {'lstm_units': 82, 'learning_rate': 0.004410637800841348}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4123827698281723\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:51,105] Trial 16 finished with value: 0.4114555195307941 and parameters: {'lstm_units': 113, 'learning_rate': 0.000298232452968962}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114555195307941\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:38:58,411] Trial 17 finished with value: 0.41160787776851876 and parameters: {'lstm_units': 79, 'learning_rate': 0.005593363888668751}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41160787776851876\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:39:09,009] Trial 18 finished with value: 0.41153811602005863 and parameters: {'lstm_units': 32, 'learning_rate': 0.0018690218108519524}. Best is trial 9 with value: 0.4113901457886317.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41153811602005863\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:39:18,200] Trial 19 finished with value: 0.41138382988020444 and parameters: {'lstm_units': 99, 'learning_rate': 0.000841350459495736}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138382988020444\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:39:27,645] Trial 20 finished with value: 0.4113903559466853 and parameters: {'lstm_units': 101, 'learning_rate': 0.0007860192314531837}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113903559466853\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:39:39,374] Trial 21 finished with value: 0.41154371462899897 and parameters: {'lstm_units': 103, 'learning_rate': 0.0009319176246345415}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154371462899897\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:39:49,011] Trial 22 finished with value: 0.41173995876479197 and parameters: {'lstm_units': 85, 'learning_rate': 0.0009155934504389766}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41173995876479197\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:39:57,178] Trial 23 finished with value: 0.4122394300190757 and parameters: {'lstm_units': 99, 'learning_rate': 0.00041692012148001955}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122394300190757\n",
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:40:09,854] Trial 24 finished with value: 0.41168454320699355 and parameters: {'lstm_units': 114, 'learning_rate': 0.0018189233304158833}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41168454320699355\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:40:19,178] Trial 25 finished with value: 0.41203928335382084 and parameters: {'lstm_units': 75, 'learning_rate': 0.0009841810726127088}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41203928335382084\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:40:28,353] Trial 26 finished with value: 0.41140624021125877 and parameters: {'lstm_units': 88, 'learning_rate': 0.0006956663790892229}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140624021125877\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:40:36,915] Trial 27 finished with value: 0.4119893638287396 and parameters: {'lstm_units': 105, 'learning_rate': 0.0012715213854163792}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119893638287396\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:40:44,968] Trial 28 finished with value: 0.41185985405288045 and parameters: {'lstm_units': 92, 'learning_rate': 0.002932529566320314}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41185985405288045\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:40:53,687] Trial 29 finished with value: 0.4119705790598943 and parameters: {'lstm_units': 118, 'learning_rate': 0.009657483742389984}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119705790598943\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:02,269] Trial 30 finished with value: 0.41139763778946903 and parameters: {'lstm_units': 75, 'learning_rate': 0.0003910552534733767}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139763778946903\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:09,391] Trial 31 finished with value: 0.41158703055286355 and parameters: {'lstm_units': 55, 'learning_rate': 0.0004872415636951328}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41158703055286355\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:17,163] Trial 32 finished with value: 0.41262146776302366 and parameters: {'lstm_units': 74, 'learning_rate': 0.00029026616517874646}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41262146776302366\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:27,372] Trial 33 finished with value: 0.4122440752576158 and parameters: {'lstm_units': 50, 'learning_rate': 0.0003590675181494163}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122440752576158\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:34,580] Trial 34 finished with value: 0.41172288976330795 and parameters: {'lstm_units': 42, 'learning_rate': 0.0007609245145382673}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41172288976330795\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:45,377] Trial 35 finished with value: 0.41301998899318854 and parameters: {'lstm_units': 59, 'learning_rate': 0.00010776287537700507}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41301998899318854\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:41:56,521] Trial 36 finished with value: 0.413439359015908 and parameters: {'lstm_units': 71, 'learning_rate': 0.00023135401293743543}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.413439359015908\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:42:05,475] Trial 37 finished with value: 0.4114203563446186 and parameters: {'lstm_units': 61, 'learning_rate': 0.0012464960683360705}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114203563446186\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:42:15,074] Trial 38 finished with value: 0.4130546839765982 and parameters: {'lstm_units': 98, 'learning_rate': 0.00019305694308841375}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4130546839765982\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:42:25,124] Trial 39 finished with value: 0.4122596152615043 and parameters: {'lstm_units': 40, 'learning_rate': 0.0008194035660012463}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4122596152615043\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:42:32,310] Trial 40 finished with value: 0.41185658145859894 and parameters: {'lstm_units': 64, 'learning_rate': 0.0005718875931323679}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41185658145859894\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:42:39,511] Trial 41 finished with value: 0.41218925809793566 and parameters: {'lstm_units': 87, 'learning_rate': 0.0007266866720250162}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41218925809793566\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:42:50,972] Trial 42 finished with value: 0.41141677246131375 and parameters: {'lstm_units': 94, 'learning_rate': 0.0006994344376400781}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41141677246131375\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:43:01,291] Trial 43 finished with value: 0.41149116981581646 and parameters: {'lstm_units': 88, 'learning_rate': 0.0004187690412209827}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149116981581646\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:43:12,708] Trial 44 finished with value: 0.41189912555725894 and parameters: {'lstm_units': 103, 'learning_rate': 0.0005505743810460111}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41189912555725894\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:43:20,696] Trial 45 finished with value: 0.4117043480628312 and parameters: {'lstm_units': 78, 'learning_rate': 0.0012092416494498225}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117043480628312\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:43:32,067] Trial 46 finished with value: 0.41269258602657966 and parameters: {'lstm_units': 90, 'learning_rate': 0.007272301204397114}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41269258602657966\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:43:43,774] Trial 47 finished with value: 0.4114166045686716 and parameters: {'lstm_units': 83, 'learning_rate': 0.002126243161058105}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114166045686716\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:43:54,123] Trial 48 finished with value: 0.41386660347539916 and parameters: {'lstm_units': 108, 'learning_rate': 0.00014067217340576113}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41386660347539916\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:02,840] Trial 49 finished with value: 0.4135603517885787 and parameters: {'lstm_units': 69, 'learning_rate': 0.00036444355728089644}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4135603517885787\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:12,378] Trial 50 finished with value: 0.41145194519183714 and parameters: {'lstm_units': 100, 'learning_rate': 0.0014368348876020163}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41145194519183714\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:19,401] Trial 51 finished with value: 0.41395423488610517 and parameters: {'lstm_units': 85, 'learning_rate': 0.003984264546011304}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41395423488610517\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:28,875] Trial 52 finished with value: 0.41139528176726226 and parameters: {'lstm_units': 82, 'learning_rate': 0.0006305222266726305}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139528176726226\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:36,199] Trial 53 finished with value: 0.41242597504031786 and parameters: {'lstm_units': 95, 'learning_rate': 0.0006713101194509162}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41242597504031786\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:43,119] Trial 54 finished with value: 0.41146875972123836 and parameters: {'lstm_units': 81, 'learning_rate': 0.0004955003835884165}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41146875972123836\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:44:53,633] Trial 55 finished with value: 0.41269702604233455 and parameters: {'lstm_units': 76, 'learning_rate': 0.0011183143629389337}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41269702604233455\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:45:05,461] Trial 56 finished with value: 0.41138829824517886 and parameters: {'lstm_units': 108, 'learning_rate': 0.0008558840240372957}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138829824517886\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:45:16,758] Trial 57 finished with value: 0.41148950815230145 and parameters: {'lstm_units': 121, 'learning_rate': 0.0008759032758952208}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41148950815230145\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:45:26,542] Trial 58 finished with value: 0.411725229896492 and parameters: {'lstm_units': 110, 'learning_rate': 0.0023109590968123503}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411725229896492\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:45:35,284] Trial 59 finished with value: 0.41140632335992217 and parameters: {'lstm_units': 117, 'learning_rate': 0.001597116442310942}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41140632335992217\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:45:44,228] Trial 60 finished with value: 0.4114464551384194 and parameters: {'lstm_units': 127, 'learning_rate': 0.0010082086091347817}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114464551384194\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:45:58,382] Trial 61 finished with value: 0.4114241870452384 and parameters: {'lstm_units': 104, 'learning_rate': 0.0006636876905935964}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114241870452384\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:46:09,343] Trial 62 finished with value: 0.41149737065892344 and parameters: {'lstm_units': 91, 'learning_rate': 0.0005830940586119327}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41149737065892344\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:46:19,025] Trial 63 finished with value: 0.41155751208922736 and parameters: {'lstm_units': 100, 'learning_rate': 0.00041329154479005626}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41155751208922736\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:46:36,013] Trial 64 finished with value: 0.41153272225086346 and parameters: {'lstm_units': 107, 'learning_rate': 0.0010562469707205773}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41153272225086346\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:46:44,328] Trial 65 finished with value: 0.4124041522644248 and parameters: {'lstm_units': 113, 'learning_rate': 0.0008775378795363347}. Best is trial 19 with value: 0.41138382988020444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4124041522644248\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:46:50,703] Trial 66 finished with value: 0.4113133259197668 and parameters: {'lstm_units': 37, 'learning_rate': 0.00035154796834882567}. Best is trial 66 with value: 0.4113133259197668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113133259197668\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:46:59,547] Trial 67 finished with value: 0.4123890149695404 and parameters: {'lstm_units': 36, 'learning_rate': 0.00025061323302795995}. Best is trial 66 with value: 0.4113133259197668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4123890149695404\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:05,863] Trial 68 finished with value: 0.4118327827095148 and parameters: {'lstm_units': 48, 'learning_rate': 0.00031112793257981444}. Best is trial 66 with value: 0.4113133259197668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4118327827095148\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:12,591] Trial 69 finished with value: 0.41512412919932196 and parameters: {'lstm_units': 53, 'learning_rate': 0.00036874898983178247}. Best is trial 66 with value: 0.4113133259197668.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41512412919932196\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:18,707] Trial 70 finished with value: 0.410804036850653 and parameters: {'lstm_units': 42, 'learning_rate': 0.00019709314567273165}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.410804036850653\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:28,026] Trial 71 finished with value: 0.4132551726334231 and parameters: {'lstm_units': 43, 'learning_rate': 0.00019518707589676144}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4132551726334231\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:37,901] Trial 72 finished with value: 0.4142073495464456 and parameters: {'lstm_units': 39, 'learning_rate': 0.00015204527100738728}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4142073495464456\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:46,109] Trial 73 finished with value: 0.41206991950160415 and parameters: {'lstm_units': 35, 'learning_rate': 0.00026412064489161717}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41206991950160415\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:47:53,971] Trial 74 finished with value: 0.41172469512760146 and parameters: {'lstm_units': 51, 'learning_rate': 0.0004979301523790556}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41172469512760146\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:00,268] Trial 75 finished with value: 0.41237508162058834 and parameters: {'lstm_units': 46, 'learning_rate': 0.00032349192105820407}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41237508162058834\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:06,545] Trial 76 finished with value: 0.41154293865537694 and parameters: {'lstm_units': 38, 'learning_rate': 0.0004356710317726758}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41154293865537694\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:14,197] Trial 77 finished with value: 0.41474419131448603 and parameters: {'lstm_units': 44, 'learning_rate': 0.00021382050972694542}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41474419131448603\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:24,124] Trial 78 finished with value: 0.41138457177641696 and parameters: {'lstm_units': 32, 'learning_rate': 0.0007755674485296492}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41138457177641696\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:31,836] Trial 79 finished with value: 0.4114142794285521 and parameters: {'lstm_units': 33, 'learning_rate': 0.0007927019452531079}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114142794285521\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:40,802] Trial 80 finished with value: 0.4115693561183165 and parameters: {'lstm_units': 35, 'learning_rate': 0.0014340363748128577}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115693561183165\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:47,875] Trial 81 finished with value: 0.4113671996931946 and parameters: {'lstm_units': 57, 'learning_rate': 0.0006318448602674401}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113671996931946\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:48:55,784] Trial 82 finished with value: 0.4116357553545663 and parameters: {'lstm_units': 41, 'learning_rate': 0.0006261027522037307}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4116357553545663\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:49:06,278] Trial 83 finished with value: 0.4120305795777439 and parameters: {'lstm_units': 58, 'learning_rate': 0.0005335611077160564}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4120305795777439\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:49:13,334] Trial 84 finished with value: 0.4114050972279775 and parameters: {'lstm_units': 38, 'learning_rate': 0.0008420583899009299}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114050972279775\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:49:23,762] Trial 85 finished with value: 0.41139915550946055 and parameters: {'lstm_units': 63, 'learning_rate': 0.0009257729386681806}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41139915550946055\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:49:32,989] Trial 86 finished with value: 0.4115422062999304 and parameters: {'lstm_units': 32, 'learning_rate': 0.000754670400245512}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115422062999304\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:49:40,147] Trial 87 finished with value: 0.4119452759156584 and parameters: {'lstm_units': 47, 'learning_rate': 0.00014636331226688853}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4119452759156584\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:49:50,304] Trial 88 finished with value: 0.4115820139435351 and parameters: {'lstm_units': 55, 'learning_rate': 0.0010044749935228334}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4115820139435351\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:50:01,302] Trial 89 finished with value: 0.4117511643520211 and parameters: {'lstm_units': 97, 'learning_rate': 0.0006170761298606319}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117511643520211\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:50:10,063] Trial 90 finished with value: 0.41214364249137553 and parameters: {'lstm_units': 45, 'learning_rate': 0.008019245821520712}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41214364249137553\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:50:17,642] Trial 91 finished with value: 0.412675602095496 and parameters: {'lstm_units': 71, 'learning_rate': 0.00016902112723912106}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.412675602095496\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:50:32,032] Trial 92 finished with value: 0.411535642785121 and parameters: {'lstm_units': 102, 'learning_rate': 0.0004413962962673196}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.411535642785121\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:50:41,527] Trial 93 finished with value: 0.4114464369455891 and parameters: {'lstm_units': 36, 'learning_rate': 0.0005276465251151098}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114464369455891\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:50:53,342] Trial 94 finished with value: 0.4117566683231163 and parameters: {'lstm_units': 52, 'learning_rate': 0.0007136236960346054}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117566683231163\n",
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:51:00,898] Trial 95 finished with value: 0.4117453946221693 and parameters: {'lstm_units': 111, 'learning_rate': 0.0003787198956899531}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4117453946221693\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:51:10,859] Trial 96 finished with value: 0.4113846297874661 and parameters: {'lstm_units': 68, 'learning_rate': 0.0011226311458895466}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4113846297874661\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:51:18,917] Trial 97 finished with value: 0.4146627155849635 and parameters: {'lstm_units': 66, 'learning_rate': 0.003984932908497833}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4146627155849635\n",
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:51:28,214] Trial 98 finished with value: 0.41156651215674306 and parameters: {'lstm_units': 49, 'learning_rate': 0.005212208416404862}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41156651215674306\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 22:51:38,194] Trial 99 finished with value: 0.4125093530867139 and parameters: {'lstm_units': 60, 'learning_rate': 0.0033512778792648386}. Best is trial 70 with value: 0.410804036850653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4125093530867139\n",
      "Best Trial:\n",
      "  Value: 0.410804036850653\n",
      "  Params: \n",
      "    lstm_units: 42\n",
      "    learning_rate: 0.00019709314567273165\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.26548825562372014\n"
     ]
    }
   ],
   "source": [
    "LSTM_testing_6 = LSTM_testing(normalizes_df_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6183c4fa-c5f2-4a09-af06-6622f8bc901b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:14:43,244] A new study created in memory with name: no-name-fa809613-f595-4611-9db6-db298c2b69d5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:14:54,856] Trial 0 finished with value: 0.5906103686820068 and parameters: {'batch_size': 64, 'epochs': 115, 'units': 35, 'learning_rate': 0.0002439148370287293}. Best is trial 0 with value: 0.5906103686820068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:15:07,677] Trial 1 finished with value: 0.5894392448349818 and parameters: {'batch_size': 16, 'epochs': 133, 'units': 114, 'learning_rate': 0.0032890965486287505}. Best is trial 1 with value: 0.5894392448349818.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:15:17,094] Trial 2 finished with value: 0.5892183570346116 and parameters: {'batch_size': 64, 'epochs': 182, 'units': 50, 'learning_rate': 0.002277745536272152}. Best is trial 2 with value: 0.5892183570346116.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:15:25,005] Trial 3 finished with value: 0.5890564443779546 and parameters: {'batch_size': 32, 'epochs': 107, 'units': 78, 'learning_rate': 0.0005158827681647321}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:15:33,211] Trial 4 finished with value: 0.5894694483469872 and parameters: {'batch_size': 32, 'epochs': 68, 'units': 99, 'learning_rate': 0.0006528684274894804}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:15:48,403] Trial 5 finished with value: 0.5892375362405781 and parameters: {'batch_size': 16, 'epochs': 168, 'units': 52, 'learning_rate': 0.00042851418726639094}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:15:59,534] Trial 6 finished with value: 0.5890626653378802 and parameters: {'batch_size': 16, 'epochs': 83, 'units': 107, 'learning_rate': 0.0002964402167041968}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:16:06,348] Trial 7 finished with value: 0.5891807547298726 and parameters: {'batch_size': 64, 'epochs': 198, 'units': 35, 'learning_rate': 0.0018981278457267214}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:16:13,148] Trial 8 finished with value: 0.5890638256526636 and parameters: {'batch_size': 64, 'epochs': 189, 'units': 40, 'learning_rate': 0.006410798016058359}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:16:22,115] Trial 9 finished with value: 0.5890891943932255 and parameters: {'batch_size': 32, 'epochs': 199, 'units': 87, 'learning_rate': 0.003653276454469578}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:16:30,112] Trial 10 finished with value: 0.5914641501149663 and parameters: {'batch_size': 32, 'epochs': 108, 'units': 68, 'learning_rate': 0.00013925404585925582}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:16:42,564] Trial 11 finished with value: 0.5898699407833295 and parameters: {'batch_size': 16, 'epochs': 73, 'units': 122, 'learning_rate': 0.0008738308816110211}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:16:50,039] Trial 12 finished with value: 0.5905786997278624 and parameters: {'batch_size': 32, 'epochs': 93, 'units': 76, 'learning_rate': 0.00010029225134135537}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:17:11,106] Trial 13 finished with value: 0.5890580152178095 and parameters: {'batch_size': 16, 'epochs': 140, 'units': 102, 'learning_rate': 0.00030581970888594884}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:17:24,197] Trial 14 finished with value: 0.5893243235328217 and parameters: {'batch_size': 32, 'epochs': 146, 'units': 91, 'learning_rate': 0.0005087095072636039}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:17:38,733] Trial 15 finished with value: 0.5890569877451234 and parameters: {'batch_size': 16, 'epochs': 154, 'units': 66, 'learning_rate': 0.0011402457675941159}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:17:52,893] Trial 16 finished with value: 0.5890580490119955 and parameters: {'batch_size': 16, 'epochs': 160, 'units': 66, 'learning_rate': 0.001247715590763519}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:18:02,135] Trial 17 finished with value: 0.5892056960399669 and parameters: {'batch_size': 32, 'epochs': 104, 'units': 59, 'learning_rate': 0.001262495205168726}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:18:24,377] Trial 18 finished with value: 0.5890969139497008 and parameters: {'batch_size': 16, 'epochs': 54, 'units': 77, 'learning_rate': 0.0007710461237858806}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:18:33,200] Trial 19 finished with value: 0.5892085851004407 and parameters: {'batch_size': 32, 'epochs': 126, 'units': 87, 'learning_rate': 0.009780013879165748}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:18:41,843] Trial 20 finished with value: 0.5891372519542581 and parameters: {'batch_size': 32, 'epochs': 155, 'units': 71, 'learning_rate': 0.000189172907153386}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:18:59,986] Trial 21 finished with value: 0.5890671210166207 and parameters: {'batch_size': 16, 'epochs': 140, 'units': 97, 'learning_rate': 0.0004527260534536738}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:19:16,881] Trial 22 finished with value: 0.5890632009992943 and parameters: {'batch_size': 16, 'epochs': 120, 'units': 83, 'learning_rate': 0.00031718713419959677}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:19:34,249] Trial 23 finished with value: 0.5890598929340375 and parameters: {'batch_size': 16, 'epochs': 168, 'units': 105, 'learning_rate': 0.0015096661304317106}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:19:45,611] Trial 24 finished with value: 0.5891831090805497 and parameters: {'batch_size': 16, 'epochs': 146, 'units': 126, 'learning_rate': 0.0006410794854502295}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:20:01,086] Trial 25 finished with value: 0.5895623154738244 and parameters: {'batch_size': 16, 'epochs': 132, 'units': 56, 'learning_rate': 0.0003338719911290045}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:20:13,872] Trial 26 finished with value: 0.5891537607457416 and parameters: {'batch_size': 16, 'epochs': 103, 'units': 62, 'learning_rate': 0.0001899443047522037}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:20:27,940] Trial 27 finished with value: 0.5893355187393478 and parameters: {'batch_size': 16, 'epochs': 156, 'units': 75, 'learning_rate': 0.0010024978727855177}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:20:36,982] Trial 28 finished with value: 0.5890785190768358 and parameters: {'batch_size': 64, 'epochs': 177, 'units': 94, 'learning_rate': 0.0005953115877178664}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:20:47,214] Trial 29 finished with value: 0.5890805658904243 and parameters: {'batch_size': 32, 'epochs': 114, 'units': 82, 'learning_rate': 0.00023898179324662925}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:20:56,015] Trial 30 finished with value: 0.5898698255725483 and parameters: {'batch_size': 64, 'epochs': 96, 'units': 44, 'learning_rate': 0.00041516524418371155}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:21:08,361] Trial 31 finished with value: 0.5891908608537744 and parameters: {'batch_size': 16, 'epochs': 162, 'units': 66, 'learning_rate': 0.0012052072041733239}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:21:18,944] Trial 32 finished with value: 0.5891584802872581 and parameters: {'batch_size': 16, 'epochs': 139, 'units': 64, 'learning_rate': 0.002628447376170768}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:21:32,343] Trial 33 finished with value: 0.5893342082836879 and parameters: {'batch_size': 16, 'epochs': 151, 'units': 70, 'learning_rate': 0.0009907632587967492}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:21:55,336] Trial 34 finished with value: 0.5890832537887545 and parameters: {'batch_size': 16, 'epochs': 129, 'units': 112, 'learning_rate': 0.0017101812521014784}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:22:05,073] Trial 35 finished with value: 0.5899182075422326 and parameters: {'batch_size': 16, 'epochs': 174, 'units': 54, 'learning_rate': 0.0007222451840390527}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:22:15,481] Trial 36 finished with value: 0.589068011841178 and parameters: {'batch_size': 16, 'epochs': 120, 'units': 46, 'learning_rate': 0.004144739480275159}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:22:24,842] Trial 37 finished with value: 0.5891567585425468 and parameters: {'batch_size': 64, 'epochs': 160, 'units': 102, 'learning_rate': 0.0023908261286989985}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:22:38,882] Trial 38 finished with value: 0.5892408858501165 and parameters: {'batch_size': 16, 'epochs': 138, 'units': 80, 'learning_rate': 0.001248584406230318}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:22:48,821] Trial 39 finished with value: 0.5904211380740249 and parameters: {'batch_size': 32, 'epochs': 188, 'units': 114, 'learning_rate': 0.0005062514930399974}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:23:02,567] Trial 40 finished with value: 0.5892091969008907 and parameters: {'batch_size': 16, 'epochs': 164, 'units': 60, 'learning_rate': 0.0003715970377004184}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:23:14,735] Trial 41 finished with value: 0.5890786731041251 and parameters: {'batch_size': 16, 'epochs': 181, 'units': 105, 'learning_rate': 0.0017813020394858473}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:23:31,509] Trial 42 finished with value: 0.5891296761355804 and parameters: {'batch_size': 16, 'epochs': 172, 'units': 120, 'learning_rate': 0.0015537941148686307}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:23:46,165] Trial 43 finished with value: 0.5892458000265373 and parameters: {'batch_size': 16, 'epochs': 166, 'units': 108, 'learning_rate': 0.0014372308730430166}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:24:03,741] Trial 44 finished with value: 0.5890565189839848 and parameters: {'batch_size': 16, 'epochs': 148, 'units': 87, 'learning_rate': 0.003116986315852986}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:24:18,700] Trial 45 finished with value: 0.5890631469641205 and parameters: {'batch_size': 32, 'epochs': 147, 'units': 87, 'learning_rate': 0.005136152733871361}. Best is trial 3 with value: 0.5890564443779546.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:24:25,891] Trial 46 finished with value: 0.5890562893479404 and parameters: {'batch_size': 64, 'epochs': 114, 'units': 73, 'learning_rate': 0.0029616154068186533}. Best is trial 46 with value: 0.5890562893479404.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:24:32,633] Trial 47 finished with value: 0.5890556587729632 and parameters: {'batch_size': 64, 'epochs': 112, 'units': 92, 'learning_rate': 0.002783044891126592}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:24:40,926] Trial 48 finished with value: 0.5893497212711213 and parameters: {'batch_size': 64, 'epochs': 86, 'units': 92, 'learning_rate': 0.002999368780596456}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:24:48,619] Trial 49 finished with value: 0.5890573145116285 and parameters: {'batch_size': 64, 'epochs': 113, 'units': 73, 'learning_rate': 0.006946689035473554}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:00,095] Trial 50 finished with value: 0.5891767599857308 and parameters: {'batch_size': 64, 'epochs': 98, 'units': 78, 'learning_rate': 0.0032302333885043414}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:08,661] Trial 51 finished with value: 0.589124057753294 and parameters: {'batch_size': 64, 'epochs': 113, 'units': 73, 'learning_rate': 0.007707091571922806}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:17,168] Trial 52 finished with value: 0.5904382022023499 and parameters: {'batch_size': 64, 'epochs': 108, 'units': 86, 'learning_rate': 0.0047881422838309705}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:25,215] Trial 53 finished with value: 0.5902134191413294 and parameters: {'batch_size': 64, 'epochs': 122, 'units': 71, 'learning_rate': 0.006944792487019289}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:36,399] Trial 54 finished with value: 0.5890674985081039 and parameters: {'batch_size': 64, 'epochs': 84, 'units': 84, 'learning_rate': 0.002078423484800629}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:46,368] Trial 55 finished with value: 0.5897421629580397 and parameters: {'batch_size': 64, 'epochs': 76, 'units': 95, 'learning_rate': 0.0038894476693949616}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:25:54,685] Trial 56 finished with value: 0.589775078406734 and parameters: {'batch_size': 64, 'epochs': 91, 'units': 91, 'learning_rate': 0.005537880278206053}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:26:01,614] Trial 57 finished with value: 0.5900403697074075 and parameters: {'batch_size': 64, 'epochs': 111, 'units': 79, 'learning_rate': 0.009851641674542246}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:26:08,363] Trial 58 finished with value: 0.5890807492923269 and parameters: {'batch_size': 64, 'epochs': 105, 'units': 73, 'learning_rate': 0.002945487388515318}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:26:22,437] Trial 59 finished with value: 0.5891016291003274 and parameters: {'batch_size': 32, 'epochs': 118, 'units': 90, 'learning_rate': 0.008201676215680348}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:26:32,110] Trial 60 finished with value: 0.5890644854752695 and parameters: {'batch_size': 64, 'epochs': 126, 'units': 66, 'learning_rate': 0.004468653825654983}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:26:41,139] Trial 61 finished with value: 0.5891369794008323 and parameters: {'batch_size': 32, 'epochs': 135, 'units': 97, 'learning_rate': 0.00027010847267286794}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:26:52,308] Trial 62 finished with value: 0.5890583923352056 and parameters: {'batch_size': 64, 'epochs': 143, 'units': 75, 'learning_rate': 0.005885800748146524}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:27:02,398] Trial 63 finished with value: 0.5897234093963352 and parameters: {'batch_size': 64, 'epochs': 100, 'units': 100, 'learning_rate': 0.0021206245969452708}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:27:12,659] Trial 64 finished with value: 0.5890713260773692 and parameters: {'batch_size': 32, 'epochs': 131, 'units': 69, 'learning_rate': 0.0024937069226996494}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:27:24,313] Trial 65 finished with value: 0.5910699385931096 and parameters: {'batch_size': 64, 'epochs': 151, 'units': 82, 'learning_rate': 0.00018236611998994322}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:27:34,221] Trial 66 finished with value: 0.5890589996314893 and parameters: {'batch_size': 16, 'epochs': 108, 'units': 62, 'learning_rate': 0.003460446578596402}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:27:46,026] Trial 67 finished with value: 0.5890960186101613 and parameters: {'batch_size': 32, 'epochs': 124, 'units': 58, 'learning_rate': 0.0008919144989802418}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:27:56,526] Trial 68 finished with value: 0.589395085884499 and parameters: {'batch_size': 16, 'epochs': 117, 'units': 89, 'learning_rate': 0.0005340659471805916}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:28:04,975] Trial 69 finished with value: 0.5894361493806699 and parameters: {'batch_size': 64, 'epochs': 135, 'units': 85, 'learning_rate': 0.00025550145947913756}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:28:16,223] Trial 70 finished with value: 0.5892017784672572 and parameters: {'batch_size': 16, 'epochs': 90, 'units': 101, 'learning_rate': 0.002724196009544491}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:28:26,218] Trial 71 finished with value: 0.5891394792333071 and parameters: {'batch_size': 16, 'epochs': 157, 'units': 67, 'learning_rate': 0.0010994801888673125}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:28:41,211] Trial 72 finished with value: 0.589056782563539 and parameters: {'batch_size': 16, 'epochs': 150, 'units': 77, 'learning_rate': 0.0006715515629268348}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:28:54,270] Trial 73 finished with value: 0.5891295588993919 and parameters: {'batch_size': 16, 'epochs': 147, 'units': 77, 'learning_rate': 0.0007894117400028174}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:29:03,520] Trial 74 finished with value: 0.5890598602508559 and parameters: {'batch_size': 16, 'epochs': 126, 'units': 81, 'learning_rate': 0.0006470437401312949}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:29:14,321] Trial 75 finished with value: 0.5890562158038254 and parameters: {'batch_size': 16, 'epochs': 151, 'units': 74, 'learning_rate': 0.000388129475286798}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:29:30,417] Trial 76 finished with value: 0.5891065894688787 and parameters: {'batch_size': 16, 'epochs': 153, 'units': 73, 'learning_rate': 0.00043143704975690406}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:29:40,945] Trial 77 finished with value: 0.589076430721791 and parameters: {'batch_size': 16, 'epochs': 112, 'units': 75, 'learning_rate': 0.0005677350576487165}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:29:49,834] Trial 78 finished with value: 0.5890656940855213 and parameters: {'batch_size': 32, 'epochs': 103, 'units': 71, 'learning_rate': 0.00040069650673802207}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:30:08,857] Trial 79 finished with value: 0.5891368246188 and parameters: {'batch_size': 16, 'epochs': 141, 'units': 64, 'learning_rate': 0.0006910938320530883}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:30:15,452] Trial 80 finished with value: 0.5890899815085339 and parameters: {'batch_size': 64, 'epochs': 129, 'units': 79, 'learning_rate': 0.00035521329430215996}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:30:27,724] Trial 81 finished with value: 0.5891951597987359 and parameters: {'batch_size': 16, 'epochs': 149, 'units': 69, 'learning_rate': 0.0004957227986207808}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:30:40,492] Trial 82 finished with value: 0.5890830487137714 and parameters: {'batch_size': 16, 'epochs': 158, 'units': 83, 'learning_rate': 0.0003068645197141928}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:30:50,137] Trial 83 finished with value: 0.589287848079678 and parameters: {'batch_size': 16, 'epochs': 144, 'units': 93, 'learning_rate': 0.00048009566334041026}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:31:03,254] Trial 84 finished with value: 0.5891187661379952 and parameters: {'batch_size': 16, 'epochs': 170, 'units': 96, 'learning_rate': 0.00022140335306667259}. Best is trial 47 with value: 0.5890556587729632.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:31:13,941] Trial 85 finished with value: 0.5890553231316734 and parameters: {'batch_size': 16, 'epochs': 154, 'units': 88, 'learning_rate': 0.0007754669558086787}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:31:24,852] Trial 86 finished with value: 0.5893116366659524 and parameters: {'batch_size': 16, 'epochs': 162, 'units': 77, 'learning_rate': 0.0008319778127603781}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:31:32,790] Trial 87 finished with value: 0.5890569134646522 and parameters: {'batch_size': 64, 'epochs': 154, 'units': 88, 'learning_rate': 0.0009476316433516193}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:31:43,113] Trial 88 finished with value: 0.5899875139583404 and parameters: {'batch_size': 16, 'epochs': 154, 'units': 88, 'learning_rate': 0.0009988211158515384}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:31:50,200] Trial 89 finished with value: 0.5892351629278394 and parameters: {'batch_size': 32, 'epochs': 167, 'units': 87, 'learning_rate': 0.00137699867902082}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:32:07,823] Trial 90 finished with value: 0.5890584738160762 and parameters: {'batch_size': 16, 'epochs': 159, 'units': 84, 'learning_rate': 0.0005831944336816993}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:32:15,281] Trial 91 finished with value: 0.5890554272802878 and parameters: {'batch_size': 64, 'epochs': 116, 'units': 81, 'learning_rate': 0.0009339212363816929}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:32:24,344] Trial 92 finished with value: 0.5892602620511398 and parameters: {'batch_size': 64, 'epochs': 150, 'units': 81, 'learning_rate': 0.0007367943942707275}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:32:32,448] Trial 93 finished with value: 0.5890735854279908 and parameters: {'batch_size': 64, 'epochs': 137, 'units': 91, 'learning_rate': 0.000902888809584985}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:32:42,567] Trial 94 finished with value: 0.5891231601860231 and parameters: {'batch_size': 64, 'epochs': 108, 'units': 85, 'learning_rate': 0.0011044270629672268}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:32:49,908] Trial 95 finished with value: 0.5890555866951936 and parameters: {'batch_size': 64, 'epochs': 55, 'units': 80, 'learning_rate': 0.0006358904824917967}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:33:00,236] Trial 96 finished with value: 0.589240571389744 and parameters: {'batch_size': 64, 'epochs': 143, 'units': 81, 'learning_rate': 0.0006136542947313922}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:33:10,039] Trial 97 finished with value: 0.5890618416482561 and parameters: {'batch_size': 64, 'epochs': 61, 'units': 89, 'learning_rate': 0.0006727342241640456}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:33:17,703] Trial 98 finished with value: 0.58911650784009 and parameters: {'batch_size': 64, 'epochs': 67, 'units': 79, 'learning_rate': 0.0009577015722945964}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:33:27,870] Trial 99 finished with value: 0.5895437552636739 and parameters: {'batch_size': 64, 'epochs': 121, 'units': 98, 'learning_rate': 0.0007744191950322254}. Best is trial 85 with value: 0.5890553231316734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "  Value: 0.5890553231316734\n",
      "  Params: \n",
      "    batch_size: 16\n",
      "    epochs: 154\n",
      "    units: 88\n",
      "    learning_rate: 0.0007754669558086787\n",
      "Epoch 1/154\n",
      "60/60 [==============================] - 4s 18ms/step - loss: 0.5867 - val_loss: 0.6254\n",
      "Epoch 2/154\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5742 - val_loss: 0.5891\n",
      "Epoch 3/154\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5748 - val_loss: 0.5998\n",
      "Epoch 4/154\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5621 - val_loss: 0.6158\n",
      "Epoch 5/154\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5675 - val_loss: 0.5891\n",
      "Epoch 6/154\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5548 - val_loss: 0.6238\n",
      "Epoch 7/154\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5626 - val_loss: 0.5958\n",
      "Epoch 8/154\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5587 - val_loss: 0.6002\n",
      "Epoch 9/154\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5557 - val_loss: 0.5906\n",
      "Epoch 10/154\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5563 - val_loss: 0.6058\n",
      "Epoch 11/154\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.5538 - val_loss: 0.5915\n",
      "Epoch 12/154\n",
      "60/60 [==============================] - 1s 8ms/step - loss: 0.5533 - val_loss: 0.5965\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.589056087292537\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.4964863443414267\n"
     ]
    }
   ],
   "source": [
    "LSTM_testing_7 = LSTM_testing(normalizes_df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd908edf-0cfe-4b83-945e-8e70ac7f64be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:35:30,998] A new study created in memory with name: no-name-f63cba6c-d03c-460c-b2c7-dc7fee218e3a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:35:41,431] Trial 0 finished with value: 0.4166846279176715 and parameters: {'batch_size': 32, 'epochs': 153, 'units': 122, 'learning_rate': 0.0020821037391307415}. Best is trial 0 with value: 0.4166846279176715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:35:49,183] Trial 1 finished with value: 0.4166845305879924 and parameters: {'batch_size': 32, 'epochs': 72, 'units': 80, 'learning_rate': 0.00037325532053907626}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:36:05,342] Trial 2 finished with value: 0.4170427464611258 and parameters: {'batch_size': 16, 'epochs': 51, 'units': 87, 'learning_rate': 0.00010605528200799585}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:36:19,624] Trial 3 finished with value: 0.4170186933501543 and parameters: {'batch_size': 16, 'epochs': 61, 'units': 74, 'learning_rate': 0.00025512379351450774}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:36:33,434] Trial 4 finished with value: 0.4166848767425724 and parameters: {'batch_size': 16, 'epochs': 122, 'units': 42, 'learning_rate': 0.004521055535450626}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:36:42,403] Trial 5 finished with value: 0.41702442562480685 and parameters: {'batch_size': 16, 'epochs': 195, 'units': 37, 'learning_rate': 0.0019139344569282426}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:36:50,082] Trial 6 finished with value: 0.416775582862072 and parameters: {'batch_size': 32, 'epochs': 65, 'units': 105, 'learning_rate': 0.008757150226813545}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:37:07,741] Trial 7 finished with value: 0.41674029437925286 and parameters: {'batch_size': 16, 'epochs': 147, 'units': 93, 'learning_rate': 0.0004160076943623621}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:37:14,227] Trial 8 finished with value: 0.41696978604336815 and parameters: {'batch_size': 64, 'epochs': 109, 'units': 62, 'learning_rate': 0.00010078091405383687}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:37:22,318] Trial 9 finished with value: 0.4169888217475407 and parameters: {'batch_size': 32, 'epochs': 144, 'units': 65, 'learning_rate': 0.00021417157854193694}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:37:30,242] Trial 10 finished with value: 0.41678320015916637 and parameters: {'batch_size': 64, 'epochs': 90, 'units': 120, 'learning_rate': 0.0006946477814825722}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:37:40,164] Trial 11 finished with value: 0.41671247574445114 and parameters: {'batch_size': 32, 'epochs': 184, 'units': 116, 'learning_rate': 0.0015550839004878417}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:37:49,418] Trial 12 finished with value: 0.4169367458601166 and parameters: {'batch_size': 32, 'epochs': 163, 'units': 100, 'learning_rate': 0.0027169755987378427}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:00,102] Trial 13 finished with value: 0.4167563215787273 and parameters: {'batch_size': 32, 'epochs': 96, 'units': 75, 'learning_rate': 0.000717736313773964}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:13,347] Trial 14 finished with value: 0.4166873784899015 and parameters: {'batch_size': 32, 'epochs': 162, 'units': 128, 'learning_rate': 0.0010679291258780144}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:22,612] Trial 15 finished with value: 0.41691530428233076 and parameters: {'batch_size': 32, 'epochs': 131, 'units': 58, 'learning_rate': 0.004067936648512436}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:31,887] Trial 16 finished with value: 0.41688309537087576 and parameters: {'batch_size': 32, 'epochs': 82, 'units': 85, 'learning_rate': 0.0003991988391427443}. Best is trial 1 with value: 0.4166845305879924.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:41,077] Trial 17 finished with value: 0.41668443861356935 and parameters: {'batch_size': 64, 'epochs': 114, 'units': 106, 'learning_rate': 0.0011509581463392332}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:48,242] Trial 18 finished with value: 0.41668491191784096 and parameters: {'batch_size': 64, 'epochs': 76, 'units': 106, 'learning_rate': 0.00044405489715446}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:38:55,642] Trial 19 finished with value: 0.4191594832684055 and parameters: {'batch_size': 64, 'epochs': 110, 'units': 50, 'learning_rate': 0.0009002886485019256}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:39:02,495] Trial 20 finished with value: 0.41675278985495223 and parameters: {'batch_size': 64, 'epochs': 101, 'units': 96, 'learning_rate': 0.00020030558431686054}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:39:09,917] Trial 21 finished with value: 0.41683909361590893 and parameters: {'batch_size': 64, 'epochs': 128, 'units': 114, 'learning_rate': 0.0014664202118319929}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:39:23,722] Trial 22 finished with value: 0.41838479174767684 and parameters: {'batch_size': 32, 'epochs': 167, 'units': 128, 'learning_rate': 0.0025631616062698932}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:39:35,044] Trial 23 finished with value: 0.4167146893978485 and parameters: {'batch_size': 32, 'epochs': 146, 'units': 108, 'learning_rate': 0.0011641885694999936}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:39:41,445] Trial 24 finished with value: 0.4176300147529658 and parameters: {'batch_size': 64, 'epochs': 117, 'units': 79, 'learning_rate': 0.0006587695024187435}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:39:52,110] Trial 25 finished with value: 0.41919642649346844 and parameters: {'batch_size': 32, 'epochs': 178, 'units': 121, 'learning_rate': 0.003921366989175275}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:40:01,500] Trial 26 finished with value: 0.421378775174149 and parameters: {'batch_size': 64, 'epochs': 137, 'units': 93, 'learning_rate': 0.009117682622625651}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:40:10,320] Trial 27 finished with value: 0.4168414164290136 and parameters: {'batch_size': 32, 'epochs': 75, 'units': 112, 'learning_rate': 0.0024364651481115955}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:40:18,166] Trial 28 finished with value: 0.4171909114399487 and parameters: {'batch_size': 32, 'epochs': 159, 'units': 68, 'learning_rate': 0.0004869853355843033}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:40:25,625] Trial 29 finished with value: 0.41753743246692826 and parameters: {'batch_size': 64, 'epochs': 55, 'units': 86, 'learning_rate': 0.00029316200676049957}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:40:39,302] Trial 30 finished with value: 0.4167532160551121 and parameters: {'batch_size': 16, 'epochs': 50, 'units': 100, 'learning_rate': 0.005743882765703304}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:40:51,897] Trial 31 finished with value: 0.4180249776313633 and parameters: {'batch_size': 16, 'epochs': 115, 'units': 34, 'learning_rate': 0.004130072405405025}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:41:01,794] Trial 32 finished with value: 0.416694654293907 and parameters: {'batch_size': 16, 'epochs': 126, 'units': 44, 'learning_rate': 0.001887211882402857}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:41:11,478] Trial 33 finished with value: 0.4166939204564898 and parameters: {'batch_size': 16, 'epochs': 152, 'units': 53, 'learning_rate': 0.006514361897458673}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:41:22,262] Trial 34 finished with value: 0.4167224803319549 and parameters: {'batch_size': 16, 'epochs': 137, 'units': 121, 'learning_rate': 0.00013714356436570678}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:41:37,446] Trial 35 finished with value: 0.4168404863600826 and parameters: {'batch_size': 16, 'epochs': 101, 'units': 40, 'learning_rate': 0.003142183410799794}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:41:46,657] Trial 36 finished with value: 0.4166942884560171 and parameters: {'batch_size': 16, 'epochs': 65, 'units': 72, 'learning_rate': 0.0018710749292141712}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:41:57,744] Trial 37 finished with value: 0.4167096564274925 and parameters: {'batch_size': 16, 'epochs': 119, 'units': 101, 'learning_rate': 0.005977739352723254}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:42:08,311] Trial 38 finished with value: 0.4166956188495227 and parameters: {'batch_size': 32, 'epochs': 83, 'units': 82, 'learning_rate': 0.0013554454202415577}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:42:16,642] Trial 39 finished with value: 0.41683771564109456 and parameters: {'batch_size': 64, 'epochs': 181, 'units': 90, 'learning_rate': 0.0009831231799733284}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:42:26,920] Trial 40 finished with value: 0.41721646102920845 and parameters: {'batch_size': 32, 'epochs': 197, 'units': 110, 'learning_rate': 0.00030618493795573915}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:42:37,448] Trial 41 finished with value: 0.4175666495838928 and parameters: {'batch_size': 64, 'epochs': 62, 'units': 106, 'learning_rate': 0.000559090777886393}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:42:46,588] Trial 42 finished with value: 0.4172612034841196 and parameters: {'batch_size': 64, 'epochs': 73, 'units': 119, 'learning_rate': 0.00035372589745405486}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:42:54,036] Trial 43 finished with value: 0.41700949559795825 and parameters: {'batch_size': 64, 'epochs': 91, 'units': 103, 'learning_rate': 0.00016765198608241578}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:43:01,273] Trial 44 finished with value: 0.4180975406193245 and parameters: {'batch_size': 64, 'epochs': 73, 'units': 95, 'learning_rate': 0.0008172235292965999}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:43:09,760] Trial 45 finished with value: 0.41712067604580855 and parameters: {'batch_size': 64, 'epochs': 108, 'units': 124, 'learning_rate': 0.0005318578491191686}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:43:20,478] Trial 46 finished with value: 0.4170244755483382 and parameters: {'batch_size': 32, 'epochs': 84, 'units': 49, 'learning_rate': 0.000262337227499102}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:43:31,833] Trial 47 finished with value: 0.4167345500908443 and parameters: {'batch_size': 32, 'epochs': 135, 'units': 60, 'learning_rate': 0.0021811849580361}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:43:41,709] Trial 48 finished with value: 0.4186660831801129 and parameters: {'batch_size': 64, 'epochs': 173, 'units': 115, 'learning_rate': 0.0032929268869566148}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:43:54,535] Trial 49 finished with value: 0.4185393336538571 and parameters: {'batch_size': 16, 'epochs': 191, 'units': 77, 'learning_rate': 0.0012748263639671235}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:44:05,478] Trial 50 finished with value: 0.41807802917956904 and parameters: {'batch_size': 32, 'epochs': 151, 'units': 71, 'learning_rate': 0.0004022869362957076}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:44:14,864] Trial 51 finished with value: 0.4168226509632413 and parameters: {'batch_size': 32, 'epochs': 162, 'units': 125, 'learning_rate': 0.001079388923013194}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:44:25,167] Trial 52 finished with value: 0.416684985461675 and parameters: {'batch_size': 32, 'epochs': 143, 'units': 128, 'learning_rate': 0.000787478046087744}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:44:36,929] Trial 53 finished with value: 0.4166927635575818 and parameters: {'batch_size': 32, 'epochs': 153, 'units': 118, 'learning_rate': 0.0005826538442291531}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:44:46,004] Trial 54 finished with value: 0.41821814426337245 and parameters: {'batch_size': 32, 'epochs': 143, 'units': 125, 'learning_rate': 0.0015208163564233237}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:44:59,860] Trial 55 finished with value: 0.41700488932323726 and parameters: {'batch_size': 32, 'epochs': 102, 'units': 111, 'learning_rate': 0.0007501903341035808}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:45:08,354] Trial 56 finished with value: 0.41732423302530147 and parameters: {'batch_size': 64, 'epochs': 132, 'units': 107, 'learning_rate': 0.0009026547611056597}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:45:20,952] Trial 57 finished with value: 0.41701034251609953 and parameters: {'batch_size': 32, 'epochs': 121, 'units': 63, 'learning_rate': 0.0048720591186090685}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:45:31,800] Trial 58 finished with value: 0.41793425902448883 and parameters: {'batch_size': 32, 'epochs': 56, 'units': 90, 'learning_rate': 0.00035678376260641275}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:45:42,211] Trial 59 finished with value: 0.41689592337549847 and parameters: {'batch_size': 64, 'epochs': 142, 'units': 128, 'learning_rate': 0.00046808087011510253}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:45:51,037] Trial 60 finished with value: 0.4166961104870729 and parameters: {'batch_size': 32, 'epochs': 113, 'units': 98, 'learning_rate': 0.000654594367788859}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:46:01,490] Trial 61 finished with value: 0.41684486240014035 and parameters: {'batch_size': 32, 'epochs': 160, 'units': 123, 'learning_rate': 0.001175906896631933}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:46:11,001] Trial 62 finished with value: 0.4171296101808373 and parameters: {'batch_size': 32, 'epochs': 169, 'units': 128, 'learning_rate': 0.0017269868391812213}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:46:20,138] Trial 63 finished with value: 0.41677958089594663 and parameters: {'batch_size': 32, 'epochs': 157, 'units': 116, 'learning_rate': 0.0008685648787759983}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:46:29,501] Trial 64 finished with value: 0.4167876934945033 and parameters: {'batch_size': 32, 'epochs': 68, 'units': 113, 'learning_rate': 0.00022951963030498347}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:46:44,791] Trial 65 finished with value: 0.4167789968214212 and parameters: {'batch_size': 16, 'epochs': 123, 'units': 119, 'learning_rate': 0.0022079137703357684}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:46:53,211] Trial 66 finished with value: 0.4171498159907759 and parameters: {'batch_size': 64, 'epochs': 149, 'units': 122, 'learning_rate': 0.0006403965626402739}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:47:04,115] Trial 67 finished with value: 0.41672472631893664 and parameters: {'batch_size': 32, 'epochs': 77, 'units': 104, 'learning_rate': 0.001004584763868148}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:47:20,376] Trial 68 finished with value: 0.4168938704715844 and parameters: {'batch_size': 16, 'epochs': 140, 'units': 117, 'learning_rate': 0.008003709867365752}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:47:28,568] Trial 69 finished with value: 0.41685975284843124 and parameters: {'batch_size': 32, 'epochs': 130, 'units': 83, 'learning_rate': 0.0004416548214033491}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:47:38,674] Trial 70 finished with value: 0.4168995910510264 and parameters: {'batch_size': 64, 'epochs': 166, 'units': 127, 'learning_rate': 0.0027401703450603983}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:47:48,093] Trial 71 finished with value: 0.416893506856046 and parameters: {'batch_size': 32, 'epochs': 156, 'units': 118, 'learning_rate': 0.0005624041390403366}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:47:59,437] Trial 72 finished with value: 0.41682902614714545 and parameters: {'batch_size': 32, 'epochs': 154, 'units': 110, 'learning_rate': 0.00034811130476176353}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:48:12,054] Trial 73 finished with value: 0.41685932158553085 and parameters: {'batch_size': 32, 'epochs': 147, 'units': 122, 'learning_rate': 0.0007559766884649119}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:48:22,760] Trial 74 finished with value: 0.4168266874032459 and parameters: {'batch_size': 32, 'epochs': 176, 'units': 125, 'learning_rate': 0.0005248418804279789}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:48:33,925] Trial 75 finished with value: 0.41748281434266415 and parameters: {'batch_size': 32, 'epochs': 94, 'units': 53, 'learning_rate': 0.0006135516280644987}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:48:42,853] Trial 76 finished with value: 0.4167040372315428 and parameters: {'batch_size': 16, 'epochs': 87, 'units': 32, 'learning_rate': 0.0014212042484157844}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:48:57,697] Trial 77 finished with value: 0.4167631470031184 and parameters: {'batch_size': 32, 'epochs': 127, 'units': 114, 'learning_rate': 0.0016626980199908068}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:06,109] Trial 78 finished with value: 0.41669001746888307 and parameters: {'batch_size': 64, 'epochs': 106, 'units': 119, 'learning_rate': 0.0012733358037128168}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:15,170] Trial 79 finished with value: 0.41669550550601614 and parameters: {'batch_size': 64, 'epochs': 109, 'units': 120, 'learning_rate': 0.0011136993913008657}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:21,725] Trial 80 finished with value: 0.4171009255283094 and parameters: {'batch_size': 64, 'epochs': 98, 'units': 41, 'learning_rate': 0.001279007869116932}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:29,733] Trial 81 finished with value: 0.41674384630940847 and parameters: {'batch_size': 64, 'epochs': 115, 'units': 108, 'learning_rate': 0.0007966152883849015}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:38,785] Trial 82 finished with value: 0.41681088004818256 and parameters: {'batch_size': 64, 'epochs': 106, 'units': 126, 'learning_rate': 0.0009339912633790625}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:47,071] Trial 83 finished with value: 0.41945995986330264 and parameters: {'batch_size': 64, 'epochs': 164, 'units': 117, 'learning_rate': 0.00030349461864035565}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:49:56,074] Trial 84 finished with value: 0.4167820631124014 and parameters: {'batch_size': 64, 'epochs': 136, 'units': 121, 'learning_rate': 0.0006815237009346962}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:50:08,650] Trial 85 finished with value: 0.4166850771427788 and parameters: {'batch_size': 32, 'epochs': 68, 'units': 102, 'learning_rate': 0.00347068698181634}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:50:18,752] Trial 86 finished with value: 0.417806710691347 and parameters: {'batch_size': 16, 'epochs': 67, 'units': 102, 'learning_rate': 0.0030492151590692266}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:50:27,955] Trial 87 finished with value: 0.416784132353936 and parameters: {'batch_size': 32, 'epochs': 57, 'units': 98, 'learning_rate': 0.0035575347199555975}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:50:36,818] Trial 88 finished with value: 0.41670801764719345 and parameters: {'batch_size': 64, 'epochs': 77, 'units': 93, 'learning_rate': 0.003971335258775989}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:50:45,348] Trial 89 finished with value: 0.4168617070350949 and parameters: {'batch_size': 32, 'epochs': 62, 'units': 88, 'learning_rate': 0.002351346682663353}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:50:56,154] Trial 90 finished with value: 0.41682702970127883 and parameters: {'batch_size': 16, 'epochs': 72, 'units': 66, 'learning_rate': 0.0018576182568190067}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:51:04,457] Trial 91 finished with value: 0.41689670986384114 and parameters: {'batch_size': 32, 'epochs': 80, 'units': 105, 'learning_rate': 0.001036819982668835}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:51:13,856] Trial 92 finished with value: 0.4177604097317453 and parameters: {'batch_size': 32, 'epochs': 170, 'units': 109, 'learning_rate': 0.005030398245977181}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:51:23,923] Trial 93 finished with value: 0.4181282943809835 and parameters: {'batch_size': 32, 'epochs': 69, 'units': 112, 'learning_rate': 0.004511925255889071}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:51:35,389] Trial 94 finished with value: 0.4167705408904712 and parameters: {'batch_size': 32, 'epochs': 118, 'units': 124, 'learning_rate': 0.0004896025392349336}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:51:45,484] Trial 95 finished with value: 0.4167844224051982 and parameters: {'batch_size': 32, 'epochs': 104, 'units': 99, 'learning_rate': 0.00039778021104616137}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:51:53,942] Trial 96 finished with value: 0.41676270656247544 and parameters: {'batch_size': 32, 'epochs': 123, 'units': 115, 'learning_rate': 0.0028132281380767476}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:52:02,402] Trial 97 finished with value: 0.4167462455559302 and parameters: {'batch_size': 64, 'epochs': 152, 'units': 119, 'learning_rate': 0.0012478247326952044}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:52:13,915] Trial 98 finished with value: 0.4168574551793079 and parameters: {'batch_size': 32, 'epochs': 113, 'units': 123, 'learning_rate': 0.002108152759452477}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:52:24,887] Trial 99 finished with value: 0.41763051066671114 and parameters: {'batch_size': 64, 'epochs': 146, 'units': 95, 'learning_rate': 0.0005764141125242253}. Best is trial 17 with value: 0.41668443861356935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "  Value: 0.41668443861356935\n",
      "  Params: \n",
      "    batch_size: 64\n",
      "    epochs: 114\n",
      "    units: 106\n",
      "    learning_rate: 0.0011509581463392332\n",
      "Epoch 1/114\n",
      "15/15 [==============================] - 3s 52ms/step - loss: 0.6818 - val_loss: 0.4282\n",
      "Epoch 2/114\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4562 - val_loss: 0.4288\n",
      "Epoch 3/114\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4372 - val_loss: 0.4220\n",
      "Epoch 4/114\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4347 - val_loss: 0.4236\n",
      "Epoch 5/114\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4274 - val_loss: 0.4289\n",
      "Epoch 6/114\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.4316 - val_loss: 0.4215\n",
      "Epoch 7/114\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4304 - val_loss: 0.4247\n",
      "Epoch 8/114\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.4214 - val_loss: 0.4250\n",
      "Epoch 9/114\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4283 - val_loss: 0.4210\n",
      "Epoch 10/114\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4128 - val_loss: 0.4306\n",
      "Epoch 11/114\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4211 - val_loss: 0.4179\n",
      "Epoch 12/114\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4149 - val_loss: 0.4359\n",
      "Epoch 13/114\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4142 - val_loss: 0.4169\n",
      "Epoch 14/114\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4203 - val_loss: 0.4287\n",
      "Epoch 15/114\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4106 - val_loss: 0.4197\n",
      "Epoch 16/114\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4098 - val_loss: 0.4349\n",
      "Epoch 17/114\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4140 - val_loss: 0.4177\n",
      "Epoch 18/114\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4074 - val_loss: 0.4209\n",
      "Epoch 19/114\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4067 - val_loss: 0.4237\n",
      "Epoch 20/114\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4101 - val_loss: 0.4219\n",
      "Epoch 21/114\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4141 - val_loss: 0.4215\n",
      "Epoch 22/114\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.4088 - val_loss: 0.4223\n",
      "Epoch 23/114\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4069 - val_loss: 0.4245\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "MSE   : 0.41692452697941196\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "MSE   : 0.415717015906766\n"
     ]
    }
   ],
   "source": [
    "LSTM_testing_8 = LSTM_testing(normalizes_df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88fecfbc-634f-4f06-87d7-ecb424cb465e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:52:35,924] A new study created in memory with name: no-name-cd888548-b62e-4103-b55d-905fd3fa269c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:52:46,308] Trial 0 finished with value: 0.2969819646798616 and parameters: {'batch_size': 64, 'epochs': 132, 'units': 100, 'learning_rate': 0.0006554222335858724}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:53:00,473] Trial 1 finished with value: 0.2969906529993143 and parameters: {'batch_size': 32, 'epochs': 98, 'units': 105, 'learning_rate': 0.0033348151832514415}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:53:15,471] Trial 2 finished with value: 0.2969819703814752 and parameters: {'batch_size': 16, 'epochs': 128, 'units': 90, 'learning_rate': 0.0023487858165151844}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:53:24,227] Trial 3 finished with value: 0.29700130276264175 and parameters: {'batch_size': 64, 'epochs': 73, 'units': 108, 'learning_rate': 0.002490660636324012}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:53:31,208] Trial 4 finished with value: 0.2969822057292419 and parameters: {'batch_size': 32, 'epochs': 154, 'units': 47, 'learning_rate': 0.000893884493355274}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:53:47,833] Trial 5 finished with value: 0.29698248090418056 and parameters: {'batch_size': 16, 'epochs': 72, 'units': 110, 'learning_rate': 0.004317426387889132}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:54:02,912] Trial 6 finished with value: 0.29700635463431374 and parameters: {'batch_size': 16, 'epochs': 97, 'units': 102, 'learning_rate': 0.00018854926282162776}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:54:11,042] Trial 7 finished with value: 0.2969979137032444 and parameters: {'batch_size': 32, 'epochs': 161, 'units': 105, 'learning_rate': 0.004879792810106308}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:54:20,276] Trial 8 finished with value: 0.2969973435358014 and parameters: {'batch_size': 16, 'epochs': 163, 'units': 68, 'learning_rate': 0.0051122738690233295}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:54:30,370] Trial 9 finished with value: 0.2969890363746949 and parameters: {'batch_size': 64, 'epochs': 88, 'units': 73, 'learning_rate': 0.0008342852162419163}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:54:39,160] Trial 10 finished with value: 0.2972484731228551 and parameters: {'batch_size': 64, 'epochs': 191, 'units': 128, 'learning_rate': 0.00025544287629088327}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:54:57,391] Trial 11 finished with value: 0.2969857476302894 and parameters: {'batch_size': 16, 'epochs': 125, 'units': 87, 'learning_rate': 0.00047988201276691393}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:55:04,172] Trial 12 finished with value: 0.2969854426808982 and parameters: {'batch_size': 64, 'epochs': 130, 'units': 87, 'learning_rate': 0.0017423791018224071}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:55:10,756] Trial 13 finished with value: 0.2969846997519237 and parameters: {'batch_size': 64, 'epochs': 139, 'units': 57, 'learning_rate': 0.00992164610428335}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:55:31,050] Trial 14 finished with value: 0.2969910878604678 and parameters: {'batch_size': 16, 'epochs': 115, 'units': 127, 'learning_rate': 0.00010512406771671268}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:55:40,035] Trial 15 finished with value: 0.29699908952974624 and parameters: {'batch_size': 64, 'epochs': 50, 'units': 90, 'learning_rate': 0.0014616683396446197}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:55:56,732] Trial 16 finished with value: 0.29698336621869614 and parameters: {'batch_size': 16, 'epochs': 188, 'units': 73, 'learning_rate': 0.0005234779176690603}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:56:08,520] Trial 17 finished with value: 0.29698372422620667 and parameters: {'batch_size': 16, 'epochs': 112, 'units': 95, 'learning_rate': 0.0005290965471112319}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:56:15,964] Trial 18 finished with value: 0.29702669402052223 and parameters: {'batch_size': 64, 'epochs': 145, 'units': 35, 'learning_rate': 0.0013869953341071062}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:56:27,095] Trial 19 finished with value: 0.29698498919532795 and parameters: {'batch_size': 32, 'epochs': 179, 'units': 80, 'learning_rate': 0.008324850667407737}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:56:38,500] Trial 20 finished with value: 0.2969858028246686 and parameters: {'batch_size': 64, 'epochs': 118, 'units': 115, 'learning_rate': 0.0023101118381219686}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:56:47,587] Trial 21 finished with value: 0.2969871119596587 and parameters: {'batch_size': 32, 'epochs': 152, 'units': 32, 'learning_rate': 0.0008976924428568505}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:56:56,492] Trial 22 finished with value: 0.297030664044394 and parameters: {'batch_size': 32, 'epochs': 137, 'units': 45, 'learning_rate': 0.0008183662584588327}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:57:06,673] Trial 23 finished with value: 0.2969849555896476 and parameters: {'batch_size': 32, 'epochs': 167, 'units': 58, 'learning_rate': 0.0002900869872697544}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:57:18,786] Trial 24 finished with value: 0.2969867178525628 and parameters: {'batch_size': 32, 'epochs': 150, 'units': 95, 'learning_rate': 0.0010877189606354595}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:57:27,404] Trial 25 finished with value: 0.2970587393285016 and parameters: {'batch_size': 32, 'epochs': 132, 'units': 59, 'learning_rate': 0.0003659275965469547}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:57:39,891] Trial 26 finished with value: 0.29698286136119084 and parameters: {'batch_size': 16, 'epochs': 173, 'units': 48, 'learning_rate': 0.00212489548128759}. Best is trial 0 with value: 0.2969819646798616.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:57:49,789] Trial 27 finished with value: 0.2969819645066575 and parameters: {'batch_size': 32, 'epochs': 104, 'units': 120, 'learning_rate': 0.0006752099866149849}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:58:02,099] Trial 28 finished with value: 0.2969889579791193 and parameters: {'batch_size': 16, 'epochs': 105, 'units': 119, 'learning_rate': 0.0001582028814399637}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:58:10,752] Trial 29 finished with value: 0.29698196728361903 and parameters: {'batch_size': 64, 'epochs': 91, 'units': 119, 'learning_rate': 0.003268424077667229}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:58:23,802] Trial 30 finished with value: 0.29698197779100677 and parameters: {'batch_size': 64, 'epochs': 85, 'units': 118, 'learning_rate': 0.0006509290457825531}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:58:34,612] Trial 31 finished with value: 0.2970423082722287 and parameters: {'batch_size': 64, 'epochs': 99, 'units': 98, 'learning_rate': 0.0035446396699251926}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:58:49,423] Trial 32 finished with value: 0.2969820163269002 and parameters: {'batch_size': 64, 'epochs': 73, 'units': 113, 'learning_rate': 0.0030035315664261194}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:58:59,781] Trial 33 finished with value: 0.297036380345695 and parameters: {'batch_size': 64, 'epochs': 121, 'units': 103, 'learning_rate': 0.006823408585247716}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:59:07,708] Trial 34 finished with value: 0.2969835408838001 and parameters: {'batch_size': 64, 'epochs': 88, 'units': 124, 'learning_rate': 0.0012222538512704159}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:59:17,310] Trial 35 finished with value: 0.2970311559208645 and parameters: {'batch_size': 32, 'epochs': 109, 'units': 120, 'learning_rate': 0.0017563699485676281}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:59:25,027] Trial 36 finished with value: 0.29698359461229784 and parameters: {'batch_size': 64, 'epochs': 99, 'units': 110, 'learning_rate': 0.0033216311106661293}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:59:37,541] Trial 37 finished with value: 0.29706758172412645 and parameters: {'batch_size': 16, 'epochs': 58, 'units': 106, 'learning_rate': 0.0006796819338863101}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 20:59:46,168] Trial 38 finished with value: 0.2969852828179556 and parameters: {'batch_size': 32, 'epochs': 77, 'units': 82, 'learning_rate': 0.002800636929813256}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:00:05,847] Trial 39 finished with value: 0.29699383454035205 and parameters: {'batch_size': 16, 'epochs': 104, 'units': 101, 'learning_rate': 0.0003849526618611963}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:00:13,062] Trial 40 finished with value: 0.2970249614420958 and parameters: {'batch_size': 64, 'epochs': 125, 'units': 111, 'learning_rate': 0.005405082224955226}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:00:24,867] Trial 41 finished with value: 0.29698250556685324 and parameters: {'batch_size': 64, 'epochs': 84, 'units': 119, 'learning_rate': 0.0006761230071140015}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:00:34,950] Trial 42 finished with value: 0.2969843085973608 and parameters: {'batch_size': 64, 'epochs': 92, 'units': 123, 'learning_rate': 0.0006871290568278834}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:00:43,416] Trial 43 finished with value: 0.2969832481097012 and parameters: {'batch_size': 64, 'epochs': 62, 'units': 115, 'learning_rate': 0.004157650701043307}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:00:52,557] Trial 44 finished with value: 0.2969831501618443 and parameters: {'batch_size': 64, 'epochs': 79, 'units': 106, 'learning_rate': 0.00043661142016507135}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:01:01,037] Trial 45 finished with value: 0.2970987360435495 and parameters: {'batch_size': 64, 'epochs': 93, 'units': 94, 'learning_rate': 0.0010309008080511127}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:01:16,637] Trial 46 finished with value: 0.29699478804245305 and parameters: {'batch_size': 16, 'epochs': 68, 'units': 117, 'learning_rate': 0.0017473861470214862}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:01:26,804] Trial 47 finished with value: 0.29698203059473477 and parameters: {'batch_size': 64, 'epochs': 141, 'units': 128, 'learning_rate': 0.0006219497365447119}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:01:42,824] Trial 48 finished with value: 0.2969864553452727 and parameters: {'batch_size': 32, 'epochs': 129, 'units': 109, 'learning_rate': 0.0002796815429390005}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:01:50,519] Trial 49 finished with value: 0.29699016092591557 and parameters: {'batch_size': 64, 'epochs': 109, 'units': 90, 'learning_rate': 0.0013929496558064262}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:02:05,956] Trial 50 finished with value: 0.29698315492398963 and parameters: {'batch_size': 16, 'epochs': 117, 'units': 99, 'learning_rate': 0.0007995170981793708}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:02:15,257] Trial 51 finished with value: 0.2969843709814044 and parameters: {'batch_size': 64, 'epochs': 71, 'units': 123, 'learning_rate': 0.002834637056343674}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:02:25,450] Trial 52 finished with value: 0.2969820317168905 and parameters: {'batch_size': 64, 'epochs': 81, 'units': 111, 'learning_rate': 0.004317337670254995}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:02:34,772] Trial 53 finished with value: 0.2969907497352888 and parameters: {'batch_size': 64, 'epochs': 64, 'units': 114, 'learning_rate': 0.0024710166750843065}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:02:46,381] Trial 54 finished with value: 0.2969828625716844 and parameters: {'batch_size': 64, 'epochs': 51, 'units': 124, 'learning_rate': 0.0020678384029834186}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:02:53,137] Trial 55 finished with value: 0.29699576164481456 and parameters: {'batch_size': 64, 'epochs': 86, 'units': 83, 'learning_rate': 0.006228342196783587}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:03:00,846] Trial 56 finished with value: 0.2970420427596927 and parameters: {'batch_size': 64, 'epochs': 77, 'units': 114, 'learning_rate': 0.0011878685727297292}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:03:14,274] Trial 57 finished with value: 0.29698217079056166 and parameters: {'batch_size': 32, 'epochs': 96, 'units': 76, 'learning_rate': 0.003272615626035258}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:03:27,826] Trial 58 finished with value: 0.29698197567748497 and parameters: {'batch_size': 16, 'epochs': 104, 'units': 104, 'learning_rate': 0.0005857338110662188}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:03:37,566] Trial 59 finished with value: 0.296987213801324 and parameters: {'batch_size': 16, 'epochs': 159, 'units': 91, 'learning_rate': 0.0005770898786057659}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:03:55,299] Trial 60 finished with value: 0.2969852165897884 and parameters: {'batch_size': 16, 'epochs': 103, 'units': 106, 'learning_rate': 0.0003373433037660146}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:04:09,783] Trial 61 finished with value: 0.2969827782785577 and parameters: {'batch_size': 16, 'epochs': 132, 'units': 102, 'learning_rate': 0.00048132342892393443}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:04:24,293] Trial 62 finished with value: 0.29704545870111865 and parameters: {'batch_size': 16, 'epochs': 114, 'units': 97, 'learning_rate': 0.0009206890416376149}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:04:36,351] Trial 63 finished with value: 0.2970486515476835 and parameters: {'batch_size': 16, 'epochs': 124, 'units': 121, 'learning_rate': 0.0007476314026006018}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:04:50,877] Trial 64 finished with value: 0.29698739102022803 and parameters: {'batch_size': 32, 'epochs': 92, 'units': 86, 'learning_rate': 0.00020208767023738335}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:05:01,020] Trial 65 finished with value: 0.2969911586118141 and parameters: {'batch_size': 64, 'epochs': 109, 'units': 113, 'learning_rate': 0.0004310528534906115}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:05:17,445] Trial 66 finished with value: 0.29698944858240234 and parameters: {'batch_size': 16, 'epochs': 146, 'units': 118, 'learning_rate': 0.0005684568819087731}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:05:28,396] Trial 67 finished with value: 0.29704463128613157 and parameters: {'batch_size': 64, 'epochs': 74, 'units': 103, 'learning_rate': 0.001561871349422332}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:05:39,059] Trial 68 finished with value: 0.2970164561828421 and parameters: {'batch_size': 32, 'epochs': 101, 'units': 126, 'learning_rate': 0.002001400069328422}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:05:48,989] Trial 69 finished with value: 0.2970078144112279 and parameters: {'batch_size': 16, 'epochs': 83, 'units': 108, 'learning_rate': 0.003637124237608034}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:05:58,261] Trial 70 finished with value: 0.296982363212853 and parameters: {'batch_size': 64, 'epochs': 199, 'units': 116, 'learning_rate': 0.000964571772432979}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:06,731] Trial 71 finished with value: 0.29701906724276084 and parameters: {'batch_size': 64, 'epochs': 137, 'units': 128, 'learning_rate': 0.0006204912609123409}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:15,747] Trial 72 finished with value: 0.2969898323102985 and parameters: {'batch_size': 64, 'epochs': 141, 'units': 120, 'learning_rate': 0.0005146089733602963}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:25,183] Trial 73 finished with value: 0.2969997497253078 and parameters: {'batch_size': 64, 'epochs': 89, 'units': 122, 'learning_rate': 0.0008266117901865615}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:33,434] Trial 74 finished with value: 0.29702364180324675 and parameters: {'batch_size': 64, 'epochs': 119, 'units': 125, 'learning_rate': 0.0006217382985496389}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:41,465] Trial 75 finished with value: 0.2970727425584243 and parameters: {'batch_size': 64, 'epochs': 133, 'units': 128, 'learning_rate': 0.00289128422570587}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:49,779] Trial 76 finished with value: 0.2970471420501184 and parameters: {'batch_size': 64, 'epochs': 156, 'units': 93, 'learning_rate': 0.00045624194066315856}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:06:59,035] Trial 77 finished with value: 0.29703896359597337 and parameters: {'batch_size': 32, 'epochs': 144, 'units': 112, 'learning_rate': 0.00040292990088073937}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:07:06,685] Trial 78 finished with value: 0.29712628638763144 and parameters: {'batch_size': 64, 'epochs': 124, 'units': 117, 'learning_rate': 0.0003280302031289376}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:07:22,151] Trial 79 finished with value: 0.29698394407289175 and parameters: {'batch_size': 16, 'epochs': 96, 'units': 104, 'learning_rate': 0.00502862801315683}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:07:31,923] Trial 80 finished with value: 0.2969838795145376 and parameters: {'batch_size': 64, 'epochs': 127, 'units': 99, 'learning_rate': 0.0011558941916441122}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:07:39,102] Trial 81 finished with value: 0.29699676601808567 and parameters: {'batch_size': 64, 'epochs': 82, 'units': 109, 'learning_rate': 0.003998918918340629}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:07:46,849] Trial 82 finished with value: 0.29703315292912474 and parameters: {'batch_size': 64, 'epochs': 80, 'units': 107, 'learning_rate': 0.005855956998893064}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:07:58,663] Trial 83 finished with value: 0.29698250557995726 and parameters: {'batch_size': 64, 'epochs': 66, 'units': 112, 'learning_rate': 0.004439461630793475}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:08:06,037] Trial 84 finished with value: 0.29698288345193513 and parameters: {'batch_size': 64, 'epochs': 71, 'units': 111, 'learning_rate': 0.0007358129539601917}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:08:14,105] Trial 85 finished with value: 0.2969826277122016 and parameters: {'batch_size': 64, 'epochs': 107, 'units': 119, 'learning_rate': 0.00265127175762067}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:08:25,308] Trial 86 finished with value: 0.29698334488065653 and parameters: {'batch_size': 32, 'epochs': 136, 'units': 116, 'learning_rate': 0.007130569747701906}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:08:33,169] Trial 87 finished with value: 0.29699365899879204 and parameters: {'batch_size': 64, 'epochs': 60, 'units': 122, 'learning_rate': 0.0031268254981140545}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:08:48,291] Trial 88 finished with value: 0.2969874522712373 and parameters: {'batch_size': 16, 'epochs': 113, 'units': 126, 'learning_rate': 0.0023077863081262156}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:08:58,232] Trial 89 finished with value: 0.2970365754480699 and parameters: {'batch_size': 64, 'epochs': 87, 'units': 96, 'learning_rate': 0.0006271913784993253}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:09:08,060] Trial 90 finished with value: 0.2969822255366144 and parameters: {'batch_size': 64, 'epochs': 75, 'units': 64, 'learning_rate': 0.0045846749871722705}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:09:15,854] Trial 91 finished with value: 0.2969958269221926 and parameters: {'batch_size': 32, 'epochs': 96, 'units': 76, 'learning_rate': 0.0036851373060131695}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:09:24,575] Trial 92 finished with value: 0.29712170998941934 and parameters: {'batch_size': 32, 'epochs': 91, 'units': 77, 'learning_rate': 0.0005237053840321917}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:09:31,532] Trial 93 finished with value: 0.29698840708186874 and parameters: {'batch_size': 32, 'epochs': 97, 'units': 73, 'learning_rate': 0.003842594749029304}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:09:41,725] Trial 94 finished with value: 0.29699489987822286 and parameters: {'batch_size': 32, 'epochs': 148, 'units': 100, 'learning_rate': 0.0030195919722316943}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:09:51,991] Trial 95 finished with value: 0.2970543911370207 and parameters: {'batch_size': 32, 'epochs': 102, 'units': 69, 'learning_rate': 0.0033915237808599804}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:10:10,379] Trial 96 finished with value: 0.29698254154893533 and parameters: {'batch_size': 16, 'epochs': 85, 'units': 86, 'learning_rate': 0.0008384486513734578}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:10:19,693] Trial 97 finished with value: 0.29703091424937045 and parameters: {'batch_size': 32, 'epochs': 78, 'units': 82, 'learning_rate': 0.0025384709543181372}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:10:32,711] Trial 98 finished with value: 0.29700131476967906 and parameters: {'batch_size': 64, 'epochs': 94, 'units': 114, 'learning_rate': 0.009807471986513059}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:10:48,457] Trial 99 finished with value: 0.296984082597114 and parameters: {'batch_size': 16, 'epochs': 90, 'units': 105, 'learning_rate': 0.0007437870908121374}. Best is trial 27 with value: 0.2969819645066575.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial:\n",
      "  Value: 0.2969819645066575\n",
      "  Params: \n",
      "    batch_size: 32\n",
      "    epochs: 104\n",
      "    units: 120\n",
      "    learning_rate: 0.0006752099866149849\n",
      "Epoch 1/104\n",
      "30/30 [==============================] - 4s 30ms/step - loss: 0.3400 - val_loss: 0.2998\n",
      "Epoch 2/104\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2989 - val_loss: 0.2999\n",
      "Epoch 3/104\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.2886 - val_loss: 0.2985\n",
      "Epoch 4/104\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.2944 - val_loss: 0.2987\n",
      "Epoch 5/104\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2779 - val_loss: 0.3133\n",
      "Epoch 6/104\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2898 - val_loss: 0.3130\n",
      "Epoch 7/104\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2858 - val_loss: 0.2995\n",
      "Epoch 8/104\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2779 - val_loss: 0.3005\n",
      "Epoch 9/104\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2833 - val_loss: 0.2984\n",
      "Epoch 10/104\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2801 - val_loss: 0.3027\n",
      "Epoch 11/104\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2783 - val_loss: 0.3016\n",
      "Epoch 12/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2763 - val_loss: 0.2993\n",
      "Epoch 13/104\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2752 - val_loss: 0.2970\n",
      "Epoch 14/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2775 - val_loss: 0.2984\n",
      "Epoch 15/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2797 - val_loss: 0.2971\n",
      "Epoch 16/104\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2739 - val_loss: 0.2986\n",
      "Epoch 17/104\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2768 - val_loss: 0.3019\n",
      "Epoch 18/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2779 - val_loss: 0.3000\n",
      "Epoch 19/104\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2752 - val_loss: 0.2970\n",
      "Epoch 20/104\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2763 - val_loss: 0.2970\n",
      "Epoch 21/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2771 - val_loss: 0.3022\n",
      "Epoch 22/104\n",
      "30/30 [==============================] - 0s 13ms/step - loss: 0.2780 - val_loss: 0.3011\n",
      "Epoch 23/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2742 - val_loss: 0.2976\n",
      "Epoch 24/104\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2761 - val_loss: 0.2970\n",
      "Epoch 25/104\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2777 - val_loss: 0.2992\n",
      "Epoch 26/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2737 - val_loss: 0.2974\n",
      "Epoch 27/104\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2747 - val_loss: 0.2998\n",
      "Epoch 28/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2752 - val_loss: 0.2985\n",
      "Epoch 29/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2739 - val_loss: 0.2973\n",
      "Epoch 30/104\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2748 - val_loss: 0.2986\n",
      "Epoch 31/104\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2749 - val_loss: 0.2970\n",
      "Epoch 32/104\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.2751 - val_loss: 0.2997\n",
      "Epoch 33/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2743 - val_loss: 0.2975\n",
      "Epoch 34/104\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.2743 - val_loss: 0.2974\n",
      "4/4 [==============================] - 1s 4ms/step\n",
      "MSE   : 0.2969832049419471\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "MSE   : 0.29305120985484234\n"
     ]
    }
   ],
   "source": [
    "LSTM_testing_9 = LSTM_testing(normalizes_df_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "678ff81d-af04-4412-9336-6e64bc996478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(trial, input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "     CNN   ,  Optuna.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    filters1 = trial.suggest_int('filters1', 32, 128)\n",
    "    kernel_size1 = trial.suggest_int('kernel_size1', 1, 3)\n",
    "    filters2 = trial.suggest_int('filters2', 16, 64)\n",
    "    kernel_size2 = trial.suggest_int('kernel_size2', 1, 3)\n",
    "\n",
    "    model.add(Conv1D(filters=filters1, kernel_size=kernel_size1, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=filters2, kernel_size=kernel_size2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def objective(trial, X_train, y_train, X_val, y_val, time_steps):\n",
    "    \n",
    "    \"\"\"\n",
    "       Optuna: ,    CNN .\n",
    "    \"\"\"\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    epochs = trial.suggest_int(\"epochs\", 50, 200)\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = create_cnn_model(trial, input_shape)\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    return mse_val\n",
    "\n",
    "def CNN_testing(df):\n",
    "    \n",
    "    \"\"\"\n",
    "     CNN ,  Optuna    \n",
    "        .\n",
    "    \"\"\"\n",
    "\n",
    "    time_steps = 10\n",
    "    X_train, X_test, X_val, y_val, y_train, y_test = divides_into_samples(df)\n",
    "\n",
    "    X_train, y_train = create_dataset(X_train.to_numpy(), y_train.to_numpy(), time_steps)\n",
    "    X_val, y_val = create_dataset(X_val.to_numpy(), y_val.to_numpy(), time_steps)\n",
    "    X_test, y_test = create_dataset(X_test.to_numpy(), y_test.to_numpy(), time_steps)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2])\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "    def objective_wrapper(trial):\n",
    "        return objective(trial, X_train, y_train, X_val, y_val, time_steps)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective_wrapper, n_trials=100)\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best validation MSE:\", study.best_value)\n",
    "\n",
    "    best_filters1 = study.best_params['filters1']\n",
    "    best_kernel_size1 = study.best_params['kernel_size1']\n",
    "    best_filters2 = study.best_params['filters2']\n",
    "    best_kernel_size2 = study.best_params['kernel_size2']\n",
    "    best_learning_rate = study.best_params['learning_rate']\n",
    "    best_batch_size = study.best_params['batch_size']\n",
    "    best_epochs = study.best_params['epochs']\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=best_filters1, kernel_size=best_kernel_size1, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=best_filters2, kernel_size=best_kernel_size2, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=best_learning_rate), loss='mean_squared_error')\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=best_epochs,\n",
    "              batch_size=best_batch_size,\n",
    "              callbacks=[early_stopping],\n",
    "              verbose=1)\n",
    "    \n",
    "    y_pred_val = model.predict(X_val)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    print(f\"MSE   : {mse_val}\")\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    print(f\"MSE   : {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a21cd8a7-7fc7-4f50-af3d-011e8a859689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:11:42,161] A new study created in memory with name: no-name-7ba35e5d-4344-4f85-a14b-c4576509424e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:11:45,905] Trial 0 finished with value: 853335062547.4124 and parameters: {'learning_rate': 0.0006719902940150935, 'batch_size': 64, 'epochs': 55, 'filters1': 47, 'kernel_size1': 3, 'filters2': 53, 'kernel_size2': 3}. Best is trial 0 with value: 853335062547.4124.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:11:55,980] Trial 1 finished with value: 11795264592.955711 and parameters: {'learning_rate': 0.0002406298507690785, 'batch_size': 32, 'epochs': 175, 'filters1': 128, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 2}. Best is trial 1 with value: 11795264592.955711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:12:06,609] Trial 2 finished with value: 18925011274.40383 and parameters: {'learning_rate': 0.00035325868996859117, 'batch_size': 32, 'epochs': 170, 'filters1': 127, 'kernel_size1': 2, 'filters2': 26, 'kernel_size2': 3}. Best is trial 1 with value: 11795264592.955711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:12:21,122] Trial 3 finished with value: 50229921241.84501 and parameters: {'learning_rate': 0.00013799773353467167, 'batch_size': 32, 'epochs': 174, 'filters1': 126, 'kernel_size1': 2, 'filters2': 35, 'kernel_size2': 2}. Best is trial 1 with value: 11795264592.955711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:12:30,110] Trial 4 finished with value: 741991917853.0968 and parameters: {'learning_rate': 0.0003808936955179712, 'batch_size': 16, 'epochs': 71, 'filters1': 114, 'kernel_size1': 3, 'filters2': 57, 'kernel_size2': 3}. Best is trial 1 with value: 11795264592.955711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:12:37,943] Trial 5 finished with value: 183950684754.2546 and parameters: {'learning_rate': 0.0010578615543945082, 'batch_size': 16, 'epochs': 125, 'filters1': 35, 'kernel_size1': 3, 'filters2': 49, 'kernel_size2': 1}. Best is trial 1 with value: 11795264592.955711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:12:42,142] Trial 6 finished with value: 1529155887.5379734 and parameters: {'learning_rate': 0.009834383653761082, 'batch_size': 32, 'epochs': 52, 'filters1': 118, 'kernel_size1': 2, 'filters2': 51, 'kernel_size2': 1}. Best is trial 6 with value: 1529155887.5379734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:12:51,962] Trial 7 finished with value: 284917661762.54443 and parameters: {'learning_rate': 0.00044552041482792443, 'batch_size': 16, 'epochs': 137, 'filters1': 37, 'kernel_size1': 2, 'filters2': 55, 'kernel_size2': 3}. Best is trial 6 with value: 1529155887.5379734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:04,438] Trial 8 finished with value: 14875229753.619663 and parameters: {'learning_rate': 0.002816164068523995, 'batch_size': 32, 'epochs': 191, 'filters1': 81, 'kernel_size1': 2, 'filters2': 54, 'kernel_size2': 1}. Best is trial 6 with value: 1529155887.5379734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:17,838] Trial 9 finished with value: 3972851883.1694503 and parameters: {'learning_rate': 0.00041147020665468364, 'batch_size': 32, 'epochs': 162, 'filters1': 68, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 3}. Best is trial 6 with value: 1529155887.5379734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:21,398] Trial 10 finished with value: 3631684169.6040936 and parameters: {'learning_rate': 0.008145037588278326, 'batch_size': 64, 'epochs': 90, 'filters1': 99, 'kernel_size1': 1, 'filters2': 39, 'kernel_size2': 1}. Best is trial 6 with value: 1529155887.5379734.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:27,379] Trial 11 finished with value: 16828329.989387657 and parameters: {'learning_rate': 0.009367741849802573, 'batch_size': 64, 'epochs': 87, 'filters1': 100, 'kernel_size1': 1, 'filters2': 41, 'kernel_size2': 1}. Best is trial 11 with value: 16828329.989387657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:33,732] Trial 12 finished with value: 1820873.7497615467 and parameters: {'learning_rate': 0.009217153818619669, 'batch_size': 64, 'epochs': 97, 'filters1': 95, 'kernel_size1': 1, 'filters2': 45, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:40,756] Trial 13 finished with value: 59963085039.04347 and parameters: {'learning_rate': 0.0036895849529541757, 'batch_size': 64, 'epochs': 99, 'filters1': 95, 'kernel_size1': 1, 'filters2': 64, 'kernel_size2': 2}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:48,189] Trial 14 finished with value: 28334120453.329063 and parameters: {'learning_rate': 0.004188104344185692, 'batch_size': 64, 'epochs': 108, 'filters1': 97, 'kernel_size1': 1, 'filters2': 44, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:13:54,343] Trial 15 finished with value: 5850217264.153158 and parameters: {'learning_rate': 0.0016698899374933912, 'batch_size': 64, 'epochs': 90, 'filters1': 77, 'kernel_size1': 1, 'filters2': 34, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:03,079] Trial 16 finished with value: 1101919716.6578066 and parameters: {'learning_rate': 0.006230417943535034, 'batch_size': 64, 'epochs': 125, 'filters1': 105, 'kernel_size1': 1, 'filters2': 45, 'kernel_size2': 2}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:05,918] Trial 17 finished with value: 97854763.04284027 and parameters: {'learning_rate': 0.002270131533489394, 'batch_size': 64, 'epochs': 72, 'filters1': 87, 'kernel_size1': 1, 'filters2': 16, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:09,175] Trial 18 finished with value: 14589002934.203754 and parameters: {'learning_rate': 0.005659695851033572, 'batch_size': 64, 'epochs': 74, 'filters1': 62, 'kernel_size1': 2, 'filters2': 33, 'kernel_size2': 2}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:17,786] Trial 19 finished with value: 2874229611.2242703 and parameters: {'learning_rate': 0.0016000004459533984, 'batch_size': 64, 'epochs': 116, 'filters1': 109, 'kernel_size1': 1, 'filters2': 41, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:26,446] Trial 20 finished with value: 3042530903.778248 and parameters: {'learning_rate': 0.00529397271467572, 'batch_size': 64, 'epochs': 145, 'filters1': 88, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:31,245] Trial 21 finished with value: 39262926.113581255 and parameters: {'learning_rate': 0.0024935700495598, 'batch_size': 64, 'epochs': 79, 'filters1': 85, 'kernel_size1': 1, 'filters2': 16, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:36,113] Trial 22 finished with value: 3559690707.884521 and parameters: {'learning_rate': 0.00955574610892276, 'batch_size': 64, 'epochs': 84, 'filters1': 71, 'kernel_size1': 1, 'filters2': 47, 'kernel_size2': 1}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:40,348] Trial 23 finished with value: 210491507112.47388 and parameters: {'learning_rate': 0.0032030631210651778, 'batch_size': 64, 'epochs': 100, 'filters1': 89, 'kernel_size1': 1, 'filters2': 40, 'kernel_size2': 2}. Best is trial 12 with value: 1820873.7497615467.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:41,737] Trial 24 finished with value: 0.4231696479397951 and parameters: {'learning_rate': 0.006551829516491733, 'batch_size': 64, 'epochs': 80, 'filters1': 103, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:48,815] Trial 25 finished with value: 4816.864906336066 and parameters: {'learning_rate': 0.006794731706585491, 'batch_size': 16, 'epochs': 64, 'filters1': 104, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:14:56,770] Trial 26 finished with value: 3871530196.4482884 and parameters: {'learning_rate': 0.006374593253801203, 'batch_size': 16, 'epochs': 62, 'filters1': 110, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 2}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:04,685] Trial 27 finished with value: 1049202163.692414 and parameters: {'learning_rate': 0.004127877467287583, 'batch_size': 16, 'epochs': 63, 'filters1': 117, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:09,898] Trial 28 finished with value: 996155.6290659758 and parameters: {'learning_rate': 0.001523050459361451, 'batch_size': 16, 'epochs': 103, 'filters1': 105, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:16,646] Trial 29 finished with value: 692520278.0599484 and parameters: {'learning_rate': 0.0008281053778432261, 'batch_size': 16, 'epochs': 51, 'filters1': 57, 'kernel_size1': 3, 'filters2': 21, 'kernel_size2': 2}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:24,707] Trial 30 finished with value: 17329.84565275734 and parameters: {'learning_rate': 0.0013898294305982302, 'batch_size': 16, 'epochs': 64, 'filters1': 122, 'kernel_size1': 1, 'filters2': 20, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:29,788] Trial 31 finished with value: 22.734009955758548 and parameters: {'learning_rate': 0.001358936478758917, 'batch_size': 16, 'epochs': 61, 'filters1': 108, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:37,188] Trial 32 finished with value: 498057.17946756043 and parameters: {'learning_rate': 0.000627996846388959, 'batch_size': 16, 'epochs': 64, 'filters1': 122, 'kernel_size1': 1, 'filters2': 19, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:42,946] Trial 33 finished with value: 16014.668290315332 and parameters: {'learning_rate': 0.0010850251317641847, 'batch_size': 16, 'epochs': 65, 'filters1': 111, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:49,974] Trial 34 finished with value: 11462099.629109746 and parameters: {'learning_rate': 0.00020576312991753984, 'batch_size': 16, 'epochs': 60, 'filters1': 112, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:15:56,235] Trial 35 finished with value: 60236656494.62931 and parameters: {'learning_rate': 0.0005710999551717878, 'batch_size': 16, 'epochs': 50, 'filters1': 106, 'kernel_size1': 2, 'filters2': 37, 'kernel_size2': 2}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:04,828] Trial 36 finished with value: 2769.486031881133 and parameters: {'learning_rate': 0.0010132303728442723, 'batch_size': 16, 'epochs': 77, 'filters1': 128, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:10,327] Trial 37 finished with value: 484249764.9241526 and parameters: {'learning_rate': 0.0021426968976205303, 'batch_size': 16, 'epochs': 80, 'filters1': 127, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:20,058] Trial 38 finished with value: 239205455966.30954 and parameters: {'learning_rate': 0.0001863377987335507, 'batch_size': 16, 'epochs': 76, 'filters1': 101, 'kernel_size1': 2, 'filters2': 27, 'kernel_size2': 2}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:32,963] Trial 39 finished with value: 408525069415.1733 and parameters: {'learning_rate': 0.00010811296914880117, 'batch_size': 16, 'epochs': 111, 'filters1': 120, 'kernel_size1': 3, 'filters2': 18, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:39,820] Trial 40 finished with value: 77418376503.05424 and parameters: {'learning_rate': 0.0003118994855692664, 'batch_size': 32, 'epochs': 70, 'filters1': 116, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:46,619] Trial 41 finished with value: 1703.4830957299562 and parameters: {'learning_rate': 0.0013834438063802382, 'batch_size': 16, 'epochs': 58, 'filters1': 128, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:50,624] Trial 42 finished with value: 18115.238769587915 and parameters: {'learning_rate': 0.0008961292635766163, 'batch_size': 16, 'epochs': 56, 'filters1': 122, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:16:56,414] Trial 43 finished with value: 760624.6908845676 and parameters: {'learning_rate': 0.0008021390321425043, 'batch_size': 16, 'epochs': 55, 'filters1': 123, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:01,241] Trial 44 finished with value: 931.1025214890731 and parameters: {'learning_rate': 0.0011032666883557664, 'batch_size': 16, 'epochs': 71, 'filters1': 128, 'kernel_size1': 1, 'filters2': 37, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:09,075] Trial 45 finished with value: 160462334.28221324 and parameters: {'learning_rate': 0.001222766071462726, 'batch_size': 32, 'epochs': 92, 'filters1': 128, 'kernel_size1': 1, 'filters2': 36, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:17,625] Trial 46 finished with value: 5346477599.531935 and parameters: {'learning_rate': 0.0004778896521076894, 'batch_size': 16, 'epochs': 200, 'filters1': 115, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 3}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:23,168] Trial 47 finished with value: 2366064.455262101 and parameters: {'learning_rate': 0.0020904664452306566, 'batch_size': 16, 'epochs': 84, 'filters1': 125, 'kernel_size1': 1, 'filters2': 35, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:28,582] Trial 48 finished with value: 223669.95622095867 and parameters: {'learning_rate': 0.0018860588608945149, 'batch_size': 16, 'epochs': 71, 'filters1': 118, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:33,020] Trial 49 finished with value: 21764969166.660786 and parameters: {'learning_rate': 0.0007115652786378357, 'batch_size': 32, 'epochs': 57, 'filters1': 40, 'kernel_size1': 1, 'filters2': 38, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:40,160] Trial 50 finished with value: 106081.03601624885 and parameters: {'learning_rate': 0.0011721206742291977, 'batch_size': 16, 'epochs': 139, 'filters1': 128, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:47,625] Trial 51 finished with value: 773.7602515154174 and parameters: {'learning_rate': 0.000979881373619076, 'batch_size': 16, 'epochs': 69, 'filters1': 94, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:17:55,293] Trial 52 finished with value: 3822020.330513725 and parameters: {'learning_rate': 0.0010173852381371573, 'batch_size': 16, 'epochs': 70, 'filters1': 95, 'kernel_size1': 1, 'filters2': 34, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:03,029] Trial 53 finished with value: 322.79759590106676 and parameters: {'learning_rate': 0.0005310424941348418, 'batch_size': 16, 'epochs': 79, 'filters1': 93, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:09,401] Trial 54 finished with value: 5847.8789672284265 and parameters: {'learning_rate': 0.0005015875407071745, 'batch_size': 16, 'epochs': 94, 'filters1': 90, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:18,420] Trial 55 finished with value: 679896881.4596884 and parameters: {'learning_rate': 0.00036485072722743756, 'batch_size': 16, 'epochs': 86, 'filters1': 81, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:31,419] Trial 56 finished with value: 28980.27398535483 and parameters: {'learning_rate': 0.0002839107141536474, 'batch_size': 16, 'epochs': 155, 'filters1': 91, 'kernel_size1': 1, 'filters2': 43, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:37,948] Trial 57 finished with value: 464026553030.7997 and parameters: {'learning_rate': 0.0013000481448702968, 'batch_size': 32, 'epochs': 82, 'filters1': 93, 'kernel_size1': 2, 'filters2': 37, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:43,731] Trial 58 finished with value: 49992.47656574965 and parameters: {'learning_rate': 0.002705228032045954, 'batch_size': 16, 'epochs': 68, 'filters1': 100, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:52,147] Trial 59 finished with value: 67578983648.30786 and parameters: {'learning_rate': 0.0007072993996466671, 'batch_size': 64, 'epochs': 123, 'filters1': 82, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 3}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:18:58,944] Trial 60 finished with value: 401164.3801328355 and parameters: {'learning_rate': 0.0032123633635431866, 'batch_size': 16, 'epochs': 57, 'filters1': 107, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:04,955] Trial 61 finished with value: 76922.29462304557 and parameters: {'learning_rate': 0.0009277434723150273, 'batch_size': 16, 'epochs': 76, 'filters1': 113, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:13,013] Trial 62 finished with value: 2764111.8840518687 and parameters: {'learning_rate': 0.0016147963641818545, 'batch_size': 16, 'epochs': 78, 'filters1': 75, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:17,027] Trial 63 finished with value: 6887787.634773118 and parameters: {'learning_rate': 0.0005550161054838147, 'batch_size': 16, 'epochs': 88, 'filters1': 103, 'kernel_size1': 1, 'filters2': 35, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:21,408] Trial 64 finished with value: 51605.20004150792 and parameters: {'learning_rate': 0.0007797969782961796, 'batch_size': 16, 'epochs': 74, 'filters1': 98, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:26,536] Trial 65 finished with value: 1244764516.5006778 and parameters: {'learning_rate': 0.0018267955506228604, 'batch_size': 16, 'epochs': 59, 'filters1': 125, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:31,360] Trial 66 finished with value: 41505920307.43772 and parameters: {'learning_rate': 0.001097398810724606, 'batch_size': 64, 'epochs': 68, 'filters1': 108, 'kernel_size1': 1, 'filters2': 39, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:35,440] Trial 67 finished with value: 3583692.3692433788 and parameters: {'learning_rate': 0.0014250705733846235, 'batch_size': 16, 'epochs': 96, 'filters1': 84, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:44,396] Trial 68 finished with value: 9327590.265105711 and parameters: {'learning_rate': 0.0006300580761225162, 'batch_size': 16, 'epochs': 102, 'filters1': 120, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:48,872] Trial 69 finished with value: 152441157452.06717 and parameters: {'learning_rate': 0.0009137093351971544, 'batch_size': 64, 'epochs': 53, 'filters1': 96, 'kernel_size1': 1, 'filters2': 42, 'kernel_size2': 2}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:19:58,568] Trial 70 finished with value: 207067650094.8669 and parameters: {'learning_rate': 0.00041324486945079186, 'batch_size': 16, 'epochs': 79, 'filters1': 92, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:06,181] Trial 71 finished with value: 16149.05377649472 and parameters: {'learning_rate': 0.007205419149296116, 'batch_size': 16, 'epochs': 65, 'filters1': 102, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:13,011] Trial 72 finished with value: 907052326.2676356 and parameters: {'learning_rate': 0.004573677084763171, 'batch_size': 16, 'epochs': 60, 'filters1': 104, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:15,809] Trial 73 finished with value: 117640354.27955306 and parameters: {'learning_rate': 0.005031260034028826, 'batch_size': 16, 'epochs': 66, 'filters1': 111, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:21,983] Trial 74 finished with value: 1177221.532037386 and parameters: {'learning_rate': 0.006224190623839929, 'batch_size': 16, 'epochs': 50, 'filters1': 87, 'kernel_size1': 1, 'filters2': 51, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:27,186] Trial 75 finished with value: 30277.16296266137 and parameters: {'learning_rate': 0.0034985204638873823, 'batch_size': 16, 'epochs': 76, 'filters1': 125, 'kernel_size1': 1, 'filters2': 35, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:31,944] Trial 76 finished with value: 5262955066.866147 and parameters: {'learning_rate': 0.001303885039552348, 'batch_size': 64, 'epochs': 73, 'filters1': 98, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:38,792] Trial 77 finished with value: 26913583.401060913 and parameters: {'learning_rate': 0.0010182144501787531, 'batch_size': 16, 'epochs': 61, 'filters1': 119, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:45,725] Trial 78 finished with value: 48617113852.81613 and parameters: {'learning_rate': 0.0075485993794743855, 'batch_size': 32, 'epochs': 83, 'filters1': 114, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 2}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:49,804] Trial 79 finished with value: 30653741618.902504 and parameters: {'learning_rate': 0.00843197423411906, 'batch_size': 16, 'epochs': 90, 'filters1': 109, 'kernel_size1': 3, 'filters2': 37, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:20:57,662] Trial 80 finished with value: 7180996.099803328 and parameters: {'learning_rate': 0.0014418481666890776, 'batch_size': 16, 'epochs': 68, 'filters1': 123, 'kernel_size1': 1, 'filters2': 58, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:08,044] Trial 81 finished with value: 913892329.1549999 and parameters: {'learning_rate': 0.0004747648126228993, 'batch_size': 16, 'epochs': 96, 'filters1': 91, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:11,268] Trial 82 finished with value: 374465.10890286893 and parameters: {'learning_rate': 0.0005496574657431358, 'batch_size': 16, 'epochs': 92, 'filters1': 93, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:20,065] Trial 83 finished with value: 6761.479987177928 and parameters: {'learning_rate': 0.0003208245432630847, 'batch_size': 16, 'epochs': 81, 'filters1': 77, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:24,399] Trial 84 finished with value: 1543938.0553966311 and parameters: {'learning_rate': 0.0018702726904579942, 'batch_size': 16, 'epochs': 73, 'filters1': 90, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:31,726] Trial 85 finished with value: 95469298.72547443 and parameters: {'learning_rate': 0.00024039476022211456, 'batch_size': 16, 'epochs': 63, 'filters1': 101, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:37,480] Trial 86 finished with value: 2176535603.628221 and parameters: {'learning_rate': 0.0007758247548883227, 'batch_size': 64, 'epochs': 109, 'filters1': 86, 'kernel_size1': 1, 'filters2': 20, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:43,585] Trial 87 finished with value: 884656.7493311798 and parameters: {'learning_rate': 0.0005169512587017269, 'batch_size': 16, 'epochs': 54, 'filters1': 97, 'kernel_size1': 1, 'filters2': 16, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:51,836] Trial 88 finished with value: 300424.45696378814 and parameters: {'learning_rate': 0.0024468269170056576, 'batch_size': 16, 'epochs': 85, 'filters1': 106, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:21:55,732] Trial 89 finished with value: 346043.91617307323 and parameters: {'learning_rate': 0.0006534791583526565, 'batch_size': 16, 'epochs': 68, 'filters1': 95, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:02,230] Trial 90 finished with value: 4071761.727287856 and parameters: {'learning_rate': 0.000407734782119252, 'batch_size': 32, 'epochs': 78, 'filters1': 116, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:09,522] Trial 91 finished with value: 2889.4186685479012 and parameters: {'learning_rate': 0.00032145482802490476, 'batch_size': 16, 'epochs': 81, 'filters1': 72, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:17,476] Trial 92 finished with value: 315611401.27081466 and parameters: {'learning_rate': 0.0002340529094480796, 'batch_size': 16, 'epochs': 71, 'filters1': 72, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:26,542] Trial 93 finished with value: 81097.38129750006 and parameters: {'learning_rate': 0.0001785000216332425, 'batch_size': 16, 'epochs': 87, 'filters1': 68, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:31,831] Trial 94 finished with value: 93855.54280675283 and parameters: {'learning_rate': 0.0011861860345233983, 'batch_size': 16, 'epochs': 76, 'filters1': 79, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:38,623] Trial 95 finished with value: 309185391627.29376 and parameters: {'learning_rate': 0.0002963623772063871, 'batch_size': 16, 'epochs': 60, 'filters1': 60, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:45,048] Trial 96 finished with value: 93908.84020794662 and parameters: {'learning_rate': 0.0008524205015290348, 'batch_size': 16, 'epochs': 93, 'filters1': 83, 'kernel_size1': 1, 'filters2': 20, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:50,880] Trial 97 finished with value: 18795805957.662083 and parameters: {'learning_rate': 0.0002741754617612722, 'batch_size': 64, 'epochs': 82, 'filters1': 126, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:22:58,048] Trial 98 finished with value: 343.8495730277794 and parameters: {'learning_rate': 0.00033406039626088447, 'batch_size': 16, 'epochs': 173, 'filters1': 68, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 21:23:05,626] Trial 99 finished with value: 1063872.1740824347 and parameters: {'learning_rate': 0.00035115891122425915, 'batch_size': 16, 'epochs': 183, 'filters1': 65, 'kernel_size1': 1, 'filters2': 34, 'kernel_size2': 1}. Best is trial 24 with value: 0.4231696479397951.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.006551829516491733, 'batch_size': 64, 'epochs': 80, 'filters1': 103, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 1}\n",
      "Best validation MSE: 0.4231696479397951\n",
      "Epoch 1/80\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 7486925787103232.0000 - val_loss: 7560698527744.0000\n",
      "Epoch 2/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1649248436224.0000 - val_loss: 33606264832.0000\n",
      "Epoch 3/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 20957669376.0000 - val_loss: 454593920.0000\n",
      "Epoch 4/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 35429076.0000 - val_loss: 0.4183\n",
      "Epoch 5/80\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4306 - val_loss: 0.4184\n",
      "Epoch 6/80\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4307 - val_loss: 0.4184\n",
      "Epoch 7/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 8/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 9/80\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 10/80\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 11/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 12/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 13/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "Epoch 14/80\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4308 - val_loss: 0.4184\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "MSE   : 0.4182887019358751\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "MSE   : 0.4934531669748255\n"
     ]
    }
   ],
   "source": [
    "CNN_testing = CNN_testing(normalizes_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11ec16e8-ac57-44b8-8e12-247689d16bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:10,897] A new study created in memory with name: no-name-8e84f513-b1c0-4ed7-b937-2a26d7427d56\n",
      "[I 2025-08-13 00:12:17,000] Trial 0 finished with value: 0.3476916253566742 and parameters: {'filters1': 41, 'kernel_size1': 1, 'filters2': 60, 'kernel_size2': 3, 'learning_rate': 0.00010221032405367038, 'batch_size': 64, 'epochs': 114}. Best is trial 0 with value: 0.3476916253566742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3476916253566742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:18,661] Trial 1 finished with value: 0.3715202510356903 and parameters: {'filters1': 41, 'kernel_size1': 1, 'filters2': 51, 'kernel_size2': 1, 'learning_rate': 0.000690298095893969, 'batch_size': 32, 'epochs': 123}. Best is trial 0 with value: 0.3476916253566742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3715202510356903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:20,701] Trial 2 finished with value: 0.40721672773361206 and parameters: {'filters1': 113, 'kernel_size1': 3, 'filters2': 61, 'kernel_size2': 2, 'learning_rate': 0.0006344637617932413, 'batch_size': 32, 'epochs': 95}. Best is trial 0 with value: 0.3476916253566742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.40721672773361206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:27,782] Trial 3 finished with value: 0.2893724739551544 and parameters: {'filters1': 92, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0014953050086010577, 'batch_size': 32, 'epochs': 129}. Best is trial 3 with value: 0.2893724739551544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2893724739551544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:32,054] Trial 4 finished with value: 0.33104023337364197 and parameters: {'filters1': 99, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 1, 'learning_rate': 0.0015612017014515003, 'batch_size': 16, 'epochs': 142}. Best is trial 3 with value: 0.2893724739551544.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33104023337364197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:33,746] Trial 5 finished with value: 0.2836848497390747 and parameters: {'filters1': 84, 'kernel_size1': 3, 'filters2': 27, 'kernel_size2': 2, 'learning_rate': 0.005193031122362324, 'batch_size': 64, 'epochs': 95}. Best is trial 5 with value: 0.2836848497390747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2836848497390747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:39,585] Trial 6 finished with value: 0.32996517419815063 and parameters: {'filters1': 114, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 1, 'learning_rate': 0.0004431470007203688, 'batch_size': 16, 'epochs': 84}. Best is trial 5 with value: 0.2836848497390747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32996517419815063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:43,385] Trial 7 finished with value: 0.9137079119682312 and parameters: {'filters1': 117, 'kernel_size1': 1, 'filters2': 54, 'kernel_size2': 2, 'learning_rate': 0.0011549440246373327, 'batch_size': 32, 'epochs': 151}. Best is trial 5 with value: 0.2836848497390747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.9137079119682312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:48,429] Trial 8 finished with value: 0.2876967191696167 and parameters: {'filters1': 119, 'kernel_size1': 3, 'filters2': 35, 'kernel_size2': 3, 'learning_rate': 0.0027858871122827308, 'batch_size': 32, 'epochs': 190}. Best is trial 5 with value: 0.2836848497390747.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2876967191696167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:50,209] Trial 9 finished with value: 0.2773701846599579 and parameters: {'filters1': 115, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.0026229707567491304, 'batch_size': 32, 'epochs': 115}. Best is trial 9 with value: 0.2773701846599579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2773701846599579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:52,407] Trial 10 finished with value: 0.3125908076763153 and parameters: {'filters1': 63, 'kernel_size1': 2, 'filters2': 44, 'kernel_size2': 3, 'learning_rate': 0.007848292053220927, 'batch_size': 16, 'epochs': 57}. Best is trial 9 with value: 0.2773701846599579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3125908076763153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:55,194] Trial 11 finished with value: 0.29245272278785706 and parameters: {'filters1': 75, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 2, 'learning_rate': 0.006211631091601242, 'batch_size': 64, 'epochs': 69}. Best is trial 9 with value: 0.2773701846599579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29245272278785706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:12:58,034] Trial 12 finished with value: 0.26897311210632324 and parameters: {'filters1': 67, 'kernel_size1': 3, 'filters2': 27, 'kernel_size2': 2, 'learning_rate': 0.0037653023928476, 'batch_size': 64, 'epochs': 98}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.26897311210632324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:00,652] Trial 13 finished with value: 0.28036245703697205 and parameters: {'filters1': 63, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0029436789902766818, 'batch_size': 64, 'epochs': 165}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28036245703697205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:03,470] Trial 14 finished with value: 0.3375079035758972 and parameters: {'filters1': 58, 'kernel_size1': 3, 'filters2': 28, 'kernel_size2': 3, 'learning_rate': 0.0029946724450818922, 'batch_size': 64, 'epochs': 108}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3375079035758972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:09,791] Trial 15 finished with value: 0.2890573740005493 and parameters: {'filters1': 128, 'kernel_size1': 2, 'filters2': 38, 'kernel_size2': 1, 'learning_rate': 0.00019716093305154078, 'batch_size': 32, 'epochs': 78}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2890573740005493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:11,725] Trial 16 finished with value: 0.2816130518913269 and parameters: {'filters1': 102, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0043121867339734506, 'batch_size': 64, 'epochs': 100}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2816130518913269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:14,261] Trial 17 finished with value: 0.3123210072517395 and parameters: {'filters1': 75, 'kernel_size1': 3, 'filters2': 44, 'kernel_size2': 3, 'learning_rate': 0.001972006045403391, 'batch_size': 64, 'epochs': 168}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3123210072517395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:17,724] Trial 18 finished with value: 0.30991843342781067 and parameters: {'filters1': 53, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 1, 'learning_rate': 0.009194681488292588, 'batch_size': 32, 'epochs': 56}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30991843342781067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:21,015] Trial 19 finished with value: 0.27920225262641907 and parameters: {'filters1': 84, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.004445465169567978, 'batch_size': 16, 'epochs': 132}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.27920225262641907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:24,647] Trial 20 finished with value: 0.3182685375213623 and parameters: {'filters1': 102, 'kernel_size1': 3, 'filters2': 33, 'kernel_size2': 2, 'learning_rate': 0.002214200797970968, 'batch_size': 64, 'epochs': 116}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3182685375213623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:27,056] Trial 21 finished with value: 0.2833917438983917 and parameters: {'filters1': 82, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0041012707106244115, 'batch_size': 16, 'epochs': 133}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2833917438983917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:29,247] Trial 22 finished with value: 0.30461499094963074 and parameters: {'filters1': 70, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.00394285072870737, 'batch_size': 16, 'epochs': 150}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30461499094963074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:32,271] Trial 23 finished with value: 0.28576672077178955 and parameters: {'filters1': 92, 'kernel_size1': 3, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.006810413939915227, 'batch_size': 16, 'epochs': 105}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28576672077178955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:34,540] Trial 24 finished with value: 0.3211703300476074 and parameters: {'filters1': 49, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.0009830615622293231, 'batch_size': 16, 'epochs': 83}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3211703300476074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:39,200] Trial 25 finished with value: 0.28503522276878357 and parameters: {'filters1': 91, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 2, 'learning_rate': 0.0022084557929655814, 'batch_size': 16, 'epochs': 137}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28503522276878357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:40,980] Trial 26 finished with value: 0.31331270933151245 and parameters: {'filters1': 69, 'kernel_size1': 3, 'filters2': 19, 'kernel_size2': 1, 'learning_rate': 0.009396928655482781, 'batch_size': 32, 'epochs': 118}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31331270933151245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:42,936] Trial 27 finished with value: 0.2882276773452759 and parameters: {'filters1': 86, 'kernel_size1': 2, 'filters2': 25, 'kernel_size2': 3, 'learning_rate': 0.003563443579707821, 'batch_size': 32, 'epochs': 170}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2882276773452759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:45,088] Trial 28 finished with value: 0.2931746542453766 and parameters: {'filters1': 109, 'kernel_size1': 1, 'filters2': 40, 'kernel_size2': 2, 'learning_rate': 0.005235118706446481, 'batch_size': 16, 'epochs': 89}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2931746542453766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:46,954] Trial 29 finished with value: 0.29522448778152466 and parameters: {'filters1': 125, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 3, 'learning_rate': 0.0002837683935048382, 'batch_size': 64, 'epochs': 111}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29522448778152466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:51,649] Trial 30 finished with value: 0.5267054438591003 and parameters: {'filters1': 42, 'kernel_size1': 3, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.00011999305539354723, 'batch_size': 64, 'epochs': 73}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5267054438591003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:53,599] Trial 31 finished with value: 0.27897658944129944 and parameters: {'filters1': 62, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.002840178518525707, 'batch_size': 64, 'epochs': 171}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.27897658944129944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:56,380] Trial 32 finished with value: 0.2841390073299408 and parameters: {'filters1': 49, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 2, 'learning_rate': 0.0016886937868847995, 'batch_size': 64, 'epochs': 200}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2841390073299408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:13:58,115] Trial 33 finished with value: 0.30044856667518616 and parameters: {'filters1': 58, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 2, 'learning_rate': 0.0010673808196456087, 'batch_size': 64, 'epochs': 124}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30044856667518616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:01,675] Trial 34 finished with value: 0.35395896434783936 and parameters: {'filters1': 76, 'kernel_size1': 1, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0028517023167898502, 'batch_size': 64, 'epochs': 179}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.35395896434783936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:05,077] Trial 35 finished with value: 0.3257363736629486 and parameters: {'filters1': 71, 'kernel_size1': 2, 'filters2': 57, 'kernel_size2': 1, 'learning_rate': 0.00525319061234628, 'batch_size': 32, 'epochs': 148}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3257363736629486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:10,706] Trial 36 finished with value: 0.3841588497161865 and parameters: {'filters1': 36, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.0007156584032983547, 'batch_size': 64, 'epochs': 157}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3841588497161865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:12,797] Trial 37 finished with value: 0.2943841516971588 and parameters: {'filters1': 63, 'kernel_size1': 3, 'filters2': 26, 'kernel_size2': 2, 'learning_rate': 0.0012603721604963509, 'batch_size': 32, 'epochs': 122}. Best is trial 12 with value: 0.26897311210632324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2943841516971588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:15,537] Trial 38 finished with value: 0.26578882336616516 and parameters: {'filters1': 32, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.0008030913285079462, 'batch_size': 16, 'epochs': 98}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.26578882336616516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:18,120] Trial 39 finished with value: 0.41972240805625916 and parameters: {'filters1': 34, 'kernel_size1': 1, 'filters2': 19, 'kernel_size2': 1, 'learning_rate': 0.000510965992559604, 'batch_size': 32, 'epochs': 93}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41972240805625916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:20,573] Trial 40 finished with value: 0.30505993962287903 and parameters: {'filters1': 44, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.0008231231329154869, 'batch_size': 64, 'epochs': 100}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30505993962287903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:28,141] Trial 41 finished with value: 0.2981599271297455 and parameters: {'filters1': 110, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.0014441146686654243, 'batch_size': 16, 'epochs': 104}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2981599271297455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:30,140] Trial 42 finished with value: 0.29809561371803284 and parameters: {'filters1': 97, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.0021960308347707624, 'batch_size': 16, 'epochs': 130}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29809561371803284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:32,275] Trial 43 finished with value: 0.3119199573993683 and parameters: {'filters1': 88, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.0003975088204921708, 'batch_size': 16, 'epochs': 66}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3119199573993683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:36,413] Trial 44 finished with value: 0.2804242968559265 and parameters: {'filters1': 66, 'kernel_size1': 2, 'filters2': 63, 'kernel_size2': 2, 'learning_rate': 0.0034605736964594697, 'batch_size': 16, 'epochs': 142}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2804242968559265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:38,834] Trial 45 finished with value: 0.28317952156066895 and parameters: {'filters1': 57, 'kernel_size1': 2, 'filters2': 27, 'kernel_size2': 2, 'learning_rate': 0.006066389019739963, 'batch_size': 16, 'epochs': 180}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28317952156066895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:40,964] Trial 46 finished with value: 0.30048009753227234 and parameters: {'filters1': 80, 'kernel_size1': 3, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.0018570145761704832, 'batch_size': 16, 'epochs': 92}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30048009753227234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:48,289] Trial 47 finished with value: 0.339506059885025 and parameters: {'filters1': 49, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0008614317582400601, 'batch_size': 32, 'epochs': 113}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.339506059885025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:51,003] Trial 48 finished with value: 0.3048158884048462 and parameters: {'filters1': 77, 'kernel_size1': 2, 'filters2': 49, 'kernel_size2': 2, 'learning_rate': 0.0025645034288786315, 'batch_size': 64, 'epochs': 158}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3048158884048462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:14:54,321] Trial 49 finished with value: 0.3118961751461029 and parameters: {'filters1': 32, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 2, 'learning_rate': 0.004605974118072161, 'batch_size': 64, 'epochs': 82}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3118961751461029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:02,094] Trial 50 finished with value: 0.3359593451023102 and parameters: {'filters1': 97, 'kernel_size1': 3, 'filters2': 36, 'kernel_size2': 2, 'learning_rate': 0.0005887347170876158, 'batch_size': 32, 'epochs': 96}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3359593451023102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:03,532] Trial 51 finished with value: 0.29558905959129333 and parameters: {'filters1': 61, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.00314712105839914, 'batch_size': 64, 'epochs': 168}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29558905959129333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:05,253] Trial 52 finished with value: 0.31375259160995483 and parameters: {'filters1': 54, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0026405177696669367, 'batch_size': 64, 'epochs': 178}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31375259160995483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:07,163] Trial 53 finished with value: 0.2860307991504669 and parameters: {'filters1': 67, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.004786375955973483, 'batch_size': 64, 'epochs': 189}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2860307991504669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:09,696] Trial 54 finished with value: 0.2944484353065491 and parameters: {'filters1': 121, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.00731804522294077, 'batch_size': 64, 'epochs': 156}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2944484353065491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:12,057] Trial 55 finished with value: 0.3066225051879883 and parameters: {'filters1': 38, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.003876413606923048, 'batch_size': 16, 'epochs': 163}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3066225051879883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:17,553] Trial 56 finished with value: 0.28062188625335693 and parameters: {'filters1': 71, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 2, 'learning_rate': 0.002451498715820501, 'batch_size': 64, 'epochs': 142}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28062188625335693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:22,829] Trial 57 finished with value: 0.3528842329978943 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 26, 'kernel_size2': 1, 'learning_rate': 0.0013664154520112966, 'batch_size': 16, 'epochs': 118}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3528842329978943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:28,417] Trial 58 finished with value: 0.2950361371040344 and parameters: {'filters1': 62, 'kernel_size1': 3, 'filters2': 23, 'kernel_size2': 2, 'learning_rate': 0.003278740846226486, 'batch_size': 64, 'epochs': 108}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2950361371040344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:30,589] Trial 59 finished with value: 0.3274468779563904 and parameters: {'filters1': 79, 'kernel_size1': 2, 'filters2': 28, 'kernel_size2': 2, 'learning_rate': 0.0016858926183176833, 'batch_size': 32, 'epochs': 102}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3274468779563904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:32,729] Trial 60 finished with value: 0.3058854639530182 and parameters: {'filters1': 46, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 3, 'learning_rate': 0.00597789662520479, 'batch_size': 16, 'epochs': 88}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3058854639530182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:36,616] Trial 61 finished with value: 0.28885677456855774 and parameters: {'filters1': 66, 'kernel_size1': 2, 'filters2': 46, 'kernel_size2': 2, 'learning_rate': 0.0035184152826173284, 'batch_size': 16, 'epochs': 136}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28885677456855774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:41,972] Trial 62 finished with value: 0.27654656767845154 and parameters: {'filters1': 65, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 2, 'learning_rate': 0.004355051151738561, 'batch_size': 16, 'epochs': 143}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.27654656767845154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:44,579] Trial 63 finished with value: 0.32583945989608765 and parameters: {'filters1': 54, 'kernel_size1': 2, 'filters2': 54, 'kernel_size2': 2, 'learning_rate': 0.004231214403403064, 'batch_size': 16, 'epochs': 128}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32583945989608765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:47,098] Trial 64 finished with value: 0.28339141607284546 and parameters: {'filters1': 73, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 2, 'learning_rate': 0.0020223781782910317, 'batch_size': 16, 'epochs': 146}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28339141607284546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:49,719] Trial 65 finished with value: 0.2912358343601227 and parameters: {'filters1': 59, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 2, 'learning_rate': 0.00810513653861533, 'batch_size': 16, 'epochs': 186}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2912358343601227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:51,865] Trial 66 finished with value: 0.28158825635910034 and parameters: {'filters1': 83, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 2, 'learning_rate': 0.005357097170698609, 'batch_size': 64, 'epochs': 174}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28158825635910034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:54,634] Trial 67 finished with value: 0.2953353524208069 and parameters: {'filters1': 52, 'kernel_size1': 3, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.00305042327886889, 'batch_size': 32, 'epochs': 164}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2953353524208069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:15:58,215] Trial 68 finished with value: 0.32005393505096436 and parameters: {'filters1': 65, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0038985482362266797, 'batch_size': 64, 'epochs': 122}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32005393505096436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:03,370] Trial 69 finished with value: 0.28276923298835754 and parameters: {'filters1': 73, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.0023677393194351014, 'batch_size': 16, 'epochs': 137}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28276923298835754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:05,498] Trial 70 finished with value: 0.2971786856651306 and parameters: {'filters1': 91, 'kernel_size1': 1, 'filters2': 51, 'kernel_size2': 2, 'learning_rate': 0.004587350803641498, 'batch_size': 64, 'epochs': 198}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2971786856651306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:08,626] Trial 71 finished with value: 0.2989530563354492 and parameters: {'filters1': 67, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 2, 'learning_rate': 0.003525086581344796, 'batch_size': 16, 'epochs': 142}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2989530563354492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:11,217] Trial 72 finished with value: 0.29290279746055603 and parameters: {'filters1': 64, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 2, 'learning_rate': 0.0027148919075190014, 'batch_size': 16, 'epochs': 152}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29290279746055603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:14,373] Trial 73 finished with value: 0.28112855553627014 and parameters: {'filters1': 56, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 2, 'learning_rate': 0.006311438673907766, 'batch_size': 16, 'epochs': 132}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28112855553627014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:18,879] Trial 74 finished with value: 0.27071407437324524 and parameters: {'filters1': 69, 'kernel_size1': 2, 'filters2': 56, 'kernel_size2': 2, 'learning_rate': 0.003096780766149969, 'batch_size': 16, 'epochs': 144}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.27071407437324524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:22,598] Trial 75 finished with value: 0.29399335384368896 and parameters: {'filters1': 60, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 2, 'learning_rate': 0.0029048419696767625, 'batch_size': 16, 'epochs': 109}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29399335384368896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:27,863] Trial 76 finished with value: 0.2830770015716553 and parameters: {'filters1': 86, 'kernel_size1': 2, 'filters2': 58, 'kernel_size2': 2, 'learning_rate': 0.005383621582874892, 'batch_size': 16, 'epochs': 97}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2830770015716553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:30,704] Trial 77 finished with value: 0.3116515874862671 and parameters: {'filters1': 117, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 2, 'learning_rate': 0.0019188186183966254, 'batch_size': 32, 'epochs': 162}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3116515874862671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:32,777] Trial 78 finished with value: 0.290457159280777 and parameters: {'filters1': 69, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 2, 'learning_rate': 0.001224146865654418, 'batch_size': 16, 'epochs': 125}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.290457159280777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:42,460] Trial 79 finished with value: 1.0263468027114868 and parameters: {'filters1': 75, 'kernel_size1': 2, 'filters2': 55, 'kernel_size2': 2, 'learning_rate': 0.0003583001234921317, 'batch_size': 64, 'epochs': 145}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 1.0263468027114868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:52,541] Trial 80 finished with value: 0.27668625116348267 and parameters: {'filters1': 128, 'kernel_size1': 3, 'filters2': 42, 'kernel_size2': 2, 'learning_rate': 0.0009238529061794233, 'batch_size': 32, 'epochs': 137}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.27668625116348267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:16:54,532] Trial 81 finished with value: 0.2838597893714905 and parameters: {'filters1': 123, 'kernel_size1': 3, 'filters2': 42, 'kernel_size2': 2, 'learning_rate': 0.0008761570241784183, 'batch_size': 32, 'epochs': 152}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2838597893714905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:02,568] Trial 82 finished with value: 0.3297703266143799 and parameters: {'filters1': 128, 'kernel_size1': 3, 'filters2': 37, 'kernel_size2': 2, 'learning_rate': 0.0009636182491424882, 'batch_size': 32, 'epochs': 135}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3297703266143799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:05,888] Trial 83 finished with value: 0.29784759879112244 and parameters: {'filters1': 69, 'kernel_size1': 3, 'filters2': 44, 'kernel_size2': 2, 'learning_rate': 0.0015918535503356651, 'batch_size': 32, 'epochs': 139}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29784759879112244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:09,334] Trial 84 finished with value: 0.4190167188644409 and parameters: {'filters1': 115, 'kernel_size1': 3, 'filters2': 61, 'kernel_size2': 2, 'learning_rate': 0.00110953238085202, 'batch_size': 32, 'epochs': 174}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4190167188644409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:12,429] Trial 85 finished with value: 0.3516802489757538 and parameters: {'filters1': 113, 'kernel_size1': 3, 'filters2': 48, 'kernel_size2': 2, 'learning_rate': 0.0007137255967516122, 'batch_size': 32, 'epochs': 118}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3516802489757538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:15,220] Trial 86 finished with value: 0.38591381907463074 and parameters: {'filters1': 110, 'kernel_size1': 3, 'filters2': 34, 'kernel_size2': 2, 'learning_rate': 0.0005016495264749834, 'batch_size': 64, 'epochs': 127}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.38591381907463074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:20,583] Trial 87 finished with value: 0.28321361541748047 and parameters: {'filters1': 125, 'kernel_size1': 2, 'filters2': 56, 'kernel_size2': 2, 'learning_rate': 0.003940317726170698, 'batch_size': 16, 'epochs': 131}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28321361541748047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:23,973] Trial 88 finished with value: 0.30556628108024597 and parameters: {'filters1': 102, 'kernel_size1': 2, 'filters2': 53, 'kernel_size2': 2, 'learning_rate': 0.0006385504248913595, 'batch_size': 64, 'epochs': 114}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30556628108024597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:26,151] Trial 89 finished with value: 0.2803783118724823 and parameters: {'filters1': 72, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0007849755861684049, 'batch_size': 32, 'epochs': 121}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2803783118724823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:31,529] Trial 90 finished with value: 0.3848893940448761 and parameters: {'filters1': 95, 'kernel_size1': 1, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.0023006504202469167, 'batch_size': 16, 'epochs': 155}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3848893940448761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:34,056] Trial 91 finished with value: 0.288635790348053 and parameters: {'filters1': 72, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0009608600194227963, 'batch_size': 32, 'epochs': 120}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.288635790348053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:39,557] Trial 92 finished with value: 0.30751195549964905 and parameters: {'filters1': 78, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 2, 'learning_rate': 0.0007850759121520871, 'batch_size': 32, 'epochs': 106}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30751195549964905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:44,673] Trial 93 finished with value: 0.27592843770980835 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 2, 'learning_rate': 0.0005498634344876546, 'batch_size': 32, 'epochs': 112}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.27592843770980835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:47,412] Trial 94 finished with value: 0.2969360053539276 and parameters: {'filters1': 118, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.000596601442670445, 'batch_size': 32, 'epochs': 91}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2969360053539276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:50,398] Trial 95 finished with value: 0.2947852611541748 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.0005251016649805066, 'batch_size': 32, 'epochs': 112}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2947852611541748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:17:52,414] Trial 96 finished with value: 0.283734530210495 and parameters: {'filters1': 120, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.0032806466859804147, 'batch_size': 64, 'epochs': 160}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.283734530210495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:04,767] Trial 97 finished with value: 0.37950581312179565 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 2, 'learning_rate': 0.000443585887147256, 'batch_size': 16, 'epochs': 99}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.37950581312179565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:07,858] Trial 98 finished with value: 0.2858158349990845 and parameters: {'filters1': 115, 'kernel_size1': 3, 'filters2': 25, 'kernel_size2': 2, 'learning_rate': 0.00026474796735369565, 'batch_size': 32, 'epochs': 103}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2858158349990845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:10,183] Trial 99 finished with value: 0.2876112759113312 and parameters: {'filters1': 81, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 2, 'learning_rate': 0.004570434236055729, 'batch_size': 64, 'epochs': 148}. Best is trial 38 with value: 0.26578882336616516.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2876112759113312\n",
      "Best Trial:\n",
      "  Value: 0.26578882336616516\n",
      "  Params: \n",
      "    filters1: 32\n",
      "    kernel_size1: 2\n",
      "    filters2: 18\n",
      "    kernel_size2: 2\n",
      "    learning_rate: 0.0008030913285079462\n",
      "    batch_size: 16\n",
      "    epochs: 98\n",
      "Epoch 1/98\n",
      "60/60 [==============================] - 1s 3ms/step - loss: 226.3690 - val_loss: 0.3925\n",
      "Epoch 2/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7109 - val_loss: 0.4841\n",
      "Epoch 3/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.3843\n",
      "Epoch 4/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4007\n",
      "Epoch 5/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.4155\n",
      "Epoch 6/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5089 - val_loss: 0.4280\n",
      "Epoch 7/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4416\n",
      "Epoch 8/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.3748\n",
      "Epoch 9/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5098 - val_loss: 0.3693\n",
      "Epoch 10/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.8075\n",
      "Epoch 11/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.3833\n",
      "Epoch 12/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.5924\n",
      "Epoch 13/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.3618\n",
      "Epoch 14/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5090 - val_loss: 0.6491\n",
      "Epoch 15/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.3557\n",
      "Epoch 16/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5586 - val_loss: 0.4855\n",
      "Epoch 17/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4182 - val_loss: 0.3874\n",
      "Epoch 18/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.4009\n",
      "Epoch 19/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5459 - val_loss: 0.8121\n",
      "Epoch 20/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5687 - val_loss: 1.5119\n",
      "Epoch 21/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5822 - val_loss: 0.9084\n",
      "Epoch 22/98\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.4674 - val_loss: 0.3511\n",
      "Epoch 23/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.3600\n",
      "Epoch 24/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4719\n",
      "Epoch 25/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5039 - val_loss: 0.8274\n",
      "Epoch 26/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5800 - val_loss: 0.4046\n",
      "Epoch 27/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.3774\n",
      "Epoch 28/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4450 - val_loss: 1.4424\n",
      "Epoch 29/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 0.3601\n",
      "Epoch 30/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.8096\n",
      "Epoch 31/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4808 - val_loss: 0.3284\n",
      "Epoch 32/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5895 - val_loss: 0.5121\n",
      "Epoch 33/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 0.3399\n",
      "Epoch 34/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5808 - val_loss: 0.8097\n",
      "Epoch 35/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4952 - val_loss: 0.5649\n",
      "Epoch 36/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5729 - val_loss: 0.3453\n",
      "Epoch 37/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.3426\n",
      "Epoch 38/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6060 - val_loss: 0.7824\n",
      "Epoch 39/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6702 - val_loss: 0.3188\n",
      "Epoch 40/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5812 - val_loss: 0.3256\n",
      "Epoch 41/98\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.5210 - val_loss: 0.8653\n",
      "Epoch 42/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6099 - val_loss: 0.3282\n",
      "Epoch 43/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6608 - val_loss: 0.3668\n",
      "Epoch 44/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.9932 - val_loss: 0.7902\n",
      "Epoch 45/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5535 - val_loss: 0.3214\n",
      "Epoch 46/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7218 - val_loss: 1.2600\n",
      "Epoch 47/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6716 - val_loss: 0.6922\n",
      "Epoch 48/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.7533\n",
      "Epoch 49/98\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.5770 - val_loss: 0.3357\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "MSE   : 0.3611728112331995\n"
     ]
    }
   ],
   "source": [
    "CNN_testing_2 = CNN_testing(normalizes_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f189f53-e0e6-4eb9-ba6f-9e59c475406a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:16,330] A new study created in memory with name: no-name-3e5198af-1181-461b-a7bb-60dc481e4e82\n",
      "[I 2025-08-13 00:18:20,743] Trial 0 finished with value: 0.8474814891815186 and parameters: {'filters1': 47, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 3, 'learning_rate': 0.002171307801024678, 'batch_size': 32, 'epochs': 54}. Best is trial 0 with value: 0.8474814891815186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.8474814891815186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:29,409] Trial 1 finished with value: 0.3415047824382782 and parameters: {'filters1': 34, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 2, 'learning_rate': 0.002399562367436846, 'batch_size': 64, 'epochs': 196}. Best is trial 1 with value: 0.3415047824382782.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3415047824382782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:31,557] Trial 2 finished with value: 0.3152078092098236 and parameters: {'filters1': 70, 'kernel_size1': 3, 'filters2': 49, 'kernel_size2': 3, 'learning_rate': 0.005909277288378838, 'batch_size': 16, 'epochs': 64}. Best is trial 2 with value: 0.3152078092098236.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3152078092098236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:34,872] Trial 3 finished with value: 0.3135947287082672 and parameters: {'filters1': 92, 'kernel_size1': 3, 'filters2': 35, 'kernel_size2': 1, 'learning_rate': 0.007701447623601588, 'batch_size': 64, 'epochs': 123}. Best is trial 3 with value: 0.3135947287082672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3135947287082672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:37,332] Trial 4 finished with value: 0.32389065623283386 and parameters: {'filters1': 100, 'kernel_size1': 2, 'filters2': 49, 'kernel_size2': 3, 'learning_rate': 0.00014579539352958457, 'batch_size': 16, 'epochs': 184}. Best is trial 3 with value: 0.3135947287082672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32389065623283386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:44,721] Trial 5 finished with value: 0.4936739206314087 and parameters: {'filters1': 35, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.0002662912529277781, 'batch_size': 16, 'epochs': 64}. Best is trial 3 with value: 0.3135947287082672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4936739206314087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:47,308] Trial 6 finished with value: 0.3010527193546295 and parameters: {'filters1': 64, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 3, 'learning_rate': 0.0017173142276505594, 'batch_size': 16, 'epochs': 171}. Best is trial 6 with value: 0.3010527193546295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3010527193546295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:18:56,733] Trial 7 finished with value: 0.39485132694244385 and parameters: {'filters1': 68, 'kernel_size1': 1, 'filters2': 46, 'kernel_size2': 2, 'learning_rate': 0.00023409397975659567, 'batch_size': 16, 'epochs': 86}. Best is trial 6 with value: 0.3010527193546295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.39485132694244385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:01,145] Trial 8 finished with value: 0.29279887676239014 and parameters: {'filters1': 121, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 3, 'learning_rate': 0.0027064799226127327, 'batch_size': 16, 'epochs': 143}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29279887676239014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:06,037] Trial 9 finished with value: 0.34167101979255676 and parameters: {'filters1': 115, 'kernel_size1': 1, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.002287678777031966, 'batch_size': 64, 'epochs': 102}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.34167101979255676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:16,523] Trial 10 finished with value: 0.31267884373664856 and parameters: {'filters1': 117, 'kernel_size1': 1, 'filters2': 35, 'kernel_size2': 1, 'learning_rate': 0.0006140699526414219, 'batch_size': 32, 'epochs': 156}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31267884373664856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:21,477] Trial 11 finished with value: 0.41311800479888916 and parameters: {'filters1': 62, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 3, 'learning_rate': 0.0009449223522036441, 'batch_size': 16, 'epochs': 157}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41311800479888916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:26,412] Trial 12 finished with value: 0.30177703499794006 and parameters: {'filters1': 127, 'kernel_size1': 2, 'filters2': 56, 'kernel_size2': 3, 'learning_rate': 0.003773302240357964, 'batch_size': 16, 'epochs': 152}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30177703499794006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:30,128] Trial 13 finished with value: 0.3325379192829132 and parameters: {'filters1': 87, 'kernel_size1': 3, 'filters2': 63, 'kernel_size2': 2, 'learning_rate': 0.001113530217389097, 'batch_size': 16, 'epochs': 130}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3325379192829132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:36,114] Trial 14 finished with value: 0.3052814304828644 and parameters: {'filters1': 54, 'kernel_size1': 2, 'filters2': 40, 'kernel_size2': 3, 'learning_rate': 0.0010866896767348436, 'batch_size': 16, 'epochs': 179}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3052814304828644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:38,143] Trial 15 finished with value: 0.29510298371315 and parameters: {'filters1': 79, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 2, 'learning_rate': 0.004039083441331334, 'batch_size': 32, 'epochs': 142}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29510298371315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:41,634] Trial 16 finished with value: 0.32022517919540405 and parameters: {'filters1': 100, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 1, 'learning_rate': 0.004350584973668112, 'batch_size': 32, 'epochs': 132}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32022517919540405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:43,976] Trial 17 finished with value: 0.30723467469215393 and parameters: {'filters1': 77, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 2, 'learning_rate': 0.009801455381424415, 'batch_size': 32, 'epochs': 110}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30723467469215393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:48,551] Trial 18 finished with value: 0.3174123764038086 and parameters: {'filters1': 106, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 2, 'learning_rate': 0.00047163345137362994, 'batch_size': 32, 'epochs': 141}. Best is trial 8 with value: 0.29279887676239014.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3174123764038086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:50,843] Trial 19 finished with value: 0.2747780680656433 and parameters: {'filters1': 84, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 2, 'learning_rate': 0.003596005692075945, 'batch_size': 32, 'epochs': 107}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2747780680656433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:53,661] Trial 20 finished with value: 0.33131203055381775 and parameters: {'filters1': 127, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 1, 'learning_rate': 0.0015055893960589108, 'batch_size': 32, 'epochs': 92}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33131203055381775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:57,810] Trial 21 finished with value: 0.32451575994491577 and parameters: {'filters1': 83, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0037097697293941487, 'batch_size': 32, 'epochs': 117}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32451575994491577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:19:59,791] Trial 22 finished with value: 0.2968403697013855 and parameters: {'filters1': 93, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 2, 'learning_rate': 0.005178678822485694, 'batch_size': 32, 'epochs': 136}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2968403697013855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:06,187] Trial 23 finished with value: 0.3301173448562622 and parameters: {'filters1': 78, 'kernel_size1': 1, 'filters2': 39, 'kernel_size2': 2, 'learning_rate': 0.003222092919980006, 'batch_size': 32, 'epochs': 145}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3301173448562622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:07,930] Trial 24 finished with value: 0.2960234582424164 and parameters: {'filters1': 112, 'kernel_size1': 1, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.006399552671726023, 'batch_size': 32, 'epochs': 84}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2960234582424164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:14,332] Trial 25 finished with value: 0.32955077290534973 and parameters: {'filters1': 53, 'kernel_size1': 2, 'filters2': 39, 'kernel_size2': 1, 'learning_rate': 0.0027898400147578287, 'batch_size': 64, 'epochs': 168}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32955077290534973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:18,502] Trial 26 finished with value: 0.35031411051750183 and parameters: {'filters1': 74, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 2, 'learning_rate': 0.001600538518514146, 'batch_size': 32, 'epochs': 103}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.35031411051750183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:21,820] Trial 27 finished with value: 0.3151293098926544 and parameters: {'filters1': 87, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.009379394987856044, 'batch_size': 32, 'epochs': 122}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3151293098926544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:24,047] Trial 28 finished with value: 0.29085302352905273 and parameters: {'filters1': 99, 'kernel_size1': 1, 'filters2': 43, 'kernel_size2': 2, 'learning_rate': 0.005079898903158028, 'batch_size': 64, 'epochs': 163}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29085302352905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:30,211] Trial 29 finished with value: 0.36520010232925415 and parameters: {'filters1': 106, 'kernel_size1': 2, 'filters2': 46, 'kernel_size2': 3, 'learning_rate': 0.0019614562009230537, 'batch_size': 64, 'epochs': 198}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.36520010232925415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:34,218] Trial 30 finished with value: 0.30489981174468994 and parameters: {'filters1': 119, 'kernel_size1': 1, 'filters2': 44, 'kernel_size2': 1, 'learning_rate': 0.005648638686623894, 'batch_size': 64, 'epochs': 164}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30489981174468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:37,550] Trial 31 finished with value: 0.28979623317718506 and parameters: {'filters1': 96, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 2, 'learning_rate': 0.004314808646662417, 'batch_size': 64, 'epochs': 142}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28979623317718506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:39,786] Trial 32 finished with value: 0.3374216556549072 and parameters: {'filters1': 100, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 2, 'learning_rate': 0.002808078235986792, 'batch_size': 64, 'epochs': 150}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3374216556549072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:42,126] Trial 33 finished with value: 0.2949030101299286 and parameters: {'filters1': 95, 'kernel_size1': 1, 'filters2': 36, 'kernel_size2': 2, 'learning_rate': 0.007051833274996461, 'batch_size': 64, 'epochs': 184}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2949030101299286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:44,436] Trial 34 finished with value: 0.29507654905319214 and parameters: {'filters1': 109, 'kernel_size1': 1, 'filters2': 41, 'kernel_size2': 2, 'learning_rate': 0.00488368513117594, 'batch_size': 64, 'epochs': 116}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29507654905319214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:46,184] Trial 35 finished with value: 0.3237748146057129 and parameters: {'filters1': 122, 'kernel_size1': 3, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.00250818983014835, 'batch_size': 64, 'epochs': 162}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3237748146057129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:48,414] Trial 36 finished with value: 0.29339513182640076 and parameters: {'filters1': 87, 'kernel_size1': 1, 'filters2': 51, 'kernel_size2': 3, 'learning_rate': 0.007984332540993361, 'batch_size': 64, 'epochs': 175}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29339513182640076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:54,864] Trial 37 finished with value: 0.4114081561565399 and parameters: {'filters1': 99, 'kernel_size1': 1, 'filters2': 37, 'kernel_size2': 2, 'learning_rate': 0.0032887745201928176, 'batch_size': 64, 'epochs': 129}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4114081561565399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:20:58,994] Trial 38 finished with value: 0.2890161871910095 and parameters: {'filters1': 106, 'kernel_size1': 1, 'filters2': 43, 'kernel_size2': 3, 'learning_rate': 0.004968907930860457, 'batch_size': 64, 'epochs': 190}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2890161871910095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:01,094] Trial 39 finished with value: 0.328438401222229 and parameters: {'filters1': 106, 'kernel_size1': 2, 'filters2': 43, 'kernel_size2': 2, 'learning_rate': 0.00603182592393501, 'batch_size': 64, 'epochs': 193}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.328438401222229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:04,271] Trial 40 finished with value: 0.3081327974796295 and parameters: {'filters1': 95, 'kernel_size1': 1, 'filters2': 52, 'kernel_size2': 3, 'learning_rate': 0.004710426158702954, 'batch_size': 64, 'epochs': 74}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3081327974796295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:06,460] Trial 41 finished with value: 0.30870622396469116 and parameters: {'filters1': 111, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 3, 'learning_rate': 0.0022161467453381974, 'batch_size': 64, 'epochs': 147}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30870622396469116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:09,049] Trial 42 finished with value: 0.2962487041950226 and parameters: {'filters1': 103, 'kernel_size1': 1, 'filters2': 47, 'kernel_size2': 3, 'learning_rate': 0.007463208200964161, 'batch_size': 16, 'epochs': 186}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2962487041950226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:13,363] Trial 43 finished with value: 0.39300596714019775 and parameters: {'filters1': 90, 'kernel_size1': 1, 'filters2': 42, 'kernel_size2': 3, 'learning_rate': 0.00011575172766539769, 'batch_size': 64, 'epochs': 159}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.39300596714019775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:15,523] Trial 44 finished with value: 0.314607709646225 and parameters: {'filters1': 122, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.003132652364868862, 'batch_size': 16, 'epochs': 135}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.314607709646225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:18,102] Trial 45 finished with value: 0.2920394539833069 and parameters: {'filters1': 114, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 3, 'learning_rate': 0.001302500215380703, 'batch_size': 64, 'epochs': 190}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2920394539833069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:20,288] Trial 46 finished with value: 0.37054383754730225 and parameters: {'filters1': 114, 'kernel_size1': 1, 'filters2': 37, 'kernel_size2': 2, 'learning_rate': 0.0006827966471532548, 'batch_size': 64, 'epochs': 191}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.37054383754730225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:22,137] Trial 47 finished with value: 0.28048354387283325 and parameters: {'filters1': 84, 'kernel_size1': 1, 'filters2': 34, 'kernel_size2': 3, 'learning_rate': 0.0003137516661765261, 'batch_size': 64, 'epochs': 200}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28048354387283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:25,417] Trial 48 finished with value: 0.31459295749664307 and parameters: {'filters1': 72, 'kernel_size1': 3, 'filters2': 55, 'kernel_size2': 3, 'learning_rate': 0.00018947620581470152, 'batch_size': 64, 'epochs': 177}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31459295749664307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:28,869] Trial 49 finished with value: 0.3544878363609314 and parameters: {'filters1': 82, 'kernel_size1': 2, 'filters2': 44, 'kernel_size2': 2, 'learning_rate': 0.0002768356874777918, 'batch_size': 64, 'epochs': 200}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3544878363609314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:35,979] Trial 50 finished with value: 0.4272668659687042 and parameters: {'filters1': 68, 'kernel_size1': 1, 'filters2': 34, 'kernel_size2': 2, 'learning_rate': 0.0006855743220929961, 'batch_size': 64, 'epochs': 172}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4272668659687042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:43,219] Trial 51 finished with value: 0.3927557170391083 and parameters: {'filters1': 97, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 3, 'learning_rate': 0.00031381204747285937, 'batch_size': 64, 'epochs': 188}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3927557170391083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:45,499] Trial 52 finished with value: 0.292223185300827 and parameters: {'filters1': 92, 'kernel_size1': 1, 'filters2': 38, 'kernel_size2': 3, 'learning_rate': 0.0004152853976984848, 'batch_size': 64, 'epochs': 196}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.292223185300827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:51,075] Trial 53 finished with value: 0.3204037547111511 and parameters: {'filters1': 85, 'kernel_size1': 1, 'filters2': 35, 'kernel_size2': 3, 'learning_rate': 0.0013728591721569837, 'batch_size': 64, 'epochs': 180}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3204037547111511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:54,890] Trial 54 finished with value: 0.3104223310947418 and parameters: {'filters1': 102, 'kernel_size1': 1, 'filters2': 31, 'kernel_size2': 3, 'learning_rate': 0.0008993605624396544, 'batch_size': 64, 'epochs': 55}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3104223310947418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:21:58,155] Trial 55 finished with value: 0.36478251218795776 and parameters: {'filters1': 37, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.0018826902959056169, 'batch_size': 64, 'epochs': 191}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.36478251218795776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:01,201] Trial 56 finished with value: 0.3995686173439026 and parameters: {'filters1': 90, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 2, 'learning_rate': 0.0038792256336088243, 'batch_size': 64, 'epochs': 169}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3995686173439026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:05,920] Trial 57 finished with value: 0.3305301070213318 and parameters: {'filters1': 109, 'kernel_size1': 1, 'filters2': 41, 'kernel_size2': 3, 'learning_rate': 0.000172031984473893, 'batch_size': 64, 'epochs': 182}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3305301070213318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:13,360] Trial 58 finished with value: 0.3484426736831665 and parameters: {'filters1': 116, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 2, 'learning_rate': 0.001288447297897772, 'batch_size': 64, 'epochs': 102}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3484426736831665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:17,879] Trial 59 finished with value: 0.36432555317878723 and parameters: {'filters1': 103, 'kernel_size1': 1, 'filters2': 47, 'kernel_size2': 3, 'learning_rate': 0.0008374353260343678, 'batch_size': 32, 'epochs': 152}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.36432555317878723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:23,102] Trial 60 finished with value: 0.3322610557079315 and parameters: {'filters1': 82, 'kernel_size1': 2, 'filters2': 35, 'kernel_size2': 2, 'learning_rate': 0.00048445235899707124, 'batch_size': 64, 'epochs': 200}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3322610557079315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:28,756] Trial 61 finished with value: 0.3527998924255371 and parameters: {'filters1': 92, 'kernel_size1': 1, 'filters2': 39, 'kernel_size2': 3, 'learning_rate': 0.0003765521441302843, 'batch_size': 64, 'epochs': 195}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3527998924255371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:33,960] Trial 62 finished with value: 0.3661706745624542 and parameters: {'filters1': 76, 'kernel_size1': 1, 'filters2': 37, 'kernel_size2': 3, 'learning_rate': 0.0003986119865761406, 'batch_size': 64, 'epochs': 189}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3661706745624542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:37,227] Trial 63 finished with value: 0.3917730450630188 and parameters: {'filters1': 97, 'kernel_size1': 1, 'filters2': 38, 'kernel_size2': 3, 'learning_rate': 0.0005663366064378901, 'batch_size': 64, 'epochs': 184}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3917730450630188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:43,849] Trial 64 finished with value: 0.32154473662376404 and parameters: {'filters1': 92, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 3, 'learning_rate': 0.00023437673220530047, 'batch_size': 64, 'epochs': 174}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32154473662376404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:47,020] Trial 65 finished with value: 0.30107560753822327 and parameters: {'filters1': 89, 'kernel_size1': 1, 'filters2': 45, 'kernel_size2': 3, 'learning_rate': 0.00442301038381395, 'batch_size': 32, 'epochs': 197}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30107560753822327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:49,743] Trial 66 finished with value: 0.31350570917129517 and parameters: {'filters1': 84, 'kernel_size1': 1, 'filters2': 40, 'kernel_size2': 2, 'learning_rate': 0.005397456655822326, 'batch_size': 64, 'epochs': 110}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31350570917129517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:52,076] Trial 67 finished with value: 0.33306005597114563 and parameters: {'filters1': 80, 'kernel_size1': 1, 'filters2': 49, 'kernel_size2': 2, 'learning_rate': 0.0034886516781621954, 'batch_size': 64, 'epochs': 166}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33306005597114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:56,200] Trial 68 finished with value: 0.3078635632991791 and parameters: {'filters1': 94, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 1, 'learning_rate': 0.006614999391287238, 'batch_size': 16, 'epochs': 194}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3078635632991791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:22:58,504] Trial 69 finished with value: 0.2927631139755249 and parameters: {'filters1': 105, 'kernel_size1': 1, 'filters2': 42, 'kernel_size2': 3, 'learning_rate': 0.008638282826861287, 'batch_size': 32, 'epochs': 124}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2927631139755249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:07,108] Trial 70 finished with value: 0.4262704849243164 and parameters: {'filters1': 98, 'kernel_size1': 1, 'filters2': 35, 'kernel_size2': 2, 'learning_rate': 0.0003120265105617614, 'batch_size': 64, 'epochs': 92}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4262704849243164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:09,752] Trial 71 finished with value: 0.2956816554069519 and parameters: {'filters1': 105, 'kernel_size1': 1, 'filters2': 42, 'kernel_size2': 3, 'learning_rate': 0.008577713706114007, 'batch_size': 32, 'epochs': 179}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2956816554069519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:13,840] Trial 72 finished with value: 0.29766133427619934 and parameters: {'filters1': 109, 'kernel_size1': 1, 'filters2': 38, 'kernel_size2': 3, 'learning_rate': 0.005904502099047342, 'batch_size': 32, 'epochs': 127}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29766133427619934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:16,098] Trial 73 finished with value: 0.3076886832714081 and parameters: {'filters1': 101, 'kernel_size1': 1, 'filters2': 43, 'kernel_size2': 3, 'learning_rate': 0.004324539637938676, 'batch_size': 32, 'epochs': 122}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3076886832714081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:19,468] Trial 74 finished with value: 0.3048097789287567 and parameters: {'filters1': 113, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 3, 'learning_rate': 0.00510445299298509, 'batch_size': 32, 'epochs': 119}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3048097789287567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:21,754] Trial 75 finished with value: 0.29539743065834045 and parameters: {'filters1': 107, 'kernel_size1': 1, 'filters2': 40, 'kernel_size2': 3, 'learning_rate': 0.007908902336125095, 'batch_size': 32, 'epochs': 137}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29539743065834045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:24,480] Trial 76 finished with value: 0.3041080832481384 and parameters: {'filters1': 88, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 3, 'learning_rate': 0.00255922988682865, 'batch_size': 32, 'epochs': 114}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3041080832481384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:26,695] Trial 77 finished with value: 0.3114186227321625 and parameters: {'filters1': 120, 'kernel_size1': 1, 'filters2': 36, 'kernel_size2': 2, 'learning_rate': 0.00302205777655562, 'batch_size': 64, 'epochs': 111}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3114186227321625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:28,529] Trial 78 finished with value: 0.29274997115135193 and parameters: {'filters1': 96, 'kernel_size1': 3, 'filters2': 45, 'kernel_size2': 3, 'learning_rate': 0.00909384295541654, 'batch_size': 64, 'epochs': 185}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29274997115135193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:30,471] Trial 79 finished with value: 0.2979140877723694 and parameters: {'filters1': 95, 'kernel_size1': 3, 'filters2': 46, 'kernel_size2': 2, 'learning_rate': 0.009679097155537017, 'batch_size': 64, 'epochs': 186}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2979140877723694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:33,179] Trial 80 finished with value: 0.29211246967315674 and parameters: {'filters1': 86, 'kernel_size1': 3, 'filters2': 27, 'kernel_size2': 3, 'learning_rate': 0.006482451727079279, 'batch_size': 64, 'epochs': 158}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29211246967315674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:36,519] Trial 81 finished with value: 0.2984049320220947 and parameters: {'filters1': 85, 'kernel_size1': 3, 'filters2': 49, 'kernel_size2': 3, 'learning_rate': 0.007001100888647946, 'batch_size': 64, 'epochs': 156}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2984049320220947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:38,108] Trial 82 finished with value: 0.2928634583950043 and parameters: {'filters1': 91, 'kernel_size1': 3, 'filters2': 22, 'kernel_size2': 3, 'learning_rate': 0.0062306503162996235, 'batch_size': 64, 'epochs': 195}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2928634583950043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:39,904] Trial 83 finished with value: 0.28916993737220764 and parameters: {'filters1': 86, 'kernel_size1': 3, 'filters2': 25, 'kernel_size2': 3, 'learning_rate': 0.0039897550889348345, 'batch_size': 64, 'epochs': 161}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28916993737220764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:41,517] Trial 84 finished with value: 0.2951716184616089 and parameters: {'filters1': 75, 'kernel_size1': 3, 'filters2': 27, 'kernel_size2': 3, 'learning_rate': 0.003908153649486606, 'batch_size': 64, 'epochs': 161}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2951716184616089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:43,099] Trial 85 finished with value: 0.2974323630332947 and parameters: {'filters1': 80, 'kernel_size1': 3, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.004838457735687804, 'batch_size': 64, 'epochs': 142}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2974323630332947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:45,109] Trial 86 finished with value: 0.29262879490852356 and parameters: {'filters1': 86, 'kernel_size1': 3, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.003676693344191252, 'batch_size': 64, 'epochs': 165}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29262879490852356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:47,254] Trial 87 finished with value: 0.28963544964790344 and parameters: {'filters1': 83, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 2, 'learning_rate': 0.004383855545700285, 'batch_size': 64, 'epochs': 149}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.28963544964790344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:49,480] Trial 88 finished with value: 0.33482179045677185 and parameters: {'filters1': 78, 'kernel_size1': 2, 'filters2': 25, 'kernel_size2': 2, 'learning_rate': 0.004311478294610758, 'batch_size': 64, 'epochs': 151}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33482179045677185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:51,635] Trial 89 finished with value: 0.29836443066596985 and parameters: {'filters1': 72, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 2, 'learning_rate': 0.0022817435516636277, 'batch_size': 16, 'epochs': 147}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29836443066596985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:55,206] Trial 90 finished with value: 0.3019302189350128 and parameters: {'filters1': 88, 'kernel_size1': 2, 'filters2': 28, 'kernel_size2': 2, 'learning_rate': 0.0028969910459275537, 'batch_size': 64, 'epochs': 157}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3019302189350128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:23:58,331] Trial 91 finished with value: 0.3032423257827759 and parameters: {'filters1': 84, 'kernel_size1': 3, 'filters2': 30, 'kernel_size2': 2, 'learning_rate': 0.005304980803836016, 'batch_size': 64, 'epochs': 153}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3032423257827759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:00,209] Trial 92 finished with value: 0.3374440371990204 and parameters: {'filters1': 82, 'kernel_size1': 3, 'filters2': 34, 'kernel_size2': 2, 'learning_rate': 0.005690139648721105, 'batch_size': 64, 'epochs': 172}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3374440371990204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:02,371] Trial 93 finished with value: 0.295559823513031 and parameters: {'filters1': 99, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.0046382091785844674, 'batch_size': 64, 'epochs': 148}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.295559823513031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:04,900] Trial 94 finished with value: 0.34669649600982666 and parameters: {'filters1': 80, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 3, 'learning_rate': 0.0011210930983550412, 'batch_size': 64, 'epochs': 139}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.34669649600982666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:09,356] Trial 95 finished with value: 0.2871502935886383 and parameters: {'filters1': 92, 'kernel_size1': 1, 'filters2': 34, 'kernel_size2': 2, 'learning_rate': 0.0034240400556383942, 'batch_size': 64, 'epochs': 132}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2871502935886383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:11,260] Trial 96 finished with value: 0.301471471786499 and parameters: {'filters1': 65, 'kernel_size1': 3, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0035714838459567112, 'batch_size': 64, 'epochs': 133}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.301471471786499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:13,893] Trial 97 finished with value: 0.3364011347293854 and parameters: {'filters1': 93, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.0019173740390389493, 'batch_size': 64, 'epochs': 130}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3364011347293854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:16,923] Trial 98 finished with value: 0.3128037750720978 and parameters: {'filters1': 89, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 2, 'learning_rate': 0.003153945262412327, 'batch_size': 64, 'epochs': 143}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3128037750720978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:21,274] Trial 99 finished with value: 0.3598475158214569 and parameters: {'filters1': 118, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 2, 'learning_rate': 0.00338948424237633, 'batch_size': 64, 'epochs': 161}. Best is trial 19 with value: 0.2747780680656433.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3598475158214569\n",
      "Best Trial:\n",
      "  Value: 0.2747780680656433\n",
      "  Params: \n",
      "    filters1: 84\n",
      "    kernel_size1: 1\n",
      "    filters2: 30\n",
      "    kernel_size2: 2\n",
      "    learning_rate: 0.003596005692075945\n",
      "    batch_size: 32\n",
      "    epochs: 107\n",
      "Epoch 1/107\n",
      "30/30 [==============================] - 1s 9ms/step - loss: 2588.8748 - val_loss: 77.3170\n",
      "Epoch 2/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 13.0873 - val_loss: 0.9095\n",
      "Epoch 3/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.9905 - val_loss: 0.3225\n",
      "Epoch 4/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3571 - val_loss: 0.3319\n",
      "Epoch 5/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.3198\n",
      "Epoch 6/107\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3055 - val_loss: 0.3273\n",
      "Epoch 7/107\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3125 - val_loss: 0.3112\n",
      "Epoch 8/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3032 - val_loss: 0.3200\n",
      "Epoch 9/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3012 - val_loss: 0.3151\n",
      "Epoch 10/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3431 - val_loss: 0.3079\n",
      "Epoch 11/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3356 - val_loss: 0.3964\n",
      "Epoch 12/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3388 - val_loss: 0.3687\n",
      "Epoch 13/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3129 - val_loss: 0.4526\n",
      "Epoch 14/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3390 - val_loss: 0.3187\n",
      "Epoch 15/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3129 - val_loss: 0.3308\n",
      "Epoch 16/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3081 - val_loss: 0.3073\n",
      "Epoch 17/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3027 - val_loss: 0.3492\n",
      "Epoch 18/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3221 - val_loss: 0.3698\n",
      "Epoch 19/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3714 - val_loss: 0.3172\n",
      "Epoch 20/107\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.3298\n",
      "Epoch 21/107\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.3442\n",
      "Epoch 22/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.3197\n",
      "Epoch 23/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3194 - val_loss: 0.3512\n",
      "Epoch 24/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3509 - val_loss: 0.3912\n",
      "Epoch 25/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3537 - val_loss: 0.3122\n",
      "Epoch 26/107\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3950 - val_loss: 0.4429\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "MSE   : 0.26034976041599084\n"
     ]
    }
   ],
   "source": [
    "CNN_testing_6 = CNN_testing(normalizes_df_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f09821a-1dcd-41b2-8da8-fae379697dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:24,432] A new study created in memory with name: no-name-edc33cc9-0fad-4727-a6c6-93fa1605c917\n",
      "[I 2025-08-13 00:24:30,683] Trial 0 finished with value: 1.241079568862915 and parameters: {'filters1': 60, 'kernel_size1': 1, 'filters2': 19, 'kernel_size2': 2, 'learning_rate': 0.0002075571441492542, 'batch_size': 32, 'epochs': 81}. Best is trial 0 with value: 1.241079568862915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 1.241079568862915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:32,112] Trial 1 finished with value: 0.6334107518196106 and parameters: {'filters1': 87, 'kernel_size1': 2, 'filters2': 43, 'kernel_size2': 3, 'learning_rate': 0.0070860507795303595, 'batch_size': 64, 'epochs': 66}. Best is trial 1 with value: 0.6334107518196106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6334107518196106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:37,194] Trial 2 finished with value: 0.668359100818634 and parameters: {'filters1': 51, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 1, 'learning_rate': 0.00043640336383747477, 'batch_size': 32, 'epochs': 110}. Best is trial 1 with value: 0.6334107518196106.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.668359100818634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:38,916] Trial 3 finished with value: 0.6120986342430115 and parameters: {'filters1': 47, 'kernel_size1': 3, 'filters2': 63, 'kernel_size2': 3, 'learning_rate': 0.0033999844186332466, 'batch_size': 32, 'epochs': 133}. Best is trial 3 with value: 0.6120986342430115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6120986342430115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:42,186] Trial 4 finished with value: 0.6275759339332581 and parameters: {'filters1': 109, 'kernel_size1': 1, 'filters2': 55, 'kernel_size2': 1, 'learning_rate': 0.00013012875408558927, 'batch_size': 64, 'epochs': 126}. Best is trial 3 with value: 0.6120986342430115.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6275759339332581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:47,267] Trial 5 finished with value: 0.5666345357894897 and parameters: {'filters1': 49, 'kernel_size1': 3, 'filters2': 51, 'kernel_size2': 1, 'learning_rate': 0.0030376624643990136, 'batch_size': 16, 'epochs': 59}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5666345357894897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:49,867] Trial 6 finished with value: 0.5702492594718933 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.0001505816579714286, 'batch_size': 64, 'epochs': 89}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5702492594718933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:52,106] Trial 7 finished with value: 0.6544189453125 and parameters: {'filters1': 123, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 3, 'learning_rate': 0.005755119720244881, 'batch_size': 16, 'epochs': 152}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6544189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:56,015] Trial 8 finished with value: 0.6321507096290588 and parameters: {'filters1': 39, 'kernel_size1': 3, 'filters2': 40, 'kernel_size2': 1, 'learning_rate': 0.0053782012978798805, 'batch_size': 64, 'epochs': 129}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6321507096290588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:24:58,588] Trial 9 finished with value: 0.6656854748725891 and parameters: {'filters1': 70, 'kernel_size1': 1, 'filters2': 55, 'kernel_size2': 2, 'learning_rate': 0.0017094073352359872, 'batch_size': 32, 'epochs': 144}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6656854748725891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:04,099] Trial 10 finished with value: 0.6970759630203247 and parameters: {'filters1': 32, 'kernel_size1': 3, 'filters2': 46, 'kernel_size2': 1, 'learning_rate': 0.0010962817686003031, 'batch_size': 16, 'epochs': 191}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6970759630203247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:11,074] Trial 11 finished with value: 0.7389318943023682 and parameters: {'filters1': 93, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.0004458747673912269, 'batch_size': 16, 'epochs': 52}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.7389318943023682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:12,918] Trial 12 finished with value: 0.6075066328048706 and parameters: {'filters1': 103, 'kernel_size1': 2, 'filters2': 34, 'kernel_size2': 2, 'learning_rate': 0.0025535374513502205, 'batch_size': 64, 'epochs': 90}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6075066328048706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:17,353] Trial 13 finished with value: 0.6710284948348999 and parameters: {'filters1': 74, 'kernel_size1': 3, 'filters2': 51, 'kernel_size2': 1, 'learning_rate': 0.0005286091599771694, 'batch_size': 16, 'epochs': 96}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6710284948348999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:20,327] Trial 14 finished with value: 0.6177512407302856 and parameters: {'filters1': 123, 'kernel_size1': 2, 'filters2': 38, 'kernel_size2': 2, 'learning_rate': 0.0010047106184314244, 'batch_size': 64, 'epochs': 51}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6177512407302856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:26,797] Trial 15 finished with value: 0.7167622447013855 and parameters: {'filters1': 103, 'kernel_size1': 2, 'filters2': 25, 'kernel_size2': 1, 'learning_rate': 0.00010371379558207189, 'batch_size': 16, 'epochs': 78}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.7167622447013855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:31,963] Trial 16 finished with value: 0.8020226955413818 and parameters: {'filters1': 63, 'kernel_size1': 3, 'filters2': 64, 'kernel_size2': 3, 'learning_rate': 0.00028021634667132355, 'batch_size': 64, 'epochs': 69}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.8020226955413818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:34,656] Trial 17 finished with value: 0.5986120700836182 and parameters: {'filters1': 89, 'kernel_size1': 2, 'filters2': 50, 'kernel_size2': 2, 'learning_rate': 0.009631461532457572, 'batch_size': 16, 'epochs': 105}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5986120700836182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:36,802] Trial 18 finished with value: 0.5803177952766418 and parameters: {'filters1': 114, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 1, 'learning_rate': 0.0020131192386530273, 'batch_size': 16, 'epochs': 171}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5803177952766418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:38,332] Trial 19 finished with value: 0.6010541319847107 and parameters: {'filters1': 79, 'kernel_size1': 3, 'filters2': 27, 'kernel_size2': 2, 'learning_rate': 0.00390832264423512, 'batch_size': 64, 'epochs': 110}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6010541319847107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:40,829] Trial 20 finished with value: 0.731096088886261 and parameters: {'filters1': 54, 'kernel_size1': 3, 'filters2': 37, 'kernel_size2': 3, 'learning_rate': 0.0006949200330363651, 'batch_size': 64, 'epochs': 65}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.731096088886261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:45,575] Trial 21 finished with value: 0.632465124130249 and parameters: {'filters1': 113, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 1, 'learning_rate': 0.0022442820636882745, 'batch_size': 16, 'epochs': 188}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.632465124130249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:50,404] Trial 22 finished with value: 0.6058430075645447 and parameters: {'filters1': 115, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.002379499317918957, 'batch_size': 16, 'epochs': 169}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6058430075645447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:54,317] Trial 23 finished with value: 0.597358763217926 and parameters: {'filters1': 93, 'kernel_size1': 2, 'filters2': 45, 'kernel_size2': 1, 'learning_rate': 0.0015216930895054286, 'batch_size': 16, 'epochs': 169}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.597358763217926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:25:57,010] Trial 24 finished with value: 0.6287645697593689 and parameters: {'filters1': 128, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 1, 'learning_rate': 0.0013876551097305556, 'batch_size': 16, 'epochs': 172}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6287645697593689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:00,846] Trial 25 finished with value: 0.6453894972801208 and parameters: {'filters1': 101, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 1, 'learning_rate': 0.0007589122603395036, 'batch_size': 16, 'epochs': 93}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6453894972801208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:03,670] Trial 26 finished with value: 0.6129893660545349 and parameters: {'filters1': 83, 'kernel_size1': 2, 'filters2': 28, 'kernel_size2': 2, 'learning_rate': 0.0034062034814661486, 'batch_size': 16, 'epochs': 154}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6129893660545349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:07,845] Trial 27 finished with value: 0.677528977394104 and parameters: {'filters1': 118, 'kernel_size1': 3, 'filters2': 36, 'kernel_size2': 1, 'learning_rate': 0.00023261228107244807, 'batch_size': 16, 'epochs': 77}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.677528977394104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:10,430] Trial 28 finished with value: 0.5851826667785645 and parameters: {'filters1': 97, 'kernel_size1': 3, 'filters2': 49, 'kernel_size2': 2, 'learning_rate': 0.001975196427078662, 'batch_size': 32, 'epochs': 117}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5851826667785645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:12,326] Trial 29 finished with value: 0.621880292892456 and parameters: {'filters1': 110, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.00393049731916761, 'batch_size': 64, 'epochs': 199}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.621880292892456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:20,429] Trial 30 finished with value: 0.9641172289848328 and parameters: {'filters1': 63, 'kernel_size1': 1, 'filters2': 42, 'kernel_size2': 1, 'learning_rate': 0.00014564863898396861, 'batch_size': 32, 'epochs': 85}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.9641172289848328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:23,187] Trial 31 finished with value: 0.592304527759552 and parameters: {'filters1': 98, 'kernel_size1': 3, 'filters2': 49, 'kernel_size2': 2, 'learning_rate': 0.0020554098932543297, 'batch_size': 32, 'epochs': 119}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.592304527759552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:28,638] Trial 32 finished with value: 0.6046455502510071 and parameters: {'filters1': 107, 'kernel_size1': 3, 'filters2': 54, 'kernel_size2': 2, 'learning_rate': 0.002888846136179121, 'batch_size': 32, 'epochs': 104}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6046455502510071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:31,668] Trial 33 finished with value: 0.6132265329360962 and parameters: {'filters1': 94, 'kernel_size1': 3, 'filters2': 59, 'kernel_size2': 2, 'learning_rate': 0.0011840765443305854, 'batch_size': 32, 'epochs': 62}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6132265329360962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:33,762] Trial 34 finished with value: 0.5970067381858826 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 45, 'kernel_size2': 3, 'learning_rate': 0.001792418685410961, 'batch_size': 32, 'epochs': 118}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5970067381858826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:38,152] Trial 35 finished with value: 0.7014484405517578 and parameters: {'filters1': 87, 'kernel_size1': 2, 'filters2': 52, 'kernel_size2': 3, 'learning_rate': 0.0007957832832513513, 'batch_size': 32, 'epochs': 138}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.7014484405517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:39,972] Trial 36 finished with value: 0.5995449423789978 and parameters: {'filters1': 47, 'kernel_size1': 3, 'filters2': 48, 'kernel_size2': 1, 'learning_rate': 0.0050844812722990315, 'batch_size': 64, 'epochs': 74}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5995449423789978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:41,916] Trial 37 finished with value: 0.621644139289856 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 58, 'kernel_size2': 1, 'learning_rate': 0.007332774223286489, 'batch_size': 32, 'epochs': 97}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.621644139289856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:43,870] Trial 38 finished with value: 0.611757755279541 and parameters: {'filters1': 97, 'kernel_size1': 3, 'filters2': 41, 'kernel_size2': 2, 'learning_rate': 0.002932571527450589, 'batch_size': 64, 'epochs': 60}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.611757755279541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:45,879] Trial 39 finished with value: 0.6636641025543213 and parameters: {'filters1': 71, 'kernel_size1': 3, 'filters2': 47, 'kernel_size2': 2, 'learning_rate': 0.004439509259356129, 'batch_size': 16, 'epochs': 117}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6636641025543213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:49,580] Trial 40 finished with value: 0.5976656675338745 and parameters: {'filters1': 128, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 3, 'learning_rate': 0.0012952451668976272, 'batch_size': 32, 'epochs': 138}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5976656675338745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:54,194] Trial 41 finished with value: 0.5967057943344116 and parameters: {'filters1': 99, 'kernel_size1': 3, 'filters2': 49, 'kernel_size2': 2, 'learning_rate': 0.0016222519445806141, 'batch_size': 32, 'epochs': 121}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5967057943344116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:56,597] Trial 42 finished with value: 0.6077566146850586 and parameters: {'filters1': 80, 'kernel_size1': 3, 'filters2': 53, 'kernel_size2': 2, 'learning_rate': 0.001953194787604818, 'batch_size': 32, 'epochs': 153}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6077566146850586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:26:58,782] Trial 43 finished with value: 0.6672400236129761 and parameters: {'filters1': 35, 'kernel_size1': 3, 'filters2': 57, 'kernel_size2': 2, 'learning_rate': 0.0020160753644406356, 'batch_size': 32, 'epochs': 128}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6672400236129761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:01,456] Trial 44 finished with value: 0.5990124940872192 and parameters: {'filters1': 107, 'kernel_size1': 3, 'filters2': 44, 'kernel_size2': 2, 'learning_rate': 0.0028639129897548563, 'batch_size': 32, 'epochs': 111}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5990124940872192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:05,162] Trial 45 finished with value: 0.61751788854599 and parameters: {'filters1': 90, 'kernel_size1': 2, 'filters2': 39, 'kernel_size2': 2, 'learning_rate': 0.0002973724990555534, 'batch_size': 32, 'epochs': 145}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.61751788854599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:09,077] Trial 46 finished with value: 0.6359103322029114 and parameters: {'filters1': 97, 'kernel_size1': 3, 'filters2': 62, 'kernel_size2': 1, 'learning_rate': 0.0008842274867998864, 'batch_size': 16, 'epochs': 162}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6359103322029114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:11,139] Trial 47 finished with value: 0.5920350551605225 and parameters: {'filters1': 113, 'kernel_size1': 2, 'filters2': 56, 'kernel_size2': 2, 'learning_rate': 0.005909199206959849, 'batch_size': 64, 'epochs': 86}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5920350551605225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:14,189] Trial 48 finished with value: 0.5828018188476562 and parameters: {'filters1': 121, 'kernel_size1': 2, 'filters2': 57, 'kernel_size2': 2, 'learning_rate': 0.006912688143082188, 'batch_size': 64, 'epochs': 85}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5828018188476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:19,103] Trial 49 finished with value: 0.8370079398155212 and parameters: {'filters1': 123, 'kernel_size1': 2, 'filters2': 51, 'kernel_size2': 1, 'learning_rate': 0.0005279079155670324, 'batch_size': 64, 'epochs': 55}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.8370079398155212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:21,143] Trial 50 finished with value: 0.5811803936958313 and parameters: {'filters1': 120, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 2, 'learning_rate': 0.008540319697309253, 'batch_size': 64, 'epochs': 71}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5811803936958313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:23,876] Trial 51 finished with value: 0.6054351925849915 and parameters: {'filters1': 120, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 2, 'learning_rate': 0.009163831683329687, 'batch_size': 64, 'epochs': 67}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6054351925849915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:25,865] Trial 52 finished with value: 0.6201207041740417 and parameters: {'filters1': 124, 'kernel_size1': 2, 'filters2': 55, 'kernel_size2': 2, 'learning_rate': 0.007900151356282265, 'batch_size': 64, 'epochs': 72}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6201207041740417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:27,991] Trial 53 finished with value: 0.5902690291404724 and parameters: {'filters1': 117, 'kernel_size1': 2, 'filters2': 25, 'kernel_size2': 2, 'learning_rate': 0.005641170234869023, 'batch_size': 64, 'epochs': 85}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5902690291404724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:30,602] Trial 54 finished with value: 0.5801773071289062 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 2, 'learning_rate': 0.006521574538345337, 'batch_size': 64, 'epochs': 57}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5801773071289062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:33,037] Trial 55 finished with value: 0.5806329250335693 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 3, 'learning_rate': 0.006614980914715085, 'batch_size': 64, 'epochs': 57}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5806329250335693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:36,311] Trial 56 finished with value: 0.6187928318977356 and parameters: {'filters1': 112, 'kernel_size1': 2, 'filters2': 63, 'kernel_size2': 3, 'learning_rate': 0.004777177728175933, 'batch_size': 64, 'epochs': 58}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6187928318977356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:38,765] Trial 57 finished with value: 0.6017143726348877 and parameters: {'filters1': 104, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 3, 'learning_rate': 0.0062810204769114635, 'batch_size': 64, 'epochs': 52}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6017143726348877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:40,933] Trial 58 finished with value: 0.598324179649353 and parameters: {'filters1': 115, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 3, 'learning_rate': 0.009742806734131729, 'batch_size': 64, 'epochs': 69}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.598324179649353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:42,781] Trial 59 finished with value: 0.6188467144966125 and parameters: {'filters1': 55, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 1, 'learning_rate': 0.003981034876461753, 'batch_size': 64, 'epochs': 64}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6188467144966125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:45,530] Trial 60 finished with value: 0.5950043797492981 and parameters: {'filters1': 110, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 3, 'learning_rate': 0.008699846136595194, 'batch_size': 64, 'epochs': 80}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5950043797492981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:47,540] Trial 61 finished with value: 0.603771448135376 and parameters: {'filters1': 123, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 2, 'learning_rate': 0.00674264877153829, 'batch_size': 64, 'epochs': 50}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.603771448135376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:49,946] Trial 62 finished with value: 0.588424801826477 and parameters: {'filters1': 121, 'kernel_size1': 2, 'filters2': 60, 'kernel_size2': 2, 'learning_rate': 0.007982709328966615, 'batch_size': 64, 'epochs': 59}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.588424801826477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:51,877] Trial 63 finished with value: 0.6565631031990051 and parameters: {'filters1': 115, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 2, 'learning_rate': 0.003476364337904369, 'batch_size': 64, 'epochs': 74}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6565631031990051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:54,316] Trial 64 finished with value: 0.5921372175216675 and parameters: {'filters1': 126, 'kernel_size1': 2, 'filters2': 57, 'kernel_size2': 2, 'learning_rate': 0.006700425854865056, 'batch_size': 16, 'epochs': 56}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5921372175216675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:27:56,285] Trial 65 finished with value: 0.5957680344581604 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 35, 'kernel_size2': 1, 'learning_rate': 0.004728529354361344, 'batch_size': 64, 'epochs': 91}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5957680344581604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:02,017] Trial 66 finished with value: 0.5884436964988708 and parameters: {'filters1': 116, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.00763955068725812, 'batch_size': 16, 'epochs': 69}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5884436964988708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:03,780] Trial 67 finished with value: 0.5941535830497742 and parameters: {'filters1': 110, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 1, 'learning_rate': 0.004009099996261931, 'batch_size': 64, 'epochs': 97}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5941535830497742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:10,994] Trial 68 finished with value: 0.5896636247634888 and parameters: {'filters1': 101, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.005498607038745729, 'batch_size': 16, 'epochs': 178}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5896636247634888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:14,847] Trial 69 finished with value: 0.6309047937393188 and parameters: {'filters1': 42, 'kernel_size1': 2, 'filters2': 54, 'kernel_size2': 1, 'learning_rate': 0.00013431772038524758, 'batch_size': 64, 'epochs': 80}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6309047937393188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:16,919] Trial 70 finished with value: 0.593048632144928 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 58, 'kernel_size2': 2, 'learning_rate': 0.002582856951291236, 'batch_size': 64, 'epochs': 63}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.593048632144928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:20,183] Trial 71 finished with value: 0.6092042922973633 and parameters: {'filters1': 112, 'kernel_size1': 2, 'filters2': 28, 'kernel_size2': 2, 'learning_rate': 0.0010938585644432626, 'batch_size': 16, 'epochs': 75}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6092042922973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:22,726] Trial 72 finished with value: 0.5762443542480469 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 63, 'kernel_size2': 2, 'learning_rate': 0.0014552855267800982, 'batch_size': 64, 'epochs': 55}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5762443542480469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:24,896] Trial 73 finished with value: 0.7140660285949707 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 63, 'kernel_size2': 2, 'learning_rate': 0.00010113881321885098, 'batch_size': 64, 'epochs': 50}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.7140660285949707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:29,015] Trial 74 finished with value: 0.6811539530754089 and parameters: {'filters1': 66, 'kernel_size1': 2, 'filters2': 60, 'kernel_size2': 2, 'learning_rate': 0.0013962939050937255, 'batch_size': 64, 'epochs': 56}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6811539530754089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:31,389] Trial 75 finished with value: 0.5822546482086182 and parameters: {'filters1': 102, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 2, 'learning_rate': 0.0031098920421643106, 'batch_size': 64, 'epochs': 65}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5822546482086182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:33,689] Trial 76 finished with value: 0.6060546040534973 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 63, 'kernel_size2': 2, 'learning_rate': 0.002379709007842219, 'batch_size': 64, 'epochs': 65}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6060546040534973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:36,286] Trial 77 finished with value: 0.6057766675949097 and parameters: {'filters1': 102, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 2, 'learning_rate': 0.0032319308300557494, 'batch_size': 16, 'epochs': 61}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6057766675949097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:38,041] Trial 78 finished with value: 0.6671578288078308 and parameters: {'filters1': 84, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 1, 'learning_rate': 0.0016231600436124056, 'batch_size': 64, 'epochs': 72}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6671578288078308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:41,803] Trial 79 finished with value: 0.7582551836967468 and parameters: {'filters1': 75, 'kernel_size1': 2, 'filters2': 60, 'kernel_size2': 2, 'learning_rate': 0.00030137263596060585, 'batch_size': 64, 'epochs': 53}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.7582551836967468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:44,255] Trial 80 finished with value: 0.5714066028594971 and parameters: {'filters1': 93, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 3, 'learning_rate': 0.0018002777164180064, 'batch_size': 16, 'epochs': 68}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5714066028594971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:46,560] Trial 81 finished with value: 0.588955283164978 and parameters: {'filters1': 95, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 3, 'learning_rate': 0.0023030475606217555, 'batch_size': 16, 'epochs': 68}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.588955283164978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:50,085] Trial 82 finished with value: 0.5905366539955139 and parameters: {'filters1': 109, 'kernel_size1': 2, 'filters2': 58, 'kernel_size2': 3, 'learning_rate': 0.001779791632989083, 'batch_size': 16, 'epochs': 56}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5905366539955139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:28:54,920] Trial 83 finished with value: 0.6353352069854736 and parameters: {'filters1': 100, 'kernel_size1': 2, 'filters2': 60, 'kernel_size2': 3, 'learning_rate': 0.0012598537012397893, 'batch_size': 16, 'epochs': 62}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6353352069854736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:05,432] Trial 84 finished with value: 0.5759342908859253 and parameters: {'filters1': 112, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 3, 'learning_rate': 0.0001678055792313405, 'batch_size': 16, 'epochs': 77}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5759342908859253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:09,173] Trial 85 finished with value: 0.6140192151069641 and parameters: {'filters1': 113, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 3, 'learning_rate': 0.00024732738897671947, 'batch_size': 16, 'epochs': 71}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6140192151069641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:13,448] Trial 86 finished with value: 0.6659435033798218 and parameters: {'filters1': 91, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 3, 'learning_rate': 0.00017571815233308023, 'batch_size': 16, 'epochs': 83}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6659435033798218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:24,035] Trial 87 finished with value: 0.6534738540649414 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 55, 'kernel_size2': 3, 'learning_rate': 0.00016474358479368195, 'batch_size': 16, 'epochs': 78}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6534738540649414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:29,050] Trial 88 finished with value: 0.658514678478241 and parameters: {'filters1': 117, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 3, 'learning_rate': 0.00011293983881102933, 'batch_size': 16, 'epochs': 59}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.658514678478241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:33,529] Trial 89 finished with value: 0.7306663393974304 and parameters: {'filters1': 108, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 3, 'learning_rate': 0.0008659801697712379, 'batch_size': 16, 'epochs': 190}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.7306663393974304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:41,066] Trial 90 finished with value: 0.6656808257102966 and parameters: {'filters1': 114, 'kernel_size1': 2, 'filters2': 43, 'kernel_size2': 3, 'learning_rate': 0.00019900650408484933, 'batch_size': 16, 'epochs': 102}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6656808257102966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:43,861] Trial 91 finished with value: 0.6074506044387817 and parameters: {'filters1': 106, 'kernel_size1': 2, 'filters2': 62, 'kernel_size2': 3, 'learning_rate': 0.0032230292289471218, 'batch_size': 64, 'epochs': 66}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6074506044387817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:45,796] Trial 92 finished with value: 0.5691298246383667 and parameters: {'filters1': 103, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 2, 'learning_rate': 0.0026005226418797933, 'batch_size': 64, 'epochs': 77}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5691298246383667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:50,736] Trial 93 finished with value: 0.6124643683433533 and parameters: {'filters1': 104, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.0015026595496500695, 'batch_size': 64, 'epochs': 76}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6124643683433533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:53,577] Trial 94 finished with value: 0.5825864672660828 and parameters: {'filters1': 109, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 3, 'learning_rate': 0.0021165151285447224, 'batch_size': 16, 'epochs': 88}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5825864672660828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:29:55,689] Trial 95 finished with value: 0.610641360282898 and parameters: {'filters1': 118, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 2, 'learning_rate': 0.0026093168851514604, 'batch_size': 64, 'epochs': 200}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.610641360282898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:01,070] Trial 96 finished with value: 0.6670263409614563 and parameters: {'filters1': 95, 'kernel_size1': 2, 'filters2': 63, 'kernel_size2': 1, 'learning_rate': 0.0003616229023255425, 'batch_size': 16, 'epochs': 81}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6670263409614563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:03,704] Trial 97 finished with value: 0.6478608846664429 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 56, 'kernel_size2': 2, 'learning_rate': 0.0019084618401175276, 'batch_size': 64, 'epochs': 182}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6478608846664429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:05,581] Trial 98 finished with value: 0.5966330766677856 and parameters: {'filters1': 99, 'kernel_size1': 2, 'filters2': 59, 'kernel_size2': 3, 'learning_rate': 0.0006614592651634012, 'batch_size': 64, 'epochs': 53}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5966330766677856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:08,057] Trial 99 finished with value: 0.6408407092094421 and parameters: {'filters1': 125, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 1, 'learning_rate': 0.008358264574759484, 'batch_size': 16, 'epochs': 157}. Best is trial 5 with value: 0.5666345357894897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6408407092094421\n",
      "Best Trial:\n",
      "  Value: 0.5666345357894897\n",
      "  Params: \n",
      "    filters1: 49\n",
      "    kernel_size1: 3\n",
      "    filters2: 51\n",
      "    kernel_size2: 1\n",
      "    learning_rate: 0.0030376624643990136\n",
      "    batch_size: 16\n",
      "    epochs: 59\n",
      "Epoch 1/59\n",
      "60/60 [==============================] - 1s 3ms/step - loss: 1949.2577 - val_loss: 2.3570\n",
      "Epoch 2/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0554 - val_loss: 0.6831\n",
      "Epoch 3/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6603 - val_loss: 0.8136\n",
      "Epoch 4/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7360 - val_loss: 1.0972\n",
      "Epoch 5/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8639 - val_loss: 0.7047\n",
      "Epoch 6/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7795 - val_loss: 0.6811\n",
      "Epoch 7/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7067 - val_loss: 0.8251\n",
      "Epoch 8/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7726 - val_loss: 1.2054\n",
      "Epoch 9/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8310 - val_loss: 1.1212\n",
      "Epoch 10/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7365 - val_loss: 1.3091\n",
      "Epoch 11/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7258 - val_loss: 0.7471\n",
      "Epoch 12/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6943 - val_loss: 0.7189\n",
      "Epoch 13/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7565 - val_loss: 0.6632\n",
      "Epoch 14/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7817 - val_loss: 0.6679\n",
      "Epoch 15/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 1.0283 - val_loss: 0.7066\n",
      "Epoch 16/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8412 - val_loss: 0.8278\n",
      "Epoch 17/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6666 - val_loss: 0.6834\n",
      "Epoch 18/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6262 - val_loss: 0.6638\n",
      "Epoch 19/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.7263 - val_loss: 0.6561\n",
      "Epoch 20/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6872 - val_loss: 0.6595\n",
      "Epoch 21/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8924 - val_loss: 1.1921\n",
      "Epoch 22/59\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7279 - val_loss: 0.6867\n",
      "Epoch 23/59\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6255 - val_loss: 0.8661\n",
      "Epoch 24/59\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.6958 - val_loss: 0.8822\n",
      "Epoch 25/59\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.7985 - val_loss: 0.6580\n",
      "Epoch 26/59\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.5954 - val_loss: 1.0441\n",
      "Epoch 27/59\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.9562 - val_loss: 0.6593\n",
      "Epoch 28/59\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.8503 - val_loss: 0.6578\n",
      "Epoch 29/59\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 1.1487 - val_loss: 2.3851\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.5677671444442339\n"
     ]
    }
   ],
   "source": [
    "CNN_testing_7 = CNN_testing(normalizes_df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea1135fa-98d4-446b-ac3c-26c2610d964a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:12,883] A new study created in memory with name: no-name-5e12a910-8d88-4bba-9f28-f66616fbad08\n",
      "[I 2025-08-13 00:30:18,751] Trial 0 finished with value: 0.4474470019340515 and parameters: {'filters1': 87, 'kernel_size1': 1, 'filters2': 57, 'kernel_size2': 1, 'learning_rate': 0.0002309764584541127, 'batch_size': 32, 'epochs': 121}. Best is trial 0 with value: 0.4474470019340515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4474470019340515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:20,931] Trial 1 finished with value: 0.4562912881374359 and parameters: {'filters1': 106, 'kernel_size1': 3, 'filters2': 25, 'kernel_size2': 3, 'learning_rate': 0.0003447276413432592, 'batch_size': 32, 'epochs': 199}. Best is trial 0 with value: 0.4474470019340515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4562912881374359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:25,387] Trial 2 finished with value: 0.6195886731147766 and parameters: {'filters1': 54, 'kernel_size1': 3, 'filters2': 57, 'kernel_size2': 1, 'learning_rate': 0.00022077820224747233, 'batch_size': 64, 'epochs': 99}. Best is trial 0 with value: 0.4474470019340515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6195886731147766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:27,092] Trial 3 finished with value: 0.42082762718200684 and parameters: {'filters1': 44, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 1, 'learning_rate': 0.0004790320650645633, 'batch_size': 64, 'epochs': 96}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42082762718200684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:29,005] Trial 4 finished with value: 0.4515361189842224 and parameters: {'filters1': 84, 'kernel_size1': 2, 'filters2': 64, 'kernel_size2': 2, 'learning_rate': 0.0024605493033118065, 'batch_size': 64, 'epochs': 166}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4515361189842224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:35,631] Trial 5 finished with value: 0.5673051476478577 and parameters: {'filters1': 61, 'kernel_size1': 3, 'filters2': 61, 'kernel_size2': 1, 'learning_rate': 0.0014258144822414174, 'batch_size': 32, 'epochs': 127}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5673051476478577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:41,080] Trial 6 finished with value: 0.6116403341293335 and parameters: {'filters1': 91, 'kernel_size1': 1, 'filters2': 55, 'kernel_size2': 3, 'learning_rate': 0.00015156063256852747, 'batch_size': 64, 'epochs': 80}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6116403341293335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:44,865] Trial 7 finished with value: 0.5019146203994751 and parameters: {'filters1': 61, 'kernel_size1': 3, 'filters2': 37, 'kernel_size2': 1, 'learning_rate': 0.003648284271649516, 'batch_size': 16, 'epochs': 177}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5019146203994751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:46,549] Trial 8 finished with value: 0.5277109742164612 and parameters: {'filters1': 37, 'kernel_size1': 3, 'filters2': 31, 'kernel_size2': 3, 'learning_rate': 0.0016366141990301027, 'batch_size': 64, 'epochs': 154}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5277109742164612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:51,276] Trial 9 finished with value: 0.4256190359592438 and parameters: {'filters1': 89, 'kernel_size1': 2, 'filters2': 46, 'kernel_size2': 1, 'learning_rate': 0.008417280104941995, 'batch_size': 64, 'epochs': 58}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4256190359592438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:53,588] Trial 10 finished with value: 0.44812819361686707 and parameters: {'filters1': 126, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.0005754037841364095, 'batch_size': 16, 'epochs': 50}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.44812819361686707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:56,142] Trial 11 finished with value: 0.43867430090904236 and parameters: {'filters1': 33, 'kernel_size1': 2, 'filters2': 46, 'kernel_size2': 2, 'learning_rate': 0.005588285843102023, 'batch_size': 64, 'epochs': 53}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.43867430090904236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:30:58,623] Trial 12 finished with value: 0.46808937191963196 and parameters: {'filters1': 69, 'kernel_size1': 2, 'filters2': 46, 'kernel_size2': 1, 'learning_rate': 0.007779932551544097, 'batch_size': 64, 'epochs': 79}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.46808937191963196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:04,456] Trial 13 finished with value: 0.5126969218254089 and parameters: {'filters1': 108, 'kernel_size1': 1, 'filters2': 44, 'kernel_size2': 1, 'learning_rate': 0.0007651606953636673, 'batch_size': 64, 'epochs': 76}. Best is trial 3 with value: 0.42082762718200684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5126969218254089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:08,193] Trial 14 finished with value: 0.40905511379241943 and parameters: {'filters1': 45, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0005618138822625489, 'batch_size': 64, 'epochs': 107}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.40905511379241943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:12,522] Trial 15 finished with value: 0.4647964537143707 and parameters: {'filters1': 45, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0005196928327473764, 'batch_size': 16, 'epochs': 117}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4647964537143707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:16,744] Trial 16 finished with value: 0.6128717660903931 and parameters: {'filters1': 47, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 2, 'learning_rate': 0.0009983024868919876, 'batch_size': 64, 'epochs': 104}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6128717660903931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:18,482] Trial 17 finished with value: 0.4405907094478607 and parameters: {'filters1': 70, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 3, 'learning_rate': 0.00011081915384894085, 'batch_size': 64, 'epochs': 140}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4405907094478607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:22,235] Trial 18 finished with value: 0.6052741408348083 and parameters: {'filters1': 43, 'kernel_size1': 1, 'filters2': 33, 'kernel_size2': 2, 'learning_rate': 0.0003662879162924121, 'batch_size': 32, 'epochs': 97}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6052741408348083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:25,066] Trial 19 finished with value: 0.4256541132926941 and parameters: {'filters1': 55, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.0014109446408580115, 'batch_size': 16, 'epochs': 138}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4256541132926941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:27,679] Trial 20 finished with value: 0.5030726790428162 and parameters: {'filters1': 72, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 3, 'learning_rate': 0.0003485356529622231, 'batch_size': 64, 'epochs': 108}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5030726790428162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:32,380] Trial 21 finished with value: 0.5884405374526978 and parameters: {'filters1': 102, 'kernel_size1': 2, 'filters2': 51, 'kernel_size2': 1, 'learning_rate': 0.0006655704327672167, 'batch_size': 64, 'epochs': 64}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5884405374526978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:34,332] Trial 22 finished with value: 0.44333305954933167 and parameters: {'filters1': 79, 'kernel_size1': 2, 'filters2': 40, 'kernel_size2': 1, 'learning_rate': 0.0027425751556371053, 'batch_size': 64, 'epochs': 91}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.44333305954933167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:39,206] Trial 23 finished with value: 0.4295875132083893 and parameters: {'filters1': 127, 'kernel_size1': 2, 'filters2': 37, 'kernel_size2': 1, 'learning_rate': 0.009141015031813672, 'batch_size': 64, 'epochs': 68}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4295875132083893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:43,022] Trial 24 finished with value: 0.4127673804759979 and parameters: {'filters1': 95, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.0009187948037392758, 'batch_size': 64, 'epochs': 84}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4127673804759979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:48,599] Trial 25 finished with value: 0.5202746391296387 and parameters: {'filters1': 99, 'kernel_size1': 3, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.0009064372354474607, 'batch_size': 64, 'epochs': 85}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5202746391296387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:31:55,432] Trial 26 finished with value: 0.524000346660614 and parameters: {'filters1': 118, 'kernel_size1': 1, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0004693608295502648, 'batch_size': 64, 'epochs': 112}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.524000346660614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:03,439] Trial 27 finished with value: 0.6919662952423096 and parameters: {'filters1': 38, 'kernel_size1': 2, 'filters2': 27, 'kernel_size2': 1, 'learning_rate': 0.0002521024984074714, 'batch_size': 64, 'epochs': 130}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6919662952423096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:06,250] Trial 28 finished with value: 0.43287211656570435 and parameters: {'filters1': 78, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.0011922779090760096, 'batch_size': 16, 'epochs': 91}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.43287211656570435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:09,120] Trial 29 finished with value: 0.48316702246665955 and parameters: {'filters1': 52, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 1, 'learning_rate': 0.0019273576693696504, 'batch_size': 32, 'epochs': 120}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.48316702246665955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:12,967] Trial 30 finished with value: 0.43320825695991516 and parameters: {'filters1': 62, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 1, 'learning_rate': 0.0007763089111870954, 'batch_size': 32, 'epochs': 72}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.43320825695991516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:17,518] Trial 31 finished with value: 0.4172551929950714 and parameters: {'filters1': 89, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.0049173619579772265, 'batch_size': 64, 'epochs': 61}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4172551929950714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:22,050] Trial 32 finished with value: 0.4761158227920532 and parameters: {'filters1': 97, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 1, 'learning_rate': 0.0043073067609243065, 'batch_size': 64, 'epochs': 89}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4761158227920532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:26,913] Trial 33 finished with value: 0.9900025725364685 and parameters: {'filters1': 109, 'kernel_size1': 2, 'filters2': 26, 'kernel_size2': 1, 'learning_rate': 0.0002503003931945547, 'batch_size': 64, 'epochs': 62}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.9900025725364685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:31,915] Trial 34 finished with value: 0.6374818086624146 and parameters: {'filters1': 93, 'kernel_size1': 3, 'filters2': 19, 'kernel_size2': 1, 'learning_rate': 0.0004531161540111433, 'batch_size': 64, 'epochs': 100}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6374818086624146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:37,144] Trial 35 finished with value: 0.41401517391204834 and parameters: {'filters1': 84, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 1, 'learning_rate': 0.00019425604601546246, 'batch_size': 64, 'epochs': 73}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41401517391204834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:38,966] Trial 36 finished with value: 0.6439607739448547 and parameters: {'filters1': 84, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 1, 'learning_rate': 0.00018886053381807184, 'batch_size': 64, 'epochs': 71}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6439607739448547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:46,347] Trial 37 finished with value: 0.5402831435203552 and parameters: {'filters1': 85, 'kernel_size1': 3, 'filters2': 32, 'kernel_size2': 2, 'learning_rate': 0.00015512693456403833, 'batch_size': 32, 'epochs': 82}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5402831435203552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:53,151] Trial 38 finished with value: 0.46675315499305725 and parameters: {'filters1': 75, 'kernel_size1': 2, 'filters2': 28, 'kernel_size2': 1, 'learning_rate': 0.0022570156750870746, 'batch_size': 64, 'epochs': 192}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.46675315499305725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:55,995] Trial 39 finished with value: 0.4184291362762451 and parameters: {'filters1': 113, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.0031453139971343858, 'batch_size': 64, 'epochs': 64}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4184291362762451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:58,037] Trial 40 finished with value: 0.599572479724884 and parameters: {'filters1': 95, 'kernel_size1': 3, 'filters2': 25, 'kernel_size2': 1, 'learning_rate': 0.0001225115100653278, 'batch_size': 64, 'epochs': 58}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.599572479724884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:32:59,896] Trial 41 finished with value: 0.4132032096385956 and parameters: {'filters1': 113, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.0033627426523314082, 'batch_size': 64, 'epochs': 67}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4132032096385956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:01,901] Trial 42 finished with value: 0.4199286997318268 and parameters: {'filters1': 103, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 3, 'learning_rate': 0.0065271027546329845, 'batch_size': 64, 'epochs': 76}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4199286997318268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:04,241] Trial 43 finished with value: 0.4132241904735565 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.0046745808196296266, 'batch_size': 64, 'epochs': 56}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4132241904735565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:06,304] Trial 44 finished with value: 0.42465120553970337 and parameters: {'filters1': 123, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.0037380384301750973, 'batch_size': 64, 'epochs': 51}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42465120553970337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:08,072] Trial 45 finished with value: 0.42675891518592834 and parameters: {'filters1': 116, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.0020272909372640183, 'batch_size': 64, 'epochs': 83}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42675891518592834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:11,575] Trial 46 finished with value: 0.4530129134654999 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0012093116564354247, 'batch_size': 16, 'epochs': 70}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4530129134654999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:13,776] Trial 47 finished with value: 0.45943063497543335 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 3, 'learning_rate': 0.0017149078004663118, 'batch_size': 64, 'epochs': 55}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.45943063497543335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:17,766] Trial 48 finished with value: 0.4210561513900757 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 29, 'kernel_size2': 3, 'learning_rate': 0.007154534508482976, 'batch_size': 64, 'epochs': 75}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4210561513900757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:20,476] Trial 49 finished with value: 0.5114138722419739 and parameters: {'filters1': 122, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 2, 'learning_rate': 0.00031181755812602325, 'batch_size': 32, 'epochs': 101}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5114138722419739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:22,553] Trial 50 finished with value: 0.4437360465526581 and parameters: {'filters1': 67, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.0006155119379807469, 'batch_size': 64, 'epochs': 92}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4437360465526581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:24,641] Trial 51 finished with value: 0.4222467243671417 and parameters: {'filters1': 89, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.003724429176054799, 'batch_size': 64, 'epochs': 60}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4222467243671417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:26,879] Trial 52 finished with value: 0.43196457624435425 and parameters: {'filters1': 100, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 2, 'learning_rate': 0.005978828300070439, 'batch_size': 64, 'epochs': 66}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.43196457624435425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:29,511] Trial 53 finished with value: 0.4343850612640381 and parameters: {'filters1': 83, 'kernel_size1': 2, 'filters2': 35, 'kernel_size2': 3, 'learning_rate': 0.004845054327802873, 'batch_size': 64, 'epochs': 54}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4343850612640381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:31,668] Trial 54 finished with value: 0.4567921459674835 and parameters: {'filters1': 88, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 1, 'learning_rate': 0.004881257165045551, 'batch_size': 64, 'epochs': 79}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4567921459674835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:36,045] Trial 55 finished with value: 0.43823933601379395 and parameters: {'filters1': 114, 'kernel_size1': 2, 'filters2': 61, 'kernel_size2': 1, 'learning_rate': 0.0027245263941492173, 'batch_size': 16, 'epochs': 86}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.43823933601379395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:38,815] Trial 56 finished with value: 0.4436081647872925 and parameters: {'filters1': 76, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0050703553281168864, 'batch_size': 64, 'epochs': 61}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4436081647872925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:41,015] Trial 57 finished with value: 0.42066529393196106 and parameters: {'filters1': 82, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.00990674621011589, 'batch_size': 64, 'epochs': 50}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42066529393196106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:44,259] Trial 58 finished with value: 0.4794232249259949 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 51, 'kernel_size2': 1, 'learning_rate': 0.0013436687880833964, 'batch_size': 64, 'epochs': 110}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4794232249259949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:46,110] Trial 59 finished with value: 0.4106699526309967 and parameters: {'filters1': 92, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0008967799716914353, 'batch_size': 64, 'epochs': 70}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4106699526309967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:47,991] Trial 60 finished with value: 0.41244396567344666 and parameters: {'filters1': 93, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0009500010135850052, 'batch_size': 64, 'epochs': 157}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41244396567344666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:49,946] Trial 61 finished with value: 0.45382067561149597 and parameters: {'filters1': 92, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0007953697171840515, 'batch_size': 64, 'epochs': 149}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.45382067561149597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:52,081] Trial 62 finished with value: 0.4845018684864044 and parameters: {'filters1': 95, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.0009353414750823336, 'batch_size': 64, 'epochs': 171}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4845018684864044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:53,850] Trial 63 finished with value: 0.42404869198799133 and parameters: {'filters1': 100, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.0007116082493132326, 'batch_size': 64, 'epochs': 158}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42404869198799133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:56,036] Trial 64 finished with value: 0.5323160886764526 and parameters: {'filters1': 86, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 3, 'learning_rate': 0.0011458127426000203, 'batch_size': 64, 'epochs': 187}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5323160886764526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:33:59,955] Trial 65 finished with value: 0.569633960723877 and parameters: {'filters1': 128, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.00039821763328403207, 'batch_size': 64, 'epochs': 129}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.569633960723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:04,215] Trial 66 finished with value: 0.42288127541542053 and parameters: {'filters1': 97, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.001061332584649794, 'batch_size': 16, 'epochs': 140}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42288127541542053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:06,706] Trial 67 finished with value: 0.4223080575466156 and parameters: {'filters1': 80, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 3, 'learning_rate': 0.0005701592266026121, 'batch_size': 32, 'epochs': 115}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4223080575466156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:08,897] Trial 68 finished with value: 0.5279067754745483 and parameters: {'filters1': 65, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 3, 'learning_rate': 0.0015366350303213003, 'batch_size': 64, 'epochs': 68}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5279067754745483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:12,512] Trial 69 finished with value: 0.41489410400390625 and parameters: {'filters1': 105, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.0008404691322486784, 'batch_size': 64, 'epochs': 106}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.41489410400390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:16,976] Trial 70 finished with value: 0.5600172877311707 and parameters: {'filters1': 123, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 2, 'learning_rate': 0.0001971235385801374, 'batch_size': 64, 'epochs': 124}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5600172877311707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:18,751] Trial 71 finished with value: 0.4166659414768219 and parameters: {'filters1': 104, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.0009116650226224976, 'batch_size': 64, 'epochs': 93}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4166659414768219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:20,718] Trial 72 finished with value: 0.4204193949699402 and parameters: {'filters1': 110, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.0008392255569848468, 'batch_size': 64, 'epochs': 108}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4204193949699402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:25,965] Trial 73 finished with value: 0.47603896260261536 and parameters: {'filters1': 91, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 3, 'learning_rate': 0.0007196090093507411, 'batch_size': 64, 'epochs': 104}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.47603896260261536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:27,559] Trial 74 finished with value: 0.4665425717830658 and parameters: {'filters1': 33, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.0006371752213742421, 'batch_size': 64, 'epochs': 74}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4665425717830658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:30,026] Trial 75 finished with value: 0.42525824904441833 and parameters: {'filters1': 94, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 3, 'learning_rate': 0.0005483601208526234, 'batch_size': 64, 'epochs': 96}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42525824904441833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:33,425] Trial 76 finished with value: 0.48493456840515137 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.00030663503076883104, 'batch_size': 64, 'epochs': 133}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.48493456840515137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:37,853] Trial 77 finished with value: 0.4939436912536621 and parameters: {'filters1': 97, 'kernel_size1': 2, 'filters2': 25, 'kernel_size2': 3, 'learning_rate': 0.0010232445146737827, 'batch_size': 64, 'epochs': 80}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4939436912536621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:40,708] Trial 78 finished with value: 0.45991426706314087 and parameters: {'filters1': 101, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 3, 'learning_rate': 0.0004980559965898458, 'batch_size': 32, 'epochs': 88}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.45991426706314087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:42,568] Trial 79 finished with value: 0.4414084255695343 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0012591430335329085, 'batch_size': 64, 'epochs': 120}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4414084255695343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:49,478] Trial 80 finished with value: 0.5889179706573486 and parameters: {'filters1': 58, 'kernel_size1': 1, 'filters2': 19, 'kernel_size2': 2, 'learning_rate': 0.00010082933801791165, 'batch_size': 16, 'epochs': 65}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5889179706573486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:51,606] Trial 81 finished with value: 0.4620822072029114 and parameters: {'filters1': 104, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.0008350595699272159, 'batch_size': 64, 'epochs': 95}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4620822072029114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:53,702] Trial 82 finished with value: 0.44493719935417175 and parameters: {'filters1': 113, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 3, 'learning_rate': 0.0009184692464630292, 'batch_size': 64, 'epochs': 102}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.44493719935417175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:55,562] Trial 83 finished with value: 0.43339240550994873 and parameters: {'filters1': 116, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 3, 'learning_rate': 0.00042703950250153505, 'batch_size': 64, 'epochs': 56}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.43339240550994873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:34:58,467] Trial 84 finished with value: 0.42938247323036194 and parameters: {'filters1': 49, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 3, 'learning_rate': 0.0010898607016813888, 'batch_size': 64, 'epochs': 83}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42938247323036194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:00,527] Trial 85 finished with value: 0.42257726192474365 and parameters: {'filters1': 103, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 3, 'learning_rate': 0.0016677526957028354, 'batch_size': 64, 'epochs': 78}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42257726192474365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:02,176] Trial 86 finished with value: 0.4408608078956604 and parameters: {'filters1': 97, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.001397335985816088, 'batch_size': 64, 'epochs': 114}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4408608078956604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:06,891] Trial 87 finished with value: 0.44438430666923523 and parameters: {'filters1': 91, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.0006654695038139014, 'batch_size': 64, 'epochs': 105}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.44438430666923523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:13,268] Trial 88 finished with value: 0.9300101399421692 and parameters: {'filters1': 87, 'kernel_size1': 2, 'filters2': 22, 'kernel_size2': 1, 'learning_rate': 0.000926807751310308, 'batch_size': 64, 'epochs': 72}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.9300101399421692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:15,744] Trial 89 finished with value: 0.4331245422363281 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.0032586668665203974, 'batch_size': 64, 'epochs': 94}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4331245422363281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:22,910] Trial 90 finished with value: 0.5436340570449829 and parameters: {'filters1': 105, 'kernel_size1': 3, 'filters2': 24, 'kernel_size2': 3, 'learning_rate': 0.0007272433536702166, 'batch_size': 64, 'epochs': 98}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5436340570449829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:24,896] Trial 91 finished with value: 0.4552459120750427 and parameters: {'filters1': 81, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.007975606794915517, 'batch_size': 64, 'epochs': 60}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4552459120750427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:30,687] Trial 92 finished with value: 0.42497703433036804 and parameters: {'filters1': 89, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 1, 'learning_rate': 0.005690702438975818, 'batch_size': 64, 'epochs': 68}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.42497703433036804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:36,926] Trial 93 finished with value: 0.46739158034324646 and parameters: {'filters1': 72, 'kernel_size1': 2, 'filters2': 17, 'kernel_size2': 1, 'learning_rate': 0.004340485468717343, 'batch_size': 64, 'epochs': 86}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.46739158034324646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:38,758] Trial 94 finished with value: 0.4092673659324646 and parameters: {'filters1': 85, 'kernel_size1': 2, 'filters2': 26, 'kernel_size2': 1, 'learning_rate': 0.006594908232623186, 'batch_size': 64, 'epochs': 63}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4092673659324646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:44,010] Trial 95 finished with value: 0.49182090163230896 and parameters: {'filters1': 39, 'kernel_size1': 2, 'filters2': 27, 'kernel_size2': 1, 'learning_rate': 0.0019353788338489929, 'batch_size': 64, 'epochs': 76}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.49182090163230896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:46,386] Trial 96 finished with value: 0.5010632872581482 and parameters: {'filters1': 99, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 1, 'learning_rate': 0.0012803388004458838, 'batch_size': 64, 'epochs': 57}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5010632872581482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:49,757] Trial 97 finished with value: 0.44993630051612854 and parameters: {'filters1': 76, 'kernel_size1': 2, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.006976172250623091, 'batch_size': 32, 'epochs': 90}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.44993630051612854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:52,641] Trial 98 finished with value: 0.5648100972175598 and parameters: {'filters1': 85, 'kernel_size1': 2, 'filters2': 26, 'kernel_size2': 1, 'learning_rate': 0.0010096759521955399, 'batch_size': 64, 'epochs': 71}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.5648100972175598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:35:58,619] Trial 99 finished with value: 0.6194719076156616 and parameters: {'filters1': 78, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 3, 'learning_rate': 0.000156962134372081, 'batch_size': 16, 'epochs': 65}. Best is trial 14 with value: 0.40905511379241943.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6194719076156616\n",
      "Best Trial:\n",
      "  Value: 0.40905511379241943\n",
      "  Params: \n",
      "    filters1: 45\n",
      "    kernel_size1: 2\n",
      "    filters2: 16\n",
      "    kernel_size2: 2\n",
      "    learning_rate: 0.0005618138822625489\n",
      "    batch_size: 64\n",
      "    epochs: 107\n",
      "Epoch 1/107\n",
      "15/15 [==============================] - 1s 10ms/step - loss: 687.9490 - val_loss: 40.6998\n",
      "Epoch 2/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 84.1226 - val_loss: 58.2918\n",
      "Epoch 3/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 17.4566 - val_loss: 0.6199\n",
      "Epoch 4/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 3.7881 - val_loss: 3.5363\n",
      "Epoch 5/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1754 - val_loss: 0.9708\n",
      "Epoch 6/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6280 - val_loss: 0.5131\n",
      "Epoch 7/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5159 - val_loss: 0.5132\n",
      "Epoch 8/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4833 - val_loss: 0.5132\n",
      "Epoch 9/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4729 - val_loss: 0.5383\n",
      "Epoch 10/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4718 - val_loss: 0.5568\n",
      "Epoch 11/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4794 - val_loss: 0.5701\n",
      "Epoch 12/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4744 - val_loss: 0.5341\n",
      "Epoch 13/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4805 - val_loss: 0.5492\n",
      "Epoch 14/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4688 - val_loss: 0.5335\n",
      "Epoch 15/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4689 - val_loss: 0.5286\n",
      "Epoch 16/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4667 - val_loss: 0.5100\n",
      "Epoch 17/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4693 - val_loss: 0.5105\n",
      "Epoch 18/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4656 - val_loss: 0.5152\n",
      "Epoch 19/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4669 - val_loss: 0.5110\n",
      "Epoch 20/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4684 - val_loss: 0.5421\n",
      "Epoch 21/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4705 - val_loss: 0.5831\n",
      "Epoch 22/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4756 - val_loss: 0.5161\n",
      "Epoch 23/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4635 - val_loss: 0.5177\n",
      "Epoch 24/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4657 - val_loss: 0.5075\n",
      "Epoch 25/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4608 - val_loss: 0.5288\n",
      "Epoch 26/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4870 - val_loss: 0.5062\n",
      "Epoch 27/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4803 - val_loss: 0.5661\n",
      "Epoch 28/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4723 - val_loss: 0.5299\n",
      "Epoch 29/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5113 - val_loss: 0.6547\n",
      "Epoch 30/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4959 - val_loss: 0.5256\n",
      "Epoch 31/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5426 - val_loss: 0.8558\n",
      "Epoch 32/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5477 - val_loss: 0.5108\n",
      "Epoch 33/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4745 - val_loss: 0.5035\n",
      "Epoch 34/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4558 - val_loss: 0.5316\n",
      "Epoch 35/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4556 - val_loss: 0.5168\n",
      "Epoch 36/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4571 - val_loss: 0.5144\n",
      "Epoch 37/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4569 - val_loss: 0.5049\n",
      "Epoch 38/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4663 - val_loss: 0.5125\n",
      "Epoch 39/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4525 - val_loss: 0.5820\n",
      "Epoch 40/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4607 - val_loss: 0.5015\n",
      "Epoch 41/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4560 - val_loss: 0.5141\n",
      "Epoch 42/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4769 - val_loss: 0.6115\n",
      "Epoch 43/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4692 - val_loss: 0.5152\n",
      "Epoch 44/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4508 - val_loss: 0.4982\n",
      "Epoch 45/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4650 - val_loss: 0.5912\n",
      "Epoch 46/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4708 - val_loss: 0.4966\n",
      "Epoch 47/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4499 - val_loss: 0.5357\n",
      "Epoch 48/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4532 - val_loss: 0.5458\n",
      "Epoch 49/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4730 - val_loss: 0.5271\n",
      "Epoch 50/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4470 - val_loss: 0.4983\n",
      "Epoch 51/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4539 - val_loss: 0.4961\n",
      "Epoch 52/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4648 - val_loss: 0.4947\n",
      "Epoch 53/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4538 - val_loss: 0.5019\n",
      "Epoch 54/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4568 - val_loss: 0.5429\n",
      "Epoch 55/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4478 - val_loss: 0.5034\n",
      "Epoch 56/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4469 - val_loss: 0.5391\n",
      "Epoch 57/107\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.4660 - val_loss: 0.4929\n",
      "Epoch 58/107\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4390 - val_loss: 0.5034\n",
      "Epoch 59/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4377 - val_loss: 0.5097\n",
      "Epoch 60/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4368 - val_loss: 0.5055\n",
      "Epoch 61/107\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4482 - val_loss: 0.5002\n",
      "Epoch 62/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4422 - val_loss: 0.4980\n",
      "Epoch 63/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4524 - val_loss: 0.5252\n",
      "Epoch 64/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4654 - val_loss: 0.5607\n",
      "Epoch 65/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4559 - val_loss: 0.5300\n",
      "Epoch 66/107\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4457 - val_loss: 0.5008\n",
      "Epoch 67/107\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4467 - val_loss: 0.5026\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "MSE   : 0.46456173095244624\n"
     ]
    }
   ],
   "source": [
    "CNN_testing_8 = CNN_testing(normalizes_df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "433241ed-4f81-4e4f-a622-332a711d9d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:03,501] A new study created in memory with name: no-name-b009a5a7-928c-4a83-806b-fbdad8423564\n",
      "[I 2025-08-13 00:36:08,241] Trial 0 finished with value: 0.3831366300582886 and parameters: {'filters1': 128, 'kernel_size1': 1, 'filters2': 43, 'kernel_size2': 3, 'learning_rate': 0.000340403631265004, 'batch_size': 16, 'epochs': 190}. Best is trial 0 with value: 0.3831366300582886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3831366300582886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:11,938] Trial 1 finished with value: 0.3923364579677582 and parameters: {'filters1': 90, 'kernel_size1': 2, 'filters2': 20, 'kernel_size2': 1, 'learning_rate': 0.00045754826025274514, 'batch_size': 64, 'epochs': 54}. Best is trial 0 with value: 0.3831366300582886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3923364579677582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:16,253] Trial 2 finished with value: 0.29654961824417114 and parameters: {'filters1': 124, 'kernel_size1': 2, 'filters2': 27, 'kernel_size2': 3, 'learning_rate': 0.0023514065039247334, 'batch_size': 16, 'epochs': 99}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29654961824417114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:18,960] Trial 3 finished with value: 0.33782273530960083 and parameters: {'filters1': 84, 'kernel_size1': 3, 'filters2': 38, 'kernel_size2': 3, 'learning_rate': 0.0014140573604263069, 'batch_size': 64, 'epochs': 93}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33782273530960083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:21,243] Trial 4 finished with value: 0.38240230083465576 and parameters: {'filters1': 119, 'kernel_size1': 3, 'filters2': 57, 'kernel_size2': 3, 'learning_rate': 0.0007693250940568624, 'batch_size': 32, 'epochs': 192}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.38240230083465576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:25,064] Trial 5 finished with value: 0.3122858703136444 and parameters: {'filters1': 128, 'kernel_size1': 2, 'filters2': 51, 'kernel_size2': 3, 'learning_rate': 0.00624479472522836, 'batch_size': 16, 'epochs': 67}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3122858703136444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:29,325] Trial 6 finished with value: 0.4555337131023407 and parameters: {'filters1': 44, 'kernel_size1': 1, 'filters2': 48, 'kernel_size2': 1, 'learning_rate': 0.00024042874689045706, 'batch_size': 64, 'epochs': 85}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.4555337131023407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:31,505] Trial 7 finished with value: 0.3000837564468384 and parameters: {'filters1': 112, 'kernel_size1': 3, 'filters2': 27, 'kernel_size2': 2, 'learning_rate': 0.007167937639575055, 'batch_size': 64, 'epochs': 118}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3000837564468384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:38,608] Trial 8 finished with value: 0.49503612518310547 and parameters: {'filters1': 85, 'kernel_size1': 1, 'filters2': 17, 'kernel_size2': 1, 'learning_rate': 0.0001959457833468151, 'batch_size': 64, 'epochs': 108}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.49503612518310547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:49,159] Trial 9 finished with value: 0.6289101839065552 and parameters: {'filters1': 95, 'kernel_size1': 2, 'filters2': 49, 'kernel_size2': 2, 'learning_rate': 0.00010594832426661236, 'batch_size': 64, 'epochs': 105}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.6289101839065552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:51,540] Trial 10 finished with value: 0.3396543860435486 and parameters: {'filters1': 60, 'kernel_size1': 2, 'filters2': 31, 'kernel_size2': 2, 'learning_rate': 0.0025510987769339897, 'batch_size': 16, 'epochs': 142}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3396543860435486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:53,908] Trial 11 finished with value: 0.3083480894565582 and parameters: {'filters1': 106, 'kernel_size1': 3, 'filters2': 28, 'kernel_size2': 2, 'learning_rate': 0.007573738175951648, 'batch_size': 32, 'epochs': 140}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3083480894565582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:36:58,996] Trial 12 finished with value: 0.29733335971832275 and parameters: {'filters1': 110, 'kernel_size1': 3, 'filters2': 29, 'kernel_size2': 2, 'learning_rate': 0.0034494467244679987, 'batch_size': 16, 'epochs': 127}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29733335971832275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:03,341] Trial 13 finished with value: 0.30159932374954224 and parameters: {'filters1': 68, 'kernel_size1': 2, 'filters2': 35, 'kernel_size2': 2, 'learning_rate': 0.0027377125388406004, 'batch_size': 16, 'epochs': 159}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30159932374954224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:07,379] Trial 14 finished with value: 0.33270686864852905 and parameters: {'filters1': 102, 'kernel_size1': 3, 'filters2': 23, 'kernel_size2': 3, 'learning_rate': 0.0029090817500280262, 'batch_size': 16, 'epochs': 133}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33270686864852905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:10,588] Trial 15 finished with value: 0.3198665678501129 and parameters: {'filters1': 116, 'kernel_size1': 2, 'filters2': 35, 'kernel_size2': 2, 'learning_rate': 0.0011644511314386524, 'batch_size': 16, 'epochs': 164}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3198665678501129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:13,012] Trial 16 finished with value: 0.34652119874954224 and parameters: {'filters1': 100, 'kernel_size1': 3, 'filters2': 25, 'kernel_size2': 3, 'learning_rate': 0.0039007381222760686, 'batch_size': 16, 'epochs': 82}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.34652119874954224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:19,689] Trial 17 finished with value: 0.3294887840747833 and parameters: {'filters1': 36, 'kernel_size1': 1, 'filters2': 64, 'kernel_size2': 1, 'learning_rate': 0.0016674507364689544, 'batch_size': 16, 'epochs': 121}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3294887840747833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:23,235] Trial 18 finished with value: 0.3977420926094055 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 2, 'learning_rate': 0.0007486260138716734, 'batch_size': 32, 'epochs': 162}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3977420926094055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:25,465] Trial 19 finished with value: 0.3155701160430908 and parameters: {'filters1': 72, 'kernel_size1': 3, 'filters2': 31, 'kernel_size2': 2, 'learning_rate': 0.004364973844194197, 'batch_size': 16, 'epochs': 99}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3155701160430908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:29,977] Trial 20 finished with value: 0.33871695399284363 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 43, 'kernel_size2': 3, 'learning_rate': 0.0019083566435646674, 'batch_size': 16, 'epochs': 74}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33871695399284363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:31,792] Trial 21 finished with value: 0.3000318109989166 and parameters: {'filters1': 110, 'kernel_size1': 3, 'filters2': 26, 'kernel_size2': 2, 'learning_rate': 0.005213071832625912, 'batch_size': 64, 'epochs': 120}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3000318109989166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:33,442] Trial 22 finished with value: 0.29994308948516846 and parameters: {'filters1': 108, 'kernel_size1': 3, 'filters2': 22, 'kernel_size2': 2, 'learning_rate': 0.009601131980404147, 'batch_size': 64, 'epochs': 115}. Best is trial 2 with value: 0.29654961824417114.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29994308948516846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:36,078] Trial 23 finished with value: 0.29540351033210754 and parameters: {'filters1': 122, 'kernel_size1': 3, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.008876441785201531, 'batch_size': 32, 'epochs': 148}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29540351033210754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:39,184] Trial 24 finished with value: 0.2982751429080963 and parameters: {'filters1': 124, 'kernel_size1': 2, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0036873673259423924, 'batch_size': 32, 'epochs': 153}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2982751429080963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:40,987] Trial 25 finished with value: 0.2959594428539276 and parameters: {'filters1': 123, 'kernel_size1': 3, 'filters2': 31, 'kernel_size2': 1, 'learning_rate': 0.009408287963788708, 'batch_size': 32, 'epochs': 182}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2959594428539276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:48,290] Trial 26 finished with value: 0.29720667004585266 and parameters: {'filters1': 121, 'kernel_size1': 3, 'filters2': 35, 'kernel_size2': 1, 'learning_rate': 0.009870822758835923, 'batch_size': 32, 'epochs': 179}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29720667004585266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:50,843] Trial 27 finished with value: 0.2970215082168579 and parameters: {'filters1': 96, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 1, 'learning_rate': 0.0057748920964359445, 'batch_size': 32, 'epochs': 174}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2970215082168579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:54,117] Trial 28 finished with value: 0.3164466619491577 and parameters: {'filters1': 123, 'kernel_size1': 3, 'filters2': 39, 'kernel_size2': 1, 'learning_rate': 0.0020047579303927106, 'batch_size': 32, 'epochs': 177}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3164466619491577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:56,895] Trial 29 finished with value: 0.3020670413970947 and parameters: {'filters1': 128, 'kernel_size1': 1, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.009761684980989453, 'batch_size': 32, 'epochs': 198}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3020670413970947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:37:59,502] Trial 30 finished with value: 0.3033277690410614 and parameters: {'filters1': 53, 'kernel_size1': 2, 'filters2': 43, 'kernel_size2': 1, 'learning_rate': 0.004844121777699319, 'batch_size': 32, 'epochs': 145}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3033277690410614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:02,677] Trial 31 finished with value: 0.302310585975647 and parameters: {'filters1': 101, 'kernel_size1': 2, 'filters2': 31, 'kernel_size2': 1, 'learning_rate': 0.006169520542538009, 'batch_size': 32, 'epochs': 175}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.302310585975647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:04,931] Trial 32 finished with value: 0.46298813819885254 and parameters: {'filters1': 94, 'kernel_size1': 2, 'filters2': 24, 'kernel_size2': 1, 'learning_rate': 0.006964334668642073, 'batch_size': 32, 'epochs': 183}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.46298813819885254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:06,846] Trial 33 finished with value: 0.3169231116771698 and parameters: {'filters1': 116, 'kernel_size1': 2, 'filters2': 33, 'kernel_size2': 1, 'learning_rate': 0.005353679322884538, 'batch_size': 32, 'epochs': 168}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3169231116771698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:09,005] Trial 34 finished with value: 0.3391941785812378 and parameters: {'filters1': 79, 'kernel_size1': 2, 'filters2': 38, 'kernel_size2': 1, 'learning_rate': 0.008160176165304588, 'batch_size': 32, 'epochs': 188}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3391941785812378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:11,747] Trial 35 finished with value: 0.3107975721359253 and parameters: {'filters1': 128, 'kernel_size1': 2, 'filters2': 29, 'kernel_size2': 3, 'learning_rate': 0.0009134073604268823, 'batch_size': 32, 'epochs': 197}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3107975721359253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:16,295] Trial 36 finished with value: 0.3758850693702698 and parameters: {'filters1': 88, 'kernel_size1': 3, 'filters2': 20, 'kernel_size2': 1, 'learning_rate': 0.0004360762930491614, 'batch_size': 32, 'epochs': 52}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3758850693702698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:20,934] Trial 37 finished with value: 0.3000333607196808 and parameters: {'filters1': 116, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.005693139517860878, 'batch_size': 32, 'epochs': 152}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3000333607196808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:23,242] Trial 38 finished with value: 0.30860435962677 and parameters: {'filters1': 104, 'kernel_size1': 3, 'filters2': 37, 'kernel_size2': 1, 'learning_rate': 0.003344540970822408, 'batch_size': 32, 'epochs': 170}. Best is trial 23 with value: 0.29540351033210754.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30860435962677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:26,735] Trial 39 finished with value: 0.29436537623405457 and parameters: {'filters1': 123, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 1, 'learning_rate': 0.007730202513966538, 'batch_size': 32, 'epochs': 189}. Best is trial 39 with value: 0.29436537623405457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29436537623405457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:30,907] Trial 40 finished with value: 0.367876261472702 and parameters: {'filters1': 124, 'kernel_size1': 3, 'filters2': 47, 'kernel_size2': 3, 'learning_rate': 0.0005973186466429945, 'batch_size': 32, 'epochs': 189}. Best is trial 39 with value: 0.29436537623405457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.367876261472702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:32,491] Trial 41 finished with value: 0.29698213934898376 and parameters: {'filters1': 116, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 1, 'learning_rate': 0.007830709304921189, 'batch_size': 32, 'epochs': 183}. Best is trial 39 with value: 0.29436537623405457.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29698213934898376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:34,329] Trial 42 finished with value: 0.29077526926994324 and parameters: {'filters1': 115, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 1, 'learning_rate': 0.00803170816921116, 'batch_size': 32, 'epochs': 186}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29077526926994324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:36,558] Trial 43 finished with value: 0.30788761377334595 and parameters: {'filters1': 128, 'kernel_size1': 2, 'filters2': 44, 'kernel_size2': 1, 'learning_rate': 0.008282171721588074, 'batch_size': 32, 'epochs': 89}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30788761377334595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:40,476] Trial 44 finished with value: 0.2993142306804657 and parameters: {'filters1': 121, 'kernel_size1': 2, 'filters2': 53, 'kernel_size2': 1, 'learning_rate': 0.004470909632028808, 'batch_size': 32, 'epochs': 192}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2993142306804657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:44,859] Trial 45 finished with value: 0.30272889137268066 and parameters: {'filters1': 114, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 1, 'learning_rate': 0.006406119421188448, 'batch_size': 32, 'epochs': 63}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30272889137268066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:47,178] Trial 46 finished with value: 0.3316541314125061 and parameters: {'filters1': 120, 'kernel_size1': 2, 'filters2': 18, 'kernel_size2': 2, 'learning_rate': 0.0013159290892924272, 'batch_size': 64, 'epochs': 134}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3316541314125061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:49,564] Trial 47 finished with value: 0.32893964648246765 and parameters: {'filters1': 124, 'kernel_size1': 1, 'filters2': 46, 'kernel_size2': 1, 'learning_rate': 0.007481748362424463, 'batch_size': 16, 'epochs': 156}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.32893964648246765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:38:52,769] Trial 48 finished with value: 0.30694809556007385 and parameters: {'filters1': 107, 'kernel_size1': 2, 'filters2': 51, 'kernel_size2': 2, 'learning_rate': 0.003165155558212107, 'batch_size': 32, 'epochs': 108}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30694809556007385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:02,945] Trial 49 finished with value: 0.40521571040153503 and parameters: {'filters1': 118, 'kernel_size1': 3, 'filters2': 28, 'kernel_size2': 1, 'learning_rate': 0.0002382889970411848, 'batch_size': 16, 'epochs': 198}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.40521571040153503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:06,127] Trial 50 finished with value: 0.29886385798454285 and parameters: {'filters1': 111, 'kernel_size1': 2, 'filters2': 36, 'kernel_size2': 2, 'learning_rate': 0.0021887724019105576, 'batch_size': 32, 'epochs': 183}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29886385798454285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:08,053] Trial 51 finished with value: 0.31370311975479126 and parameters: {'filters1': 114, 'kernel_size1': 2, 'filters2': 41, 'kernel_size2': 1, 'learning_rate': 0.008241588134108368, 'batch_size': 32, 'epochs': 185}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31370311975479126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:10,770] Trial 52 finished with value: 0.31154072284698486 and parameters: {'filters1': 125, 'kernel_size1': 2, 'filters2': 45, 'kernel_size2': 1, 'learning_rate': 0.004364835650791745, 'batch_size': 32, 'epochs': 167}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31154072284698486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:13,546] Trial 53 finished with value: 0.3980148434638977 and parameters: {'filters1': 118, 'kernel_size1': 2, 'filters2': 42, 'kernel_size2': 1, 'learning_rate': 0.0068805886334069866, 'batch_size': 32, 'epochs': 181}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3980148434638977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:18,095] Trial 54 finished with value: 0.30004602670669556 and parameters: {'filters1': 115, 'kernel_size1': 2, 'filters2': 39, 'kernel_size2': 1, 'learning_rate': 0.00867218022098417, 'batch_size': 16, 'epochs': 147}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30004602670669556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:20,260] Trial 55 finished with value: 0.3094545304775238 and parameters: {'filters1': 106, 'kernel_size1': 2, 'filters2': 34, 'kernel_size2': 1, 'learning_rate': 0.002544386253345349, 'batch_size': 64, 'epochs': 192}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3094545304775238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:23,103] Trial 56 finished with value: 0.305044025182724 and parameters: {'filters1': 126, 'kernel_size1': 3, 'filters2': 40, 'kernel_size2': 1, 'learning_rate': 0.006983736908419457, 'batch_size': 32, 'epochs': 96}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.305044025182724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:30,824] Trial 57 finished with value: 0.3755209147930145 and parameters: {'filters1': 121, 'kernel_size1': 2, 'filters2': 23, 'kernel_size2': 2, 'learning_rate': 0.00011384931562611952, 'batch_size': 16, 'epochs': 172}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3755209147930145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:32,970] Trial 58 finished with value: 0.31432321667671204 and parameters: {'filters1': 112, 'kernel_size1': 3, 'filters2': 48, 'kernel_size2': 1, 'learning_rate': 0.009475559707077749, 'batch_size': 32, 'epochs': 160}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31432321667671204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:36,102] Trial 59 finished with value: 0.30563271045684814 and parameters: {'filters1': 119, 'kernel_size1': 2, 'filters2': 30, 'kernel_size2': 2, 'learning_rate': 0.0041156686735400435, 'batch_size': 32, 'epochs': 130}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30563271045684814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:38,460] Trial 60 finished with value: 0.2984297275543213 and parameters: {'filters1': 99, 'kernel_size1': 2, 'filters2': 50, 'kernel_size2': 3, 'learning_rate': 0.0053581744540656725, 'batch_size': 16, 'epochs': 200}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2984297275543213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:41,405] Trial 61 finished with value: 0.33836135268211365 and parameters: {'filters1': 97, 'kernel_size1': 2, 'filters2': 33, 'kernel_size2': 1, 'learning_rate': 0.0059733909561623735, 'batch_size': 32, 'epochs': 177}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33836135268211365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:44,300] Trial 62 finished with value: 0.34956714510917664 and parameters: {'filters1': 92, 'kernel_size1': 2, 'filters2': 37, 'kernel_size2': 1, 'learning_rate': 0.0076471066207010815, 'batch_size': 32, 'epochs': 193}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.34956714510917664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:48,203] Trial 63 finished with value: 0.3099501430988312 and parameters: {'filters1': 77, 'kernel_size1': 2, 'filters2': 32, 'kernel_size2': 1, 'learning_rate': 0.006135725503532149, 'batch_size': 32, 'epochs': 172}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3099501430988312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:50,820] Trial 64 finished with value: 0.29738345742225647 and parameters: {'filters1': 122, 'kernel_size1': 2, 'filters2': 27, 'kernel_size2': 1, 'learning_rate': 0.009824809477190416, 'batch_size': 32, 'epochs': 188}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29738345742225647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:53,693] Trial 65 finished with value: 0.33467787504196167 and parameters: {'filters1': 109, 'kernel_size1': 2, 'filters2': 16, 'kernel_size2': 1, 'learning_rate': 0.00805895219803916, 'batch_size': 32, 'epochs': 178}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33467787504196167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:55,842] Trial 66 finished with value: 0.31700628995895386 and parameters: {'filters1': 104, 'kernel_size1': 2, 'filters2': 25, 'kernel_size2': 1, 'learning_rate': 0.005159631212514086, 'batch_size': 64, 'epochs': 78}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.31700628995895386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:39:57,817] Trial 67 finished with value: 0.30241456627845764 and parameters: {'filters1': 65, 'kernel_size1': 3, 'filters2': 39, 'kernel_size2': 3, 'learning_rate': 0.0037467406072802215, 'batch_size': 32, 'epochs': 165}. Best is trial 42 with value: 0.29077526926994324.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30241456627845764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:02,845] Trial 68 finished with value: 0.2867877185344696 and parameters: {'filters1': 87, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 1, 'learning_rate': 0.004773178389486693, 'batch_size': 32, 'epochs': 136}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2867877185344696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:05,969] Trial 69 finished with value: 0.2933308780193329 and parameters: {'filters1': 84, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.0016103480914854487, 'batch_size': 16, 'epochs': 142}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2933308780193329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:08,172] Trial 70 finished with value: 0.35727888345718384 and parameters: {'filters1': 86, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.0015364864337055286, 'batch_size': 16, 'epochs': 141}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.35727888345718384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:12,541] Trial 71 finished with value: 0.36848318576812744 and parameters: {'filters1': 81, 'kernel_size1': 1, 'filters2': 19, 'kernel_size2': 1, 'learning_rate': 0.002347455780677399, 'batch_size': 16, 'epochs': 137}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.36848318576812744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:18,903] Trial 72 finished with value: 0.39178353548049927 and parameters: {'filters1': 44, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 1, 'learning_rate': 0.0017864657648676255, 'batch_size': 16, 'epochs': 124}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.39178353548049927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:25,606] Trial 73 finished with value: 0.3129543364048004 and parameters: {'filters1': 76, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 1, 'learning_rate': 0.0028559871736498184, 'batch_size': 16, 'epochs': 114}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3129543364048004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:35,136] Trial 74 finished with value: 0.3400473892688751 and parameters: {'filters1': 89, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 1, 'learning_rate': 0.0010435146048701311, 'batch_size': 16, 'epochs': 147}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3400473892688751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:38,718] Trial 75 finished with value: 0.3279160261154175 and parameters: {'filters1': 73, 'kernel_size1': 1, 'filters2': 18, 'kernel_size2': 1, 'learning_rate': 0.004732134876673942, 'batch_size': 32, 'epochs': 128}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3279160261154175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:40,869] Trial 76 finished with value: 0.2972267270088196 and parameters: {'filters1': 82, 'kernel_size1': 1, 'filters2': 23, 'kernel_size2': 1, 'learning_rate': 0.008816815234393033, 'batch_size': 32, 'epochs': 152}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2972267270088196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:44,280] Trial 77 finished with value: 0.3958992063999176 and parameters: {'filters1': 117, 'kernel_size1': 1, 'filters2': 63, 'kernel_size2': 1, 'learning_rate': 0.0013779428819464478, 'batch_size': 32, 'epochs': 104}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3958992063999176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:47,022] Trial 78 finished with value: 0.33516159653663635 and parameters: {'filters1': 58, 'kernel_size1': 3, 'filters2': 43, 'kernel_size2': 1, 'learning_rate': 0.007300662993332494, 'batch_size': 16, 'epochs': 137}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.33516159653663635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:49,026] Trial 79 finished with value: 0.2927100360393524 and parameters: {'filters1': 127, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 3, 'learning_rate': 0.006619286776466464, 'batch_size': 64, 'epochs': 116}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2927100360393524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:51,635] Trial 80 finished with value: 0.29294076561927795 and parameters: {'filters1': 127, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 3, 'learning_rate': 0.006605673756425714, 'batch_size': 64, 'epochs': 102}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29294076561927795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:53,539] Trial 81 finished with value: 0.3007940351963043 and parameters: {'filters1': 126, 'kernel_size1': 1, 'filters2': 28, 'kernel_size2': 3, 'learning_rate': 0.006974714270083192, 'batch_size': 64, 'epochs': 88}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3007940351963043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:57,023] Trial 82 finished with value: 0.29217013716697693 and parameters: {'filters1': 128, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.006157769778727838, 'batch_size': 64, 'epochs': 114}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29217013716697693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:40:59,504] Trial 83 finished with value: 0.30144330859184265 and parameters: {'filters1': 128, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.005798891358640748, 'batch_size': 64, 'epochs': 113}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30144330859184265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:03,713] Trial 84 finished with value: 0.29700371623039246 and parameters: {'filters1': 123, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 3, 'learning_rate': 0.006490501033994908, 'batch_size': 64, 'epochs': 123}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29700371623039246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:06,455] Trial 85 finished with value: 0.3059793710708618 and parameters: {'filters1': 126, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 3, 'learning_rate': 0.009051387518060979, 'batch_size': 64, 'epochs': 118}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3059793710708618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:09,263] Trial 86 finished with value: 0.2969820201396942 and parameters: {'filters1': 122, 'kernel_size1': 1, 'filters2': 25, 'kernel_size2': 3, 'learning_rate': 0.004797891526455539, 'batch_size': 64, 'epochs': 104}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2969820201396942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:11,773] Trial 87 finished with value: 0.30331215262413025 and parameters: {'filters1': 128, 'kernel_size1': 1, 'filters2': 20, 'kernel_size2': 3, 'learning_rate': 0.0006389906559761006, 'batch_size': 64, 'epochs': 109}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30331215262413025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:14,527] Trial 88 finished with value: 0.38110995292663574 and parameters: {'filters1': 120, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 3, 'learning_rate': 0.005304555261586491, 'batch_size': 64, 'epochs': 130}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.38110995292663574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:16,566] Trial 89 finished with value: 0.29701754450798035 and parameters: {'filters1': 124, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 3, 'learning_rate': 0.009966219784451119, 'batch_size': 64, 'epochs': 110}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29701754450798035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:20,211] Trial 90 finished with value: 0.2979011535644531 and parameters: {'filters1': 114, 'kernel_size1': 1, 'filters2': 29, 'kernel_size2': 3, 'learning_rate': 0.006430412115832882, 'batch_size': 64, 'epochs': 118}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2979011535644531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:23,645] Trial 91 finished with value: 0.29698431491851807 and parameters: {'filters1': 126, 'kernel_size1': 1, 'filters2': 22, 'kernel_size2': 3, 'learning_rate': 0.008631144899179623, 'batch_size': 64, 'epochs': 100}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29698431491851807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:25,891] Trial 92 finished with value: 0.3200721740722656 and parameters: {'filters1': 119, 'kernel_size1': 1, 'filters2': 24, 'kernel_size2': 3, 'learning_rate': 0.003238935658326612, 'batch_size': 64, 'epochs': 92}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3200721740722656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:28,143] Trial 93 finished with value: 0.30679047107696533 and parameters: {'filters1': 123, 'kernel_size1': 1, 'filters2': 27, 'kernel_size2': 3, 'learning_rate': 0.003924574291189009, 'batch_size': 64, 'epochs': 102}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30679047107696533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:29,793] Trial 94 finished with value: 0.2970035970211029 and parameters: {'filters1': 125, 'kernel_size1': 3, 'filters2': 19, 'kernel_size2': 3, 'learning_rate': 0.006788690787867832, 'batch_size': 64, 'epochs': 98}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.2970035970211029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:33,358] Trial 95 finished with value: 0.30009710788726807 and parameters: {'filters1': 84, 'kernel_size1': 1, 'filters2': 30, 'kernel_size2': 3, 'learning_rate': 0.007419832441980588, 'batch_size': 16, 'epochs': 111}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30009710788726807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:36,647] Trial 96 finished with value: 0.30187854170799255 and parameters: {'filters1': 121, 'kernel_size1': 1, 'filters2': 26, 'kernel_size2': 3, 'learning_rate': 0.00787737051381939, 'batch_size': 64, 'epochs': 143}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30187854170799255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:39,184] Trial 97 finished with value: 0.29929012060165405 and parameters: {'filters1': 113, 'kernel_size1': 3, 'filters2': 28, 'kernel_size2': 3, 'learning_rate': 0.0020643246699313953, 'batch_size': 32, 'epochs': 121}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.29929012060165405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:44,466] Trial 98 finished with value: 0.30363598465919495 and parameters: {'filters1': 117, 'kernel_size1': 1, 'filters2': 21, 'kernel_size2': 2, 'learning_rate': 0.004318169748202297, 'batch_size': 16, 'epochs': 134}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.30363598465919495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-13 00:41:48,272] Trial 99 finished with value: 0.3126784563064575 and parameters: {'filters1': 126, 'kernel_size1': 1, 'filters2': 32, 'kernel_size2': 3, 'learning_rate': 0.0011628919112602824, 'batch_size': 32, 'epochs': 107}. Best is trial 68 with value: 0.2867877185344696.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE   : 0.3126784563064575\n",
      "Best Trial:\n",
      "  Value: 0.2867877185344696\n",
      "  Params: \n",
      "    filters1: 87\n",
      "    kernel_size1: 1\n",
      "    filters2: 22\n",
      "    kernel_size2: 1\n",
      "    learning_rate: 0.004773178389486693\n",
      "    batch_size: 32\n",
      "    epochs: 136\n",
      "Epoch 1/136\n",
      "30/30 [==============================] - 1s 6ms/step - loss: 790.8815 - val_loss: 26.7532\n",
      "Epoch 2/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 7.4943 - val_loss: 2.3794\n",
      "Epoch 3/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.7788 - val_loss: 0.3773\n",
      "Epoch 4/136\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3573 - val_loss: 0.3593\n",
      "Epoch 5/136\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.5166\n",
      "Epoch 6/136\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4025\n",
      "Epoch 7/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3586 - val_loss: 0.3474\n",
      "Epoch 8/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3336 - val_loss: 0.3427\n",
      "Epoch 9/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3344 - val_loss: 0.3515\n",
      "Epoch 10/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3179 - val_loss: 0.4093\n",
      "Epoch 11/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3807 - val_loss: 0.4217\n",
      "Epoch 12/136\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3886\n",
      "Epoch 13/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3521 - val_loss: 0.3546\n",
      "Epoch 14/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3173 - val_loss: 0.3305\n",
      "Epoch 15/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3233 - val_loss: 0.3286\n",
      "Epoch 16/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3287 - val_loss: 0.3553\n",
      "Epoch 17/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3296 - val_loss: 0.4713\n",
      "Epoch 18/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3361 - val_loss: 0.3556\n",
      "Epoch 19/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3302 - val_loss: 0.6778\n",
      "Epoch 20/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3882 - val_loss: 0.3545\n",
      "Epoch 21/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3461 - val_loss: 0.3273\n",
      "Epoch 22/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3041 - val_loss: 0.4224\n",
      "Epoch 23/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3202 - val_loss: 0.3204\n",
      "Epoch 24/136\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.2894 - val_loss: 0.3196\n",
      "Epoch 25/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3193 - val_loss: 0.4386\n",
      "Epoch 26/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3325 - val_loss: 0.3200\n",
      "Epoch 27/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2996 - val_loss: 0.3238\n",
      "Epoch 28/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3156 - val_loss: 0.3316\n",
      "Epoch 29/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2829 - val_loss: 0.3674\n",
      "Epoch 30/136\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.3456 - val_loss: 0.3327\n",
      "Epoch 31/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2928 - val_loss: 0.3507\n",
      "Epoch 32/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3091 - val_loss: 0.5448\n",
      "Epoch 33/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.3171\n",
      "Epoch 34/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2922 - val_loss: 0.7496\n",
      "Epoch 35/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3443 - val_loss: 0.3326\n",
      "Epoch 36/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3355 - val_loss: 0.4504\n",
      "Epoch 37/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2982 - val_loss: 0.3275\n",
      "Epoch 38/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3202 - val_loss: 0.4107\n",
      "Epoch 39/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3198 - val_loss: 0.3275\n",
      "Epoch 40/136\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3837 - val_loss: 0.7707\n",
      "Epoch 41/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.3096 - val_loss: 0.4680\n",
      "Epoch 42/136\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3144 - val_loss: 0.4786\n",
      "Epoch 43/136\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.2868 - val_loss: 0.3624\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "MSE   : 0.3056032808135413\n"
     ]
    }
   ],
   "source": [
    "CNN_testing_9 = CNN_testing(normalizes_df_9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
